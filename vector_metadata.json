[
  {
    "id": "a742d75a-3f71-4ae7-b2e7-b5481c960479",
    "filename": "documents\\376709eng.pdf",
    "page_number": 1,
    "chunk_id": "1_0",
    "chunk_text": "AI and education\nGuidance for policy-makers"
  },
  {
    "id": "1dc78495-eeb2-411d-be98-b818a50c0097",
    "filename": "documents\\376709eng.pdf",
    "page_number": 2,
    "chunk_id": "2_0",
    "chunk_text": "UNESCO Education Sector\nEducation is UNESCO’s top priority because  \nit is a basic human right and the foundation \non which to build peace and drive sustainable \ndevelopment. UNESCO is the United Nations’ \nspecialized agency for education and the \nEducation Sector provides global and \nregional leadership in education, strengthens \nnational education systems and responds \nto contemporary global challenges through \neducation with a special focus on gender \nequality and Africa. The Global Education 2030 Agenda\nUNESCO, as the United Nations’ specialized  \nagency for education, is entrusted to lead and \ncoordinate the Education 2030 Agenda, which is \npart of a global movement to eradicate poverty \nthrough 17 Sustainable Development Goals by \n2030. Education, essential to achieve all of these \ngoals, has its own dedicated Goal 4, which aims to \n“ensure inclusive and equitable quality education \nand promote lifelong learning opportunities for \nall.” The Education 2030 Framework for Action \nprovides guidance for the implementation of this \nambitious goal and commitments. Published in 2021 by the United Nations Educational, Scientific and Cultural Organization \n7, place de Fontenoy, 75352 Paris 07 SP, France\n© UNESCO 2021\nISBN 978-92-3-100447-6\nhttps://doi.org/10.54675/PCSP7350\nThis publication is available in Open Access under the Attribution-ShareAlike 3.0 IGO (CC-BY-SA 3.0 IGO) license  \n(http://creativecommons.org/licenses/by-sa/3.0/igo/). By using the content of this publication, the users accept to be bound \nby the terms of use of the UNESCO Open Access Repository (http://www.unesco.org/open-access/terms-use-ccbysa-en). The designations employed and the presentation of material throughout this publication do not imply the expression of \nany opinion whatsoever on the part of UNESCO concerning the legal status of any country, territory, city or area or of its \nauthorities, or concerning the delimitation of its frontiers or boundaries. The ideas and opinions expressed in this publication are those of the authors; they are not necessarily those of UNESCO \nand do not commit the Organization. Authors: Fengchun Miao, Wayne Holmes, Ronghuai Huang, and Hui Zhang\nCover credits: SChompoongam/Shutterstock.com, Lidiia/Shutterstock.com and illustrator096/Shutterstock.com\nDesigned by Anna Mortreux\nPrinted by UNESCO\nPrinted in France\nCLD  222.20"
  },
  {
    "id": "90e3d10f-645d-4c61-9144-6f8e909cedbe",
    "filename": "documents\\376709eng.pdf",
    "page_number": 3,
    "chunk_id": "3_0",
    "chunk_text": "S H O R T  S U M M A R Y\nAI and education:  \nPromise and implications\nArtificial Intelligence (AI) has the potential to address some of the biggest \nchallenges in education today, innovate teaching and learning practices, \nand ultimately accelerate the progress towards SDG 4. However, these rapid \ntechnological developments inevitably bring multiple risks and challenges, \nwhich have so far outpaced policy debates and \nregulatory frameworks. This publication offers guidance for policy-makers on \nhow best to leverage the opportunities and address \nthe risks, presented by the growing connection \nbetween AI and education. It starts with the essentials of AI: definitions, \ntechniques and technologies. It continues with \na detailed analysis of the emerging trends and \nimplications of AI for teaching and learning, including \nhow we can ensure the ethical, inclusive and \nequitable use of AI in education, how education can \nprepare humans to live and work with AI, and how \nAI can be applied to enhance education. It finally \nintroduces the challenges of harnessing AI to achieve SDG 4 and offers \nconcrete actionable recommendations for policy-makers to plan policies and \nprogrammes for local contexts. Short Summary\nAI in education is  \nexpected to be worth\n$6 billion\nby 2024\n‘Since wars begin in the minds of \nmen and women it is in the minds of \nmen and women that the defences \nof peace must be constructed.’"
  },
  {
    "id": "b3d8abfb-b2b8-4959-bad1-b23c8703df1a",
    "filename": "documents\\376709eng.pdf",
    "page_number": 4,
    "chunk_id": "4_0",
    "chunk_text": "Foreword – AI and education: Guidance for policy-makers \nForeword\n \nThe rapid development of Artificial Intelligence (AI) \nis having a major impact on education. Advances in \nAI-powered solutions carry enormous potential for \nsocial good and the achievement of the Sustainable \nDevelopment Goals. Making this happen requires \nsystem-wide policy adjustments and calls for robust \nethical oversight as well as in-depth engagement with \npractitioners and researchers globally. Policy-makers and educators have entered uncharted \nterritory that raises fundamental questions on how the future \nof learning will interact with AI. The bottom line is that the \ndeployment and use of AI in education must be guided by \nthe core principles of inclusion and equity. For this to happen, \npolicies must promote equitable and inclusive access to AI \nand the use of AI as a public good, with focus on empowering \ngirls and women and disadvantaged socio-economic groups. The growing use of novel AI technologies in education will \nonly benefit all of humanity if – by design – it enhances \nhuman-centred approaches to pedagogy, and respects \nethical norms and standards. AI should be geared to \nimproving learning for every student, empowering teachers \nand strengthening learning management systems. Beyond \nthis, preparing students and all citizens to live and work safely \nand effectively with AI is a shared challenge at global level. Future learning and training systems must equip all people \nwith core AI competencies, including understanding of how \nAI collects and can manipulate data, and skills to ensure \nsafety and protection of personal data. Finally, AI by nature \ntranscends the sectors, the planning of effective AI and \neducation policies requires consultation and collaboration \nwith stakeholders across disciplines and sectors. UNESCO has been playing a lead role in fostering dialogue and \nknowledge in all these areas with key public and private sector \nplayers. A number of events and publications have raised \nawareness of the extensive opportunities and implications of \nAI for education, and helped Member States begin to respond \nto complex challenges. In 2019, the relationship between AI \nand sustainable development was explored at ‘Mobile Learning \nWeek’, the United Nations’ flagship event on Information and \nCommunication Technology in education. The same year, in cooperation with the Government of \nthe People’s Republic of China, UNESCO organized the \n‘International Conference on Artificial Intelligence and \nEducation’ in Beijing under the theme ‘Planning Education \nin the AI Era: Lead the Leap’."
  },
  {
    "id": "ac590452-31d4-4910-9ed8-614354bc6f8c",
    "filename": "documents\\376709eng.pdf",
    "page_number": 4,
    "chunk_id": "4_1",
    "chunk_text": "Finally, AI by nature \ntranscends the sectors, the planning of effective AI and \neducation policies requires consultation and collaboration \nwith stakeholders across disciplines and sectors. UNESCO has been playing a lead role in fostering dialogue and \nknowledge in all these areas with key public and private sector \nplayers. A number of events and publications have raised \nawareness of the extensive opportunities and implications of \nAI for education, and helped Member States begin to respond \nto complex challenges. In 2019, the relationship between AI \nand sustainable development was explored at ‘Mobile Learning \nWeek’, the United Nations’ flagship event on Information and \nCommunication Technology in education. The same year, in cooperation with the Government of \nthe People’s Republic of China, UNESCO organized the \n‘International Conference on Artificial Intelligence and \nEducation’ in Beijing under the theme ‘Planning Education \nin the AI Era: Lead the Leap’. This conference examined the \nsystem-wide impacts of AI on education, and it was here \nthat the Beijing Consensus was adopted and released as \nthe first-ever document \nto offer recommendations \non how best to harness \nAI technologies for \nSDG4-Education 2030. The Beijing Consensus \nnotably recommends that \nUNESCO develop guidelines \nand resources to support \nthe capacity-building of \neducation policy-makers \nand the integration of AI \nskills into ICT competency frameworks. More broadly, it calls \non UNESCO to take a holistic approach to strengthening \ninternational cooperation in the field of AI and education \nwith relevant partners. 'AI and education: Guidance for policy-makers' is developed \nwithin the framework of the implementation of the Beijing \nConsensus, aimed at fostering AI-ready policy-makers \nin education. It adds to the growing body of UNESCO’s \nintellectual work in the field, and will be of interest to a \nrange of practitioners and professionals in the policymaking \nand education communities. It aims to generate a shared \nunderstanding of the opportunities offered by AI for \neducation, as well as its implications for the essential \ncompetencies required by the AI era. It presents a benefit-risk \nassessment to provoke critical thinking on how AI should \nbe leveraged to address the challenges of reaching the \nSDG 4 targets, and how potential risks should be uncovered \nand mitigated. It collects emerging national policies and \nbest practices on leveraging AI to enhance education and \nlearning."
  },
  {
    "id": "3fdc98ee-2de5-4935-9ba7-80a834563dfe",
    "filename": "documents\\376709eng.pdf",
    "page_number": 4,
    "chunk_id": "4_2",
    "chunk_text": "'AI and education: Guidance for policy-makers' is developed \nwithin the framework of the implementation of the Beijing \nConsensus, aimed at fostering AI-ready policy-makers \nin education. It adds to the growing body of UNESCO’s \nintellectual work in the field, and will be of interest to a \nrange of practitioners and professionals in the policymaking \nand education communities. It aims to generate a shared \nunderstanding of the opportunities offered by AI for \neducation, as well as its implications for the essential \ncompetencies required by the AI era. It presents a benefit-risk \nassessment to provoke critical thinking on how AI should \nbe leveraged to address the challenges of reaching the \nSDG 4 targets, and how potential risks should be uncovered \nand mitigated. It collects emerging national policies and \nbest practices on leveraging AI to enhance education and \nlearning. This publication can also be used as a guidebook \nfor the development of policies for AI and education, from \nplanning a humanistic and strategic objectives, to setting \nout key building policy components and implementation \nstrategies. It is therefore my hope that the key policy questions, analysis \nof lessons learned, and the humanistic policy approach \nshared herein will help governments and partners to deploy \nAI in a way that transforms education and training systems for \nthe common good of society, and for an inclusive and \nsustainable future. Stefania Giannini\nAssistant Director-General for Education\nUNESCO"
  },
  {
    "id": "86ec7faf-aa58-401a-abb5-2d2ecb4c3016",
    "filename": "documents\\376709eng.pdf",
    "page_number": 5,
    "chunk_id": "5_0",
    "chunk_text": "AI and education: Guidance for policy-makers – Acknowledgements\nAcknowledgements\nThis publication represents a collective effort of experts \nfrom the AI and education communities. The framework of the publication was conceptualized by \nFengchun Miao, Chief of UNESCO’s Unit for Technology \nand AI in Education, and Wayne Holmes, former Principal \nResearcher of Education at Nesta in the United Kingdom. They also served as the principal authors of the publication. The other two authors are Ronghuai Huang and Hui Zhang \nworking at the Beijing Normal University of China. The team members of the Unit for Technology and AI in \nEducation who coordinated the review and production \nof the publication are: Huhua Fan, Samuel Grimonprez, \nShutong Wang, Veronica Cucuiat and Glen Hertelendy. UNESCO specialists who provided inputs and peer reviews \nare: Borhene Chakroun, Director for Policies and Lifelong \nLearning Systems; Sobhi Tawil, Director for Future of \nLearning and Innovation; Keith Holmes, Programme \nSpecialist at the Future of Learning and Innovation Team; \nJulia Heiss, Programme Specialist at the Office in Harare; \nNatalia Amelina, Senior National Project Officer in Education \nat IITE; Valtencir M. Mendes, Senior Programme Lead, \nDivision for Policies and Lifelong Learning Systems; and \nElspeth McOmish, Programme Specialist at the Gender \nEquality Division. External experts whose contributions have benefited this \npublication are Ethel Agnes Pascua-Valenzuela, Director \nof Southeast Asian Ministers of Education Organizations \nSecretariat; Jianhua Zhao, Professor at China’s Southern \nUniversity of Science and Technology; Shafika Isaacs, \nResearch Associate at the University of Johannesburg; \nWerner Westermann, Chief of the Civic Education Program \nat Chile’s Library of Congress; and Mike Sharples, Emeritus \nProfessor of Educational Technology at the United \nKingdom's Open University. Gratitude is also extended to Jenny Webster for copyediting \nand proofreading the text, and to Anna Mortreux for \ndesigning the layout. UNESCO would like to thank the Weidong Group of China \nfor making this publication possible through its financial \nsupport to UNESCO. The financial support also helps \nMember States leverage technology and AI to achieve \nSustainable Development Goal 4."
  },
  {
    "id": "3200b0e8-a103-4b20-89ac-1a6ae4470dcc",
    "filename": "documents\\376709eng.pdf",
    "page_number": 6,
    "chunk_id": "6_0",
    "chunk_text": "3\nTable of contents – AI and education: Guidance for policy-makers \nAI and education\nGuidance for policy-makers\nTable of contents\nForeword \n1\nAcknowledgements \n2\nList of acronyms and abbreviations \n4\n1. Introduction \n5\n2. AI essentials for policy-makers \n6\n2.1 The interdisciplinary nature of AI \n6\n2.2 A brief introduction to AI techniques \n8\n2.3 A brief introduction to AI technologies \n9\n2.4 Possible trends in AI developments: ‘Weak’ and ‘strong’ AI \n10\n2.5 A critical view of the capabilities and limitations of AI \n11\n2.6 Human-machine collaborative intelligence \n11\n2.7 The Fourth Industrial Revolution and impact of AI on employment \n12\n3. Understanding AI and education: Emerging practices and benefit-risk assessment \n13\n3.1 How can AI be leveraged to enhance education? 13\n \nThe use of AI for education management and delivery \n14\n \nThe use of AI for learning and assessment  \n15\n \nThe use of AI to empower teachers and enhance teaching  \n18\n3.2 How can AI be best exploited for the common good in education? 19\n3.3 How can we ensure the ethical, inclusive and equitable use of AI in education? 20\n3.4 How can education prepare humans to live and work with AI? 23\n4. The challenges of harnessing AI to achieve SDG 4 \n25\n4.1 Data ethics and algorithmic biases  \n25\n4.2 Gender-equitable AI and AI for gender equality \n25\n4.3 Monitoring, evaluation and research into the use of AI in education \n26\n4.4 What impact will AI have on teacher roles? 27\n4.5 What impact will AI have on learner agency? 27\n5. A review of policy responses \n28\n5.1 Approaches to policy responses \n28\n5.2 Common areas of concern \n30\n5.3 Financing, partnership and international cooperation \n30\n6. Policy recommendations \n31\n6.1 A system-wide vision and strategic priorities  \n31\n6.2 Overarching principle for AI and education policies \n32\n6.3 Interdisciplinary planning and inter-sectoral governance \n32\n6.4 Policies and regulations for equitable, inclusive, and ethical use of AI  \n33\n6.5 Master plans for using AI in education management, teaching, learning, and assessment \n34\n6.6 Pilot testing, monitoring and evaluation, and building an evidence base \n36\n6.7 Fostering local AI innovations for education  \n37\n7. References \n38\nNotes \n44"
  },
  {
    "id": "829624b9-96d4-4473-b127-b7a0fd5de8c2",
    "filename": "documents\\376709eng.pdf",
    "page_number": 7,
    "chunk_id": "7_0",
    "chunk_text": "AI and education: Guidance for policy-makers – List of acronyms and abbreviations\n4\nList of acronyms and abbreviations\nAI \nArtificial Intelligence\nAI TA \nAI Teaching Assistant\nANN \nArtificial Neural Network\nAR \nAugmented Reality \nAWE \nAutomated Writing Evaluation\nCNN \nConvolutional Neural Network\nDBTS \nDialogue-Based Tutoring System\nDigComp \nEuropean Digital Competence Framework\nDNN \nDeep Neural Networks\nEEG \nElectroencephalography\nELE \nExploratory Learning Environment\nEMIS \nEducation Management Information System\nGAN \nGenerative Adversarial Network\nGDPR \nGeneral Data Protection Regulation\nGOFAI \nGood-Old-Fashioned AI\nICT \nInformation and Communication Technology\nILO \nInternational Labour Organization\nITS \nIntelligent Tutoring Systems\nIoT \nInternet of Things\nLMS \nLearning Management System\nLNO \nLearning Network Orchestrator\nLSTM \nLong Short-Term Memory\nML \nMachine Learning\nNLP \nNatural Language Processing\nOER \nOpen Educational Resources\nRNN \nRecurrent Neural Network\nSDG \nSustainable Development Goal\nSTEM \nScience, Technology, Engineering, and Mathematics\nTVET \nTechnical and Vocational Education and Training\nUNESCO \nUnited Nations Educational, Scientific, and Cultural Organization\nVR \nVirtual Reality"
  },
  {
    "id": "278053ff-cb76-4ccf-90fd-a3e7f88885df",
    "filename": "documents\\376709eng.pdf",
    "page_number": 8,
    "chunk_id": "8_0",
    "chunk_text": "Introduction – AI and education: Guidance for policy-makers \n5\n1. Introduction\nWithin just the last five years, because of some prominent successes and its disruptive \npotential, artificial intelligence (AI) has moved from the backwaters of academic research \nto the forefront of public discussions, including those at the level of the United Nations. In many countries, AI has become pervasive in daily life – from smartphone personal \nassistants to customer support chatbots, from recommending entertainment to \npredicting crime, and from facial recognition to medical diagnoses. However, while AI might have the potential to support the \nachievement of the Sustainable Development Goals (SDGs) \nof the United Nations, the rapid technological developments \ninevitably bring multiple risks and challenges, which have so \nfar outpaced policy debates and regulatory frameworks. And, \nwhile the main worries might involve AI overpowering human \nagency, more imminent concerns involve AI’s social and ethical \nimplications – such as the misuse of personal data and the \npossibility that AI might actually exacerbate rather than reduce \nexisting inequalities. Nonetheless, AI has also entered the world of education. ‘Intelligent’, ‘adaptive’ and ‘personalized’ learning systems \nare increasingly being developed by the private sector for \ndeployment in schools and universities around the world, \ncreating a market expected to be worth US$6 billion in 2024 \n(Bhutani and Wadhwani, 2018). Inescapably, the application \nof AI in educational contexts raises profound questions – for \nexample about what should be taught and how, the evolving \nrole of teachers, and AI’s social and ethical implications. There are also numerous challenges, including issues such \nas educational equity and access. There is also an emerging \nconsensus that the very foundations of teaching and learning \nmay be reshaped by the deployment of AI in education. All of these issues are further complicated by the massive shift \nto online learning due to the COVID-19 school closures. Accordingly, this UNESCO guidance seeks to help policy-\nmakers better understand the possibilities and implications \nof AI for teaching and learning, so that its application in \neducational contexts genuinely helps achieve SDG 4: Ensure \ninclusive and equitable quality education and promote lifelong \nlearning opportunities for all. However, we must also be aware that the connection between \nAI and education will inevitably play out in very different \nways depending on the national and socio-economic \ncircumstances."
  },
  {
    "id": "f1277519-4691-4156-935c-889b488fc672",
    "filename": "documents\\376709eng.pdf",
    "page_number": 8,
    "chunk_id": "8_1",
    "chunk_text": "There are also numerous challenges, including issues such \nas educational equity and access. There is also an emerging \nconsensus that the very foundations of teaching and learning \nmay be reshaped by the deployment of AI in education. All of these issues are further complicated by the massive shift \nto online learning due to the COVID-19 school closures. Accordingly, this UNESCO guidance seeks to help policy-\nmakers better understand the possibilities and implications \nof AI for teaching and learning, so that its application in \neducational contexts genuinely helps achieve SDG 4: Ensure \ninclusive and equitable quality education and promote lifelong \nlearning opportunities for all. However, we must also be aware that the connection between \nAI and education will inevitably play out in very different \nways depending on the national and socio-economic \ncircumstances. With AI in general, the concern is that \nif we continue blindly forward, we should expect to see \nincreased inequality alongside economic disruption, social \nunrest, and in some cases, political instability, with the \ntechnologically disadvantaged and underrepresented faring the \nworst. (Smith and Neupane, 2018, p. 12)\nThis is no less a concern for AI and education. If AI is to \nsupport SDG 4, there is also a need to provide low-cost \nmodels for developing AI technologies, ensure that the \ninterests of low and middle income countries are represented \nin key debates and decisions, and create bridges between \nthese nations and countries where the implementation \nof AI is more advanced. This publication begins with a \nbrief introduction to AI – what it is and how it works – to \nprovide a foundation for an in-depth discussion of the \ninteraction between AI and education. This is followed by \nan introduction to the multiple ways in which AI is being \nused in education, together with a discussion about how \nAI might enhance inclusion and equity, quality of learning, \neducation management, and pedagogy. This discussion also \nconsiders how education might help all citizens develop the \nskills needed for life and work in the AI era. The main strategic \nobjectives – harnessing the benefits and mitigating the risks \nof AI for education – are then detailed, and the challenges \nfor achieving those objectives are explored. The guidance \nconcludes by proposing a set of recommendations, which are \ndesigned to inform a comprehensive vision and action plans \nfor AI-and-education policies."
  },
  {
    "id": "533d5da3-6d09-4ee4-8dbd-339d755b0791",
    "filename": "documents\\376709eng.pdf",
    "page_number": 9,
    "chunk_id": "9_0",
    "chunk_text": "AI and education: Guidance for policy-makers – AI essentials for policy-makers\n6\n2. AI essentials for policy-makers\n2.1 The interdisciplinary nature of AI\nThe term ‘artificial intelligence’ was first used at a 1956 workshop held at Dartmouth \nCollege, a US Ivy League university, to describe the \"science and engineering of making \nintelligent machines, especially intelligent computer programs\" (McCarthy et al., 2006, \np. 2)1. Over the following decades, AI developed in fits and starts, with periods of rapid \nprogress interspersed with AI winters (Russell and Norvig, 2016). All the while, definitions of AI multiplied and expanded, often \nbecoming entangled with the philosophical questions of what \nconstitutes ‘intelligence’ and whether machines can ever really \nbe ‘intelligent’. To give just one example, Zhong defined AI as \na branch of modern science and technology aiming at the \nexploration of the secrets of human intelligence on one \nhand and the transplantation of human intelligence to \nmachines as much as possible on the other hand, so that machines \nwould be able to perform functions as intelligently as they can. (Zhong, 2006, p. 90)\nPragmatically sidestepping this long-running debate, for the \npurpose of this publication AI might be defined as computer \nsystems that have been designed \nto interact with the world through \ncapabilities that we usually think \nof as human (Luckin et al., 2016). More detail is given by UNESCO's \nWorld Commission on the Ethics of \nScientific Knowledge and Technology \n(COMEST), who describe AI as \ninvolving \nmachines capable of imitating \ncertain functionalities of \nhuman intelligence, including \nsuch features as perception, learning, \nreasoning, problem solving, language \ninteraction, and even producing creative \nwork. (COMEST, 2019)\nCurrently, we are experiencing an AI \nrenaissance, with an ever-increasing \nrange of sectors adopting the type \nof AI known as machine learning, \nwhich involves the AI system \nanalysing huge amounts of data. This has come about as a result \nof two critical developments: the \nexponential growth of data (IBM has \ncalculated that, due to the Internet \nand related technologies, more than \n2.5 quintillion2 bytes of data are created every day) and the \nexponential growth of computer processing power (because \nof Moore’s law, today’s mobile phones are as powerful as \nsupercomputers were 40 years ago)."
  },
  {
    "id": "71034a0b-50b6-48f4-a2a8-680923912417",
    "filename": "documents\\376709eng.pdf",
    "page_number": 9,
    "chunk_id": "9_1",
    "chunk_text": "(Zhong, 2006, p. 90)\nPragmatically sidestepping this long-running debate, for the \npurpose of this publication AI might be defined as computer \nsystems that have been designed \nto interact with the world through \ncapabilities that we usually think \nof as human (Luckin et al., 2016). More detail is given by UNESCO's \nWorld Commission on the Ethics of \nScientific Knowledge and Technology \n(COMEST), who describe AI as \ninvolving \nmachines capable of imitating \ncertain functionalities of \nhuman intelligence, including \nsuch features as perception, learning, \nreasoning, problem solving, language \ninteraction, and even producing creative \nwork. (COMEST, 2019)\nCurrently, we are experiencing an AI \nrenaissance, with an ever-increasing \nrange of sectors adopting the type \nof AI known as machine learning, \nwhich involves the AI system \nanalysing huge amounts of data. This has come about as a result \nof two critical developments: the \nexponential growth of data (IBM has \ncalculated that, due to the Internet \nand related technologies, more than \n2.5 quintillion2 bytes of data are created every day) and the \nexponential growth of computer processing power (because \nof Moore’s law, today’s mobile phones are as powerful as \nsupercomputers were 40 years ago). Big data and powerful \ncomputers have both been essential to the successes of \nmachine learning because its algorithms depend on the \nprocessing of millions of data points which, in turn, requires \nenormous amounts of computer power.3\nInterestingly, the machine learning algorithms that are \ngenerating the most headlines – ‘deep learning’ and \n‘neural networks’ – have themselves been around for more \nthan 40 years. The recent dramatic achievements of AI \nand its disruptive potential have come about because of \nTABLE 1: AI-AS-A-SERVICE EXAMPLES\nTECHNOLOGY  \nCOMPANY\n‘AI AS A  \nSERVICE’  \nPLATFORM\nCOMPANY’S  \nDESCRIPTION\nAlibaba \nCloud\nCloud-based AI tools to support the demands of businesses, websites, or \napplications: https://www.alibabacloud.com\nAmazon \nAWS\nPre-trained AI service for computer vision, language, recommendations, and \nforecasting."
  },
  {
    "id": "84fa9006-6f6d-48db-a2eb-27bc14224b09",
    "filename": "documents\\376709eng.pdf",
    "page_number": 9,
    "chunk_id": "9_2",
    "chunk_text": "More detail is given by UNESCO's \nWorld Commission on the Ethics of \nScientific Knowledge and Technology \n(COMEST), who describe AI as \ninvolving \nmachines capable of imitating \ncertain functionalities of \nhuman intelligence, including \nsuch features as perception, learning, \nreasoning, problem solving, language \ninteraction, and even producing creative \nwork. (COMEST, 2019)\nCurrently, we are experiencing an AI \nrenaissance, with an ever-increasing \nrange of sectors adopting the type \nof AI known as machine learning, \nwhich involves the AI system \nanalysing huge amounts of data. This has come about as a result \nof two critical developments: the \nexponential growth of data (IBM has \ncalculated that, due to the Internet \nand related technologies, more than \n2.5 quintillion2 bytes of data are created every day) and the \nexponential growth of computer processing power (because \nof Moore’s law, today’s mobile phones are as powerful as \nsupercomputers were 40 years ago). Big data and powerful \ncomputers have both been essential to the successes of \nmachine learning because its algorithms depend on the \nprocessing of millions of data points which, in turn, requires \nenormous amounts of computer power.3\nInterestingly, the machine learning algorithms that are \ngenerating the most headlines – ‘deep learning’ and \n‘neural networks’ – have themselves been around for more \nthan 40 years. The recent dramatic achievements of AI \nand its disruptive potential have come about because of \nTABLE 1: AI-AS-A-SERVICE EXAMPLES\nTECHNOLOGY  \nCOMPANY\n‘AI AS A  \nSERVICE’  \nPLATFORM\nCOMPANY’S  \nDESCRIPTION\nAlibaba \nCloud\nCloud-based AI tools to support the demands of businesses, websites, or \napplications: https://www.alibabacloud.com\nAmazon \nAWS\nPre-trained AI service for computer vision, language, recommendations, and \nforecasting. It can quickly build, train and deploy machine learning models \nat scale or build custom models with support for all the popular open-source \nframeworks: https://aws.amazon.com/machine-learning\nBaidu \nEasyDL\nSupports customers to build high-quality customized AI models without having \nto code: https://ai.baidu.com/easydl\nGoogle \nTensorFlow\nAn end-to-end open-source platform for machine learning, including an \necosystem of tools, libraries and community resources that enables researchers to \nshare the state-of-the-art in machine learning and developers to easily build and \ndeploy machine-learning-powered applications: https://www.tensorflow.org\nIBM \nWatson\nAllows users to bring AI tools and apps to the data wherever it resides regardless \nof the host platform: https://www.ibm.com/watson\nMicrosoft \nAzure\nIncludes more than 100 services to build, deploy and manage \napplications: https://azure.microsoft.com\nTencent \nWeStart\nMaps AI capabilities, professional talent and industry resources to support the \nlaunch or enhancements of start-ups."
  },
  {
    "id": "7f817053-195a-4aab-b1b7-dc92a0f0453c",
    "filename": "documents\\376709eng.pdf",
    "page_number": 9,
    "chunk_id": "9_3",
    "chunk_text": "(COMEST, 2019)\nCurrently, we are experiencing an AI \nrenaissance, with an ever-increasing \nrange of sectors adopting the type \nof AI known as machine learning, \nwhich involves the AI system \nanalysing huge amounts of data. This has come about as a result \nof two critical developments: the \nexponential growth of data (IBM has \ncalculated that, due to the Internet \nand related technologies, more than \n2.5 quintillion2 bytes of data are created every day) and the \nexponential growth of computer processing power (because \nof Moore’s law, today’s mobile phones are as powerful as \nsupercomputers were 40 years ago). Big data and powerful \ncomputers have both been essential to the successes of \nmachine learning because its algorithms depend on the \nprocessing of millions of data points which, in turn, requires \nenormous amounts of computer power.3\nInterestingly, the machine learning algorithms that are \ngenerating the most headlines – ‘deep learning’ and \n‘neural networks’ – have themselves been around for more \nthan 40 years. The recent dramatic achievements of AI \nand its disruptive potential have come about because of \nTABLE 1: AI-AS-A-SERVICE EXAMPLES\nTECHNOLOGY  \nCOMPANY\n‘AI AS A  \nSERVICE’  \nPLATFORM\nCOMPANY’S  \nDESCRIPTION\nAlibaba \nCloud\nCloud-based AI tools to support the demands of businesses, websites, or \napplications: https://www.alibabacloud.com\nAmazon \nAWS\nPre-trained AI service for computer vision, language, recommendations, and \nforecasting. It can quickly build, train and deploy machine learning models \nat scale or build custom models with support for all the popular open-source \nframeworks: https://aws.amazon.com/machine-learning\nBaidu \nEasyDL\nSupports customers to build high-quality customized AI models without having \nto code: https://ai.baidu.com/easydl\nGoogle \nTensorFlow\nAn end-to-end open-source platform for machine learning, including an \necosystem of tools, libraries and community resources that enables researchers to \nshare the state-of-the-art in machine learning and developers to easily build and \ndeploy machine-learning-powered applications: https://www.tensorflow.org\nIBM \nWatson\nAllows users to bring AI tools and apps to the data wherever it resides regardless \nof the host platform: https://www.ibm.com/watson\nMicrosoft \nAzure\nIncludes more than 100 services to build, deploy and manage \napplications: https://azure.microsoft.com\nTencent \nWeStart\nMaps AI capabilities, professional talent and industry resources to support the \nlaunch or enhancements of start-ups. It connects industry partners, disseminates \nand applies AI technology in different industry sectors:  \nhttps://westart.tencent.com/ai\nAlmost all of the world’s big technology companies, and many others, now offer sophisticated ‘AI-as-a-service’ \nplatforms, some of which are open-source. These provide various AI building-blocks that the developers can \nimplement without having to write AI algorithms from scratch."
  },
  {
    "id": "41c3c5b8-2b60-4acd-8f99-31ee81dfbd0f",
    "filename": "documents\\376709eng.pdf",
    "page_number": 10,
    "chunk_id": "10_0",
    "chunk_text": "AI essentials for policy-makers – AI and education: Guidance for policy-makers \n7\nsophisticated refinements of these algorithms, together \nwith their easy availability ‘as a service’,  rather than because \nof any fundamental new paradigm. In other words, it \nmight be argued that currently we are in the ‘age of \nimplementation’: \nMuch of the difficult but abstract work of AI research has \nbeen done… the age of implementation means we will \nfinally see real-world applications. (Lee, 2018, p. 13)\nReal-world applications of AI are becoming increasingly \npervasive and disruptive, with well-known examples \nranging from automatic translation between languages \nand automatic facial recognition, used for identifying \ntravellers and tracking criminals, to self-driving vehicles \nand personal assistants on smartphones and other devices \nin our daily life. One particularly noteworthy area is health \ncare. A recent transformative example is the application of \nAI to develop a novel drug capable of killing many species \nof antibiotic-resistant bacteria (Trafton, 2020). A second \nexample is the application of AI to analyse medical imaging \n– including foetal brain scans to give an early indication of \nabnormalities,4 retinal scans to diagnose diabetes,5 and x-rays \nto improve tumour detection.6 Together, these examples \nillustrate the potentially significant benefits of AI and humans \nworking in symbiosis:\nWhen we combine AI-based imaging technologies \ntogether with radiologists, what we have found is that \nthe combination of the AI technology and the radiologist \noutperforms either the AI or the radiologist by themselves. (Michael \nBrady, Professor of Oncology, University of Oxford, quoted in MIT \nTechnology Review and GE Healthcare, 2019)\nThis recent review further suggested that the application of \nAI technologies may actually be ‘re-humanizing’ health care:\nThe growth of AI and automated processes often creates \nconcerns that the human touch will be removed from the \nhealth-care delivery process. What the industry \nis finding, however, is [that] the opposite is becoming true: AI can \nextend the resources and capabilities of overworked health-care \nprofessionals and vastly improve processes."
  },
  {
    "id": "af8e9623-2b79-4f14-ab39-b8874e755b5a",
    "filename": "documents\\376709eng.pdf",
    "page_number": 10,
    "chunk_id": "10_1",
    "chunk_text": "One particularly noteworthy area is health \ncare. A recent transformative example is the application of \nAI to develop a novel drug capable of killing many species \nof antibiotic-resistant bacteria (Trafton, 2020). A second \nexample is the application of AI to analyse medical imaging \n– including foetal brain scans to give an early indication of \nabnormalities,4 retinal scans to diagnose diabetes,5 and x-rays \nto improve tumour detection.6 Together, these examples \nillustrate the potentially significant benefits of AI and humans \nworking in symbiosis:\nWhen we combine AI-based imaging technologies \ntogether with radiologists, what we have found is that \nthe combination of the AI technology and the radiologist \noutperforms either the AI or the radiologist by themselves. (Michael \nBrady, Professor of Oncology, University of Oxford, quoted in MIT \nTechnology Review and GE Healthcare, 2019)\nThis recent review further suggested that the application of \nAI technologies may actually be ‘re-humanizing’ health care:\nThe growth of AI and automated processes often creates \nconcerns that the human touch will be removed from the \nhealth-care delivery process. What the industry \nis finding, however, is [that] the opposite is becoming true: AI can \nextend the resources and capabilities of overworked health-care \nprofessionals and vastly improve processes. (MIT Technology Review \nand GE Healthcare, 2019)\nOther increasingly common applications of AI include:\n \n Auto-journalism  \nAI agents continually monitoring global news outlets \nand extracting key information for journalists, and also \nautomatically writing some simple stories;\n \n AI legal services  \nFor example, providing automatic discovery tools, researching \ncase law and statutes, and performing legal due diligence;\n \n AI weather forecasting  \nMining and automatically analysing vast amounts of \nhistorical meteorological data, in order to make predictions;\n \n AI fraud detection  \nAutomatically monitoring credit card usage, to \nidentify patterns and anomalies (i.e. potentially \nfraudulent transactions);\n \n AI-driven business processes  \nFor example, autonomous manufacturing, market analysis, \nstock trading, and portfolio management;\n \n Smart cities  \nUsing AI and the interconnected Internet of Things (IoT) to \nimprove efficiency and sustainability for people living and \nworking in urban settings; and\n \n AI robots  \nPhysical machines that use AI techniques, such as machine \nvision and reinforcement learning, to help them interact \nwith the world. While each of these examples have significant positive \npotential for society, we should not neglect to point out \nthat other applications of AI are more controversial."
  },
  {
    "id": "c1296a63-e33e-40e5-a0e6-ad2eb1db452a",
    "filename": "documents\\376709eng.pdf",
    "page_number": 10,
    "chunk_id": "10_2",
    "chunk_text": "(Michael \nBrady, Professor of Oncology, University of Oxford, quoted in MIT \nTechnology Review and GE Healthcare, 2019)\nThis recent review further suggested that the application of \nAI technologies may actually be ‘re-humanizing’ health care:\nThe growth of AI and automated processes often creates \nconcerns that the human touch will be removed from the \nhealth-care delivery process. What the industry \nis finding, however, is [that] the opposite is becoming true: AI can \nextend the resources and capabilities of overworked health-care \nprofessionals and vastly improve processes. (MIT Technology Review \nand GE Healthcare, 2019)\nOther increasingly common applications of AI include:\n \n Auto-journalism  \nAI agents continually monitoring global news outlets \nand extracting key information for journalists, and also \nautomatically writing some simple stories;\n \n AI legal services  \nFor example, providing automatic discovery tools, researching \ncase law and statutes, and performing legal due diligence;\n \n AI weather forecasting  \nMining and automatically analysing vast amounts of \nhistorical meteorological data, in order to make predictions;\n \n AI fraud detection  \nAutomatically monitoring credit card usage, to \nidentify patterns and anomalies (i.e. potentially \nfraudulent transactions);\n \n AI-driven business processes  \nFor example, autonomous manufacturing, market analysis, \nstock trading, and portfolio management;\n \n Smart cities  \nUsing AI and the interconnected Internet of Things (IoT) to \nimprove efficiency and sustainability for people living and \nworking in urban settings; and\n \n AI robots  \nPhysical machines that use AI techniques, such as machine \nvision and reinforcement learning, to help them interact \nwith the world. While each of these examples have significant positive \npotential for society, we should not neglect to point out \nthat other applications of AI are more controversial. Two \nexamples are:\n \n Autonomous warfare  \nWeapons, drones and other military equipment that function \nwithout human intervention; and\n \n Deep-fakes  \nAutomatic generation of fake news, and the replacement of \nfaces in videos so that politicians and celebrities appear to \nsay or do things they never said or did. In addition, we should also be careful when evaluating \nmany of the dramatic claims made by some AI companies \nand the media. To begin with, despite headlines \nannouncing that AI tools are now ‘better’ than humans \nat tasks such as reading texts and identifying objects in \nimages, the reality is that these successes are only true in \nlimited circumstances – for example, when the text is short \nand contains enough required information for inference to \nbe unnecessary. Current AI technologies can also be very \nbrittle."
  },
  {
    "id": "6ccc93a2-6012-44ea-b102-84247523c682",
    "filename": "documents\\376709eng.pdf",
    "page_number": 10,
    "chunk_id": "10_3",
    "chunk_text": "While each of these examples have significant positive \npotential for society, we should not neglect to point out \nthat other applications of AI are more controversial. Two \nexamples are:\n \n Autonomous warfare  \nWeapons, drones and other military equipment that function \nwithout human intervention; and\n \n Deep-fakes  \nAutomatic generation of fake news, and the replacement of \nfaces in videos so that politicians and celebrities appear to \nsay or do things they never said or did. In addition, we should also be careful when evaluating \nmany of the dramatic claims made by some AI companies \nand the media. To begin with, despite headlines \nannouncing that AI tools are now ‘better’ than humans \nat tasks such as reading texts and identifying objects in \nimages, the reality is that these successes are only true in \nlimited circumstances – for example, when the text is short \nand contains enough required information for inference to \nbe unnecessary. Current AI technologies can also be very \nbrittle. If the data is subtly altered, for example, if some \nrandom noise is superimposed on an image, the AI tool can \nfail badly (Marcus and Davis, 2019).7"
  },
  {
    "id": "f75f7f20-fd95-455a-b7d3-d76743422ee2",
    "filename": "documents\\376709eng.pdf",
    "page_number": 11,
    "chunk_id": "11_0",
    "chunk_text": "AI and education: Guidance for policy-makers – AI essentials for policy-makers\n8\n2.2 A brief introduction to AI techniques\nEach application of AI depends on a range of complex techniques, which require AI engineers \nto be trained in higher-level mathematics, statistics and other data sciences, as well as \ncoding. Therefore, these techniques are too specialized to explore in depth here.8 Instead, we \nwill briefly introduce some core AI techniques, followed by some typical AI technologies. Classical AI\nMuch early or ‘classical AI’, variously known as ‘symbolic AI’, \n‘rule-based AI’, or ‘good-old-fashioned AI’ (‘GOFAI’), involves \nwriting sequences of IF... THEN... and other rules of conditional \nlogic, steps that the computer will take to complete a task. Over decades, rule-based AI ‘expert systems’ were developed \nfor a diverse range of applications, such as medical diagnostics, \ncredit ratings, and manufacturing. Expert systems are based \non an approach known as ‘knowledge engineering’, which \ninvolves eliciting and modelling the knowledge of experts in a \nspecific domain, a resource-intensive task that is not without \ncomplications. Typical expert systems contain many hundreds \nof rules, yet it is usually possible to follow their logic. However, as \nthe interactions between the rules multiply, expert systems can \nbecome challenging to revise or enhance. Machine learning\nMany recent AI advances – including natural language \nprocessing, facial recognition, and self-driving cars – have \nbeen made possible by advances in machine-learning-based \ncomputational approaches. Rather than using rules, machine \nlearning (ML) analyses large amounts of data to identify \npatterns and build a model which is then used to predict future \nvalues. It is in this sense that the algorithms, rather than being \npre-programmed, are said to be ‘learning’. There are three main ML approaches: supervised, unsupervised, \nand reinforcement. Supervised learning involves data that has \nalready been labelled – such as many thousands of photographs \nof people that have been labelled by humans. The supervised \nlearning links the data to the labels, to build a model that can be \napplied to similar data – for example, to automatically identify \npeople in new photographs. In unsupervised learning, the AI \nis provided with even larger amounts of data, but this time the \ndata has not been categorized or labelled. The unsupervised \nlearning aims to uncover hidden patterns in the data, clusters \nthat can be used to classify new data."
  },
  {
    "id": "a17c58f0-6125-4c36-b7c4-5c3dc83d8f16",
    "filename": "documents\\376709eng.pdf",
    "page_number": 11,
    "chunk_id": "11_1",
    "chunk_text": "There are three main ML approaches: supervised, unsupervised, \nand reinforcement. Supervised learning involves data that has \nalready been labelled – such as many thousands of photographs \nof people that have been labelled by humans. The supervised \nlearning links the data to the labels, to build a model that can be \napplied to similar data – for example, to automatically identify \npeople in new photographs. In unsupervised learning, the AI \nis provided with even larger amounts of data, but this time the \ndata has not been categorized or labelled. The unsupervised \nlearning aims to uncover hidden patterns in the data, clusters \nthat can be used to classify new data. For example, it may \nautomatically identify letters and numbers in handwriting by \nlooking for patterns in thousands of examples. In both supervised and unsupervised learning, the model \nderived from the data is fixed, and if the data changes, the \nanalysis has to be undertaken again. However, the third ML \napproach, reinforcement learning, involves continuously \nimproving the model based on feedback – in other words, this \nis machine learning in the sense that the learning is ongoing. The AI is provided with some initial data from which it derives a \nmodel, which is assessed as correct or incorrect and rewarded \nor punished accordingly. The AI uses this reinforcement to \nupdate its model and then it tries again, thus developing \niteratively (learning and evolving) over time. For example, if an \nautonomous car avoids a collision, the model that enabled it \nto do so is rewarded (reinforced), enhancing its ability to avoid \ncollisions in the future. ML is so widespread today that it is sometimes thought to be \nsynonymous with AI, whereas it is actually a subset of AI. In fact, \nthere are still many AI applications that do not use ML, or at \nleast there is almost always some GOFAI (rule-based or symbolic \nAI) in the background. For example, many common chatbot \napplications are pre-programmed with human-defined rules \nabout how to reply to anticipated questions. In fact, like the \nearlier expert systems, \nAlmost every AI product that you see today needs content \ninserted directly by human experts. This may be expertise \nharvested from linguists and phoneticians if the AI is using \nnatural language processing, from physicians in cases where the AI is \nused in medicine, or perhaps even from experts in road traffic and \ndriving when the AI powers self-driving cars, and so on."
  },
  {
    "id": "82685e32-b9a3-49d5-be09-8ded978385b8",
    "filename": "documents\\376709eng.pdf",
    "page_number": 11,
    "chunk_id": "11_2",
    "chunk_text": "ML is so widespread today that it is sometimes thought to be \nsynonymous with AI, whereas it is actually a subset of AI. In fact, \nthere are still many AI applications that do not use ML, or at \nleast there is almost always some GOFAI (rule-based or symbolic \nAI) in the background. For example, many common chatbot \napplications are pre-programmed with human-defined rules \nabout how to reply to anticipated questions. In fact, like the \nearlier expert systems, \nAlmost every AI product that you see today needs content \ninserted directly by human experts. This may be expertise \nharvested from linguists and phoneticians if the AI is using \nnatural language processing, from physicians in cases where the AI is \nused in medicine, or perhaps even from experts in road traffic and \ndriving when the AI powers self-driving cars, and so on. Machine \nlearning could not create a full AI without the assistance of GOFAI \ncomponents. (Säuberlich and Nikolić, 2018)\nFurthermore, it is important to recognize that ML does not \nreally learn in the sense that a human learns. Nor does it learn \nindependently. Instead, ML is entirely dependent on humans: \nthey choose, clean, and label the data; design and train the AI \nalgorithm; and curate, interpret, and make value judgements \nabout the outputs. For example, a breakthrough object-\nrecognition tool was said to identify pictures of cats in a database \nFIGURE 1: THE RELATIONSHIP BETWEEN ARTIFICIAL INTELLIGENCE, \nMACHINE LEARNING, NEURAL NETWORKS AND DEEP LEARNING. Deep Learning\nNeural Networks\nMachine Learning\nArtificial Intelligence"
  },
  {
    "id": "f76a15bd-9c73-4b07-89bd-c96eadc63e6f",
    "filename": "documents\\376709eng.pdf",
    "page_number": 12,
    "chunk_id": "12_0",
    "chunk_text": "AI essentials for policy-makers – AI and education: Guidance for policy-makers \n9\nof images, but actually the system only grouped together \nobjects that looked somehow similar, and it required a human to \nidentify one set of those objects as cats. Similarly, the ML used in \nautonomous vehicles depends entirely on millions of images of \nstreet scenes being labelled by humans. To a large extent, Silicon \nValley has outsourced this labelling to people around the world \n(using systems like Amazon Mechanical Turk)9 and to companies \nin countries such as India, Kenya, Philippines and Ukraine.10 The \njob of these new-economy workers is to trace by hand and label \neach object (such as vehicles, road signs, and pedestrians) in \neach frame of video captured by prototype autonomous vehicles \n– data that the ML algorithm then analyses. Artificial neural networks\nAn artificial neural network (ANN) is an AI approach that is \ninspired by the structure of biological neural networks (i.e. animal \nbrains). ANNs each comprise three types of interconnected \nlayers of artificial neurons: an input layer, one or more hidden \nintermediary computational layers, and an output layer that \ndelivers the result. During the ML process, weightings given to \nthe connections between the neurons are adjusted in a process of \nreinforcement learning and ‘back propagation’, which allows the \nANN to compute outputs for new data. A well-known example \nthat uses an ANN is Google’s AlphaGo, which in 2016 defeated the \nworld’s leading player of the game Go. The hidden layers are the key to the power of ANNs, but they \nalso bring an important constraint. It is usually not possible \nto interrogate a deep neural network to determine how it \narrived at its solution. This leads to decision-making for which \nthe rationale is unknowable. Many companies are researching \nways in which such decisions can be opened up for inspection \n(Burt, 2019), so that users might understand why a given \nalgorithm reached a particular decision – which is especially \nimportant when ANNs and other ML techniques are being used \nto make decisions that impact significantly on humans, such as \nhow much time someone should remain in prison. However, \nas usual, this again complicates matters: \"generating more \ninformation about AI decisions might create real benefits, [but] \nit may also create new risks\" (Burt, 2019). Deep learning\nDeep learning refers to ANNs that comprise multiple \nintermediary layers."
  },
  {
    "id": "de5559cd-ce5a-4c1b-a7f5-e99eaed6e80c",
    "filename": "documents\\376709eng.pdf",
    "page_number": 12,
    "chunk_id": "12_1",
    "chunk_text": "It is usually not possible \nto interrogate a deep neural network to determine how it \narrived at its solution. This leads to decision-making for which \nthe rationale is unknowable. Many companies are researching \nways in which such decisions can be opened up for inspection \n(Burt, 2019), so that users might understand why a given \nalgorithm reached a particular decision – which is especially \nimportant when ANNs and other ML techniques are being used \nto make decisions that impact significantly on humans, such as \nhow much time someone should remain in prison. However, \nas usual, this again complicates matters: \"generating more \ninformation about AI decisions might create real benefits, [but] \nit may also create new risks\" (Burt, 2019). Deep learning\nDeep learning refers to ANNs that comprise multiple \nintermediary layers. It is this approach that has led to many of \nthe recent remarkable applications of AI (for example, in natural \nlanguage processing, speech recognition, computer vision, \nimage creation, drug discovery, and genomics). Emerging \nmodels in deep learning include so-called ‘deep neural \nnetworks’ (DNN), which find effective mathematical operations \nto turn an input into the required output; ‘recurrent neural \nnetworks’ (RNN), which allow data to flow in any direction, can \nprocess sequences of inputs, and are used for applications such \nas language modelling; and ‘convolutional neural networks’ \n(CNN), which process data that come in the form of multiple \narrays, such as using three two-dimensional images to enable \nthree-dimensional computer vision. Finally, it is worth noting that many recent advances, especially \nthose centred on image manipulation, have been achieved by \nwhat are called ‘generative adversarial networks’ (GANs). In a \nGAN, two deep neural networks compete against each other \n– one ‘generative network’ that creates possible outputs and \none ‘discriminative network’ that evaluates those outputs. The \noutcome informs the next iteration. For example, DeepMind’s \nAlphaZero used a GAN approach to learn how to play and win a \nnumber of board games (Dong et al., 2017). Meanwhile, a GAN \ntrained on photographs has generated images of people who \nlook real but do not exist.11 Other applications of this approach \nare currently being studied. 2.3 A brief introduction to AI technologies\nTogether, all of the AI techniques described above have led \nto a range of AI technologies, which are increasingly being \noffered ‘as a service’ (see Table 1), and are being used in most \nof the aforementioned applications."
  },
  {
    "id": "1cb31d3c-7487-45a0-a842-51a3302694f9",
    "filename": "documents\\376709eng.pdf",
    "page_number": 12,
    "chunk_id": "12_2",
    "chunk_text": "In a \nGAN, two deep neural networks compete against each other \n– one ‘generative network’ that creates possible outputs and \none ‘discriminative network’ that evaluates those outputs. The \noutcome informs the next iteration. For example, DeepMind’s \nAlphaZero used a GAN approach to learn how to play and win a \nnumber of board games (Dong et al., 2017). Meanwhile, a GAN \ntrained on photographs has generated images of people who \nlook real but do not exist.11 Other applications of this approach \nare currently being studied. 2.3 A brief introduction to AI technologies\nTogether, all of the AI techniques described above have led \nto a range of AI technologies, which are increasingly being \noffered ‘as a service’ (see Table 1), and are being used in most \nof the aforementioned applications. AI technologies, which are \ndetailed in Table 2, include the following:\n \n Natural language processing (NLP) \nThe use of AI to automatically interpret texts, including \nsemantic analysis (as used in legal services and translation), and \ngenerate texts (as in auto-journalism).  Speech recognition: \nThe application of NLP to spoken words, including \nsmartphones, AI personal assistants, and conversational bots in \nbanking services.  Image recognition and processing  \nThe use of AI for facial recognition (e.g. for electronic \npassports); handwriting recognition (e.g. for automated \npostal sorting); image manipulation (e.g. for deep-fakes); and \nautonomous vehicles.  Autonomous agents \nThe use of AI in computer game avatars, malicious \nsoftware bots, virtual companions, smart robots, and \nautonomous warfare.  Affect detection \nThe use of AI to analyse sentiment in text, behaviour and faces.  Data mining for prediction \nThe use of AI for medical diagnoses, weather forecasting, \nbusiness projections, smart cities, financial predictions, and \nfraud detection.  Artificial creativity \nThe use of AI in systems that can create new photographs, \nmusic, artwork, or stories."
  },
  {
    "id": "36681c4a-5153-4464-a4aa-ae242daede89",
    "filename": "documents\\376709eng.pdf",
    "page_number": 13,
    "chunk_id": "13_0",
    "chunk_text": "AI and education: Guidance for policy-makers – AI essentials for policy-makers\n10\nTABLE 2: AI TECHNOLOGIES\nTECHNOLOGY\nDETAILS\nMAIN AI TECHNIQUES\nDEVELOPMENT\nEXAMPLES\nNatural language \nprocessing (NLP)\nAI to automatically generate texts (as in \nauto-journalism), and interpret texts, \nincluding semantic analysis (as used in \nlegal services and translation). Machine learning (especially deep \nlearning), regression, and K-means. NLP, speech recognition, and image \nrecognition have all achieved accuracy \nin excess of 90%. However, some \nresearchers argue that, even with more \ndata and faster processors, this will \nnot be much improved until a new AI \nparadigm is developed. Otter12 \nSpeech recognition\nNLP applied to spoken words, including \nsmartphones, personal assistants, and \nconversational bots in banking services. Machine learning, especially a deep \nlearning recurrent neural network \napproach called long short-term \nmemory (LSTM). Alibaba Cloud13 \nImage recognition \nand processing\nIncludes facial recognition (e.g. for \ne-passports); handwriting recognition \n(e.g. for automated postal sorting); \nimage manipulation (e.g. for deep-\nfakes); and autonomous vehicles. Machine learning, especially deep \nlearning convolutional neural networks. Google Lens14 \nAutonomous agents\nIncludes computer game avatars, \nmalicious software bots, virtual \ncompanions, smart robots, and \nautonomous warfare. GOFAI and machine learning (for \nexample, deep learning self-organizing \nneural networks, evolutionary learning \nand reinforcement learning). Research efforts are focusing on \nemergent intelligence, coordinated \nactivity, situatedness, and physical \nembodiment, inspired by simpler forms \nof biological life. Woebot15 \nAffect detection\nIncludes text, behaviour and facial \nsentiment analyses. Bayesian networks and machine \nlearning, especially deep learning. Multiple products are being developed \nglobally; however, their use is \noften controversial. Affectiva16 \nData mining for prediction\nIncludes financial predictions, fraud \ndetection, medical diagnoses, weather \nforecasting, business processes and \nsmart cities. Machine learning (especially supervised \nand deep learning), Bayes networks and \nsupport vector machines. Data mining applications are growing \nexponentially, from predicting shopping \npurchases to interpreting noisy \nelectroencephalography (EEG) signals. Research project17 \nArtificial creativity\nIncludes systems that can create new \nphotographs, music, artwork, or stories. Generative adversarial networks (GANs), \na type of deep learning involving \ntwo neural networks pitted against \neach other. Autoregressive language models \nthat use deep learning to produce \nhuman-like text. GANs are at the cutting edge of AI, such \nthat future applications are only slowly \nbecoming evident. An autoregressive language model \nknown as GPT-3 can produce impressive \nhuman-like text."
  },
  {
    "id": "3493caea-bf18-4be4-9e8d-44697d7ab469",
    "filename": "documents\\376709eng.pdf",
    "page_number": 13,
    "chunk_id": "13_1",
    "chunk_text": "Research project17 \nArtificial creativity\nIncludes systems that can create new \nphotographs, music, artwork, or stories. Generative adversarial networks (GANs), \na type of deep learning involving \ntwo neural networks pitted against \neach other. Autoregressive language models \nthat use deep learning to produce \nhuman-like text. GANs are at the cutting edge of AI, such \nthat future applications are only slowly \nbecoming evident. An autoregressive language model \nknown as GPT-3 can produce impressive \nhuman-like text. However, despite \nappearances, the system does not \nunderstand the text that it outputs.18 \nThis Person Does \nNot Exist11\nGPT-3 (Brown et \nal., 2020)\n2.4 Possible trends in AI developments: ‘Weak’ and ‘strong’ AI\nWhile AI scientists started out with dreams of human-level \nartificial general intelligence (AGI), known as strong AI, each of \nthe applications in section 2.1 are in fact examples of narrow \nor weak AI (Searle, 1980). The domain in which each narrow \napplication operates is tightly constrained and limited, and the \nAI cannot be directly applied elsewhere. For example, the AI used \nto predict the weather is incapable of predicting movements in \nthe stock market, while the AI used to drive a car is incapable of \ndiagnosing a tumour. Nonetheless, although not ‘intelligent’ in a \nhuman sense, each of these applications can often outperform \nhumans in efficiency and endurance, and by its ability to identify \nsignificant patterns in huge amounts of data. Although there have been some notable successes, it is \nimportant to recognize that AI is still in its infancy. For \nexample, it is impossible to have a real conversation with \none of the personal assistants on our smartphones or other \nAI-powered household devices – instead, the AI responds \nonly, and often inaccurately, to specific commands. In other \nwords, while its performance of some functions (such as \nfinding patterns in data) is superior to that of human experts, \nin others (such as holding an in-depth conversation), AI \nperforms below the level of a two-year-old child.19 In addition, \nthere are signs from across the world that, contrary to the \nhyperbolic predictions, investment in AI technologies might \nbe cooling – not yet another AI winter, but AI’s promised \npotential all too often remains tantalisingly beyond the \nhorizon (Lucas, 2018). It has even been suggested that \nprogress in AI is soon to plateau (Marcus and Davis, 2019)."
  },
  {
    "id": "da2e2079-38ff-4fb6-8d5b-53c69419a3c5",
    "filename": "documents\\376709eng.pdf",
    "page_number": 13,
    "chunk_id": "13_2",
    "chunk_text": "Nonetheless, although not ‘intelligent’ in a \nhuman sense, each of these applications can often outperform \nhumans in efficiency and endurance, and by its ability to identify \nsignificant patterns in huge amounts of data. Although there have been some notable successes, it is \nimportant to recognize that AI is still in its infancy. For \nexample, it is impossible to have a real conversation with \none of the personal assistants on our smartphones or other \nAI-powered household devices – instead, the AI responds \nonly, and often inaccurately, to specific commands. In other \nwords, while its performance of some functions (such as \nfinding patterns in data) is superior to that of human experts, \nin others (such as holding an in-depth conversation), AI \nperforms below the level of a two-year-old child.19 In addition, \nthere are signs from across the world that, contrary to the \nhyperbolic predictions, investment in AI technologies might \nbe cooling – not yet another AI winter, but AI’s promised \npotential all too often remains tantalisingly beyond the \nhorizon (Lucas, 2018). It has even been suggested that \nprogress in AI is soon to plateau (Marcus and Davis, 2019). For \nexample, autonomous vehicles safely navigating the streets of \nPalermo or Delhi remain some decades away, while image-\nrecognition apps are still easily fooled (Mitchell, 2019)."
  },
  {
    "id": "22787b49-0376-457b-bbdb-bf1ae657a793",
    "filename": "documents\\376709eng.pdf",
    "page_number": 14,
    "chunk_id": "14_0",
    "chunk_text": "AI essentials for policy-makers – AI and education: Guidance for policy-makers \n11\n2.5 A critical view of the capabilities and limitations of AI\nIt may be useful to consider AI in terms of three basic types of \nachievement: \n \n AI technologies that represent \"genuine, rapid \ntechnological progress\", which mainly centre on ‘perception’ \n(including medical diagnosis from scans, speech to text, and \ndeep-fakes) (Narayanan, 2019);\n \n AI technologies that are \"far from perfect, but improving\", \nwhich mainly centre on automating judgements (including the \ndetection of spam and hate speech, and the recommendation \nof content) (ibid.); and \n \n AI technologies that are \"fundamentally dubious\", which \nmainly centre on predicting social outcomes (including criminal \nrecidivism and job performance) (ibid.). The key point is that, although deep neural networks have been \ntrained to complete some incredible tasks, there are many things \nthat they cannot do (Marcus and Davis, 2019). In particular, they \nare not doing anything that is genuinely intelligent. Instead, \nthey merely induce patterns through statistics. Those \npatterns may be opaquer, more mediated and more \nautomatic than historical approaches and capable of \nrepresenting more complex statistical phenomena, but they are still \nmerely mathematical incarnations, not intelligent entities, no matter \nhow spectacular their results. (Leetaru, 2018)\nFurthermore, various studies have shown that ML techniques \nthat involve thousands of data variables or features, and \ntherefore require large amounts of resources and energy to \ncompute, can be little better than a simple linear regression that \nuses only a few features and much less energy (Narayanan, 2019). Nonetheless, what does distinguish today’s AI from previous \ntechnological revolutions is the speed at which it has developed, \nleading to novel technologies and transformative approaches \nemerging almost every day, and its pervasiveness, impacting on \nalmost every aspect of modern life. To give just one impressive \nexample, researchers have developed an AI system using a trio \nof deep-learning networks that outperforms human experts in \nbreast cancer prediction (McKinney et al., 2020). In any case, there is some evidence that in many contexts the \nsuccesses of ML have been slightly exaggerated, and that the \nrapid improvements we have seen are possibly hitting a ceiling."
  },
  {
    "id": "d18031c2-c110-4cf8-a0bc-6c1b51b5bf46",
    "filename": "documents\\376709eng.pdf",
    "page_number": 14,
    "chunk_id": "14_1",
    "chunk_text": "Those \npatterns may be opaquer, more mediated and more \nautomatic than historical approaches and capable of \nrepresenting more complex statistical phenomena, but they are still \nmerely mathematical incarnations, not intelligent entities, no matter \nhow spectacular their results. (Leetaru, 2018)\nFurthermore, various studies have shown that ML techniques \nthat involve thousands of data variables or features, and \ntherefore require large amounts of resources and energy to \ncompute, can be little better than a simple linear regression that \nuses only a few features and much less energy (Narayanan, 2019). Nonetheless, what does distinguish today’s AI from previous \ntechnological revolutions is the speed at which it has developed, \nleading to novel technologies and transformative approaches \nemerging almost every day, and its pervasiveness, impacting on \nalmost every aspect of modern life. To give just one impressive \nexample, researchers have developed an AI system using a trio \nof deep-learning networks that outperforms human experts in \nbreast cancer prediction (McKinney et al., 2020). In any case, there is some evidence that in many contexts the \nsuccesses of ML have been slightly exaggerated, and that the \nrapid improvements we have seen are possibly hitting a ceiling. For example, despite some extraordinary achievements, claims \nthat ML is now as accurate as humans in identifying objects \nin pictures have two key limitations: they depend on (i) the \nsystem having access to millions of labelled images, whereas \na young child only needs a few such images to reach the same \nlevel of accuracy; and (ii) a loose interpretation of accuracy (in \none of the most publicized machine-vision competitions, an \nAI tool is deemed successful if just one of its five suggestions is \ncorrect) (Mitchell, 2019). In addition, as noted earlier, all of the \ntechniques that are currently fuelling the major advances in AI \n(such as deep neural networks and ML) were first developed \nseveral decades ago. In other words, while we continue to \nsee iterative refinements of existing techniques and new \napplications, we are still waiting for the next big breakthrough. Some experts argue that this will only happen when the \nsymbolic or rule-based techniques of so-called classical AI or \nGOFAI are combined with the data-driven techniques. This \nalready happens in, for example, autonomous vehicles:\nThere are things that intelligent agents need to do that \ndeep learning is not currently very good at. It’s not very \ngood at abstract inference."
  },
  {
    "id": "f1feeba2-5f8b-441d-8903-d352ca7e7fd0",
    "filename": "documents\\376709eng.pdf",
    "page_number": 14,
    "chunk_id": "14_2",
    "chunk_text": "In addition, as noted earlier, all of the \ntechniques that are currently fuelling the major advances in AI \n(such as deep neural networks and ML) were first developed \nseveral decades ago. In other words, while we continue to \nsee iterative refinements of existing techniques and new \napplications, we are still waiting for the next big breakthrough. Some experts argue that this will only happen when the \nsymbolic or rule-based techniques of so-called classical AI or \nGOFAI are combined with the data-driven techniques. This \nalready happens in, for example, autonomous vehicles:\nThere are things that intelligent agents need to do that \ndeep learning is not currently very good at. It’s not very \ngood at abstract inference. It’s also not very good at \nhandling situations it hasn’t seen before and where it has relatively \nincomplete information. We therefore need to supplement deep \nlearning with other tools… In my view, we need to bring together \nsymbol manipulation (i.e. rule-based AI) with deep learning. They \nhave been treated separately for too long. (Marcus interviewed by \nFord, 2018, p. 318)\n2.6 Human-machine collaborative intelligence\nAI was borne of attempts to simulate and mechanize human \nthought processes (Turing, 1950), and has existed in an \nuneasy relationship with them ever since. Interestingly, while \nwe are used to reading about dramatic AI successes (ranging \nfrom defeating humans in games to reading retinal scans \nmore accurately than humans), the limitations of current \nAI approaches are becoming increasingly clear (Mitchell, \n2019). In fact, while AI has been good at processes that can \nbe challenging for humans (such as pattern discovery and \nstatistical reasoning), it remains weak at other processes that \nare relatively easy for humans (such as self-directed learning, \ncommon sense, and value judgements). This is known as \nMoravec’s paradox: \nIt is comparatively easy to make computers exhibit adult \nlevel performance on intelligence tests or playing \ncheckers, and difficult or impossible to give them the skills \nof a one-year-old when it comes to perception and mobility. (Moravec, 1988, p. 15)\nIn addition, as we have noted, the critical importance of \nhumans to AI successes is often glossed over. Most of the \ntime, humans are required to frame the problem; formulate \nthe questions; select, clean and label the data; design or \nchoose the algorithms; decide how the pieces fit together; \ndraw conclusions and make judgments according to values;"
  },
  {
    "id": "b4135f9b-d6d7-43d2-9b46-ec5798fee859",
    "filename": "documents\\376709eng.pdf",
    "page_number": 15,
    "chunk_id": "15_0",
    "chunk_text": "AI and education: Guidance for policy-makers – AI essentials for policy-makers\n12\nand much more besides. Accordingly, although many tasks \nare likely to be automatable, there are still key roles for \nhumans to play, for which we need to be properly prepared \n(Holmes et al., 2019). In fact, the increasingly complex and nuanced relationship \nbetween humans and AI has led to calls for AI to be re-configured \nand re-branded as ‘augmented intelligence’ (Zheng, 2017). For example, while computers can now easily beat humans at \nchess, computers and humans working together appear to be \nstronger than either working alone. In competitions, amateur \nchess players using AI have been able to beat computers \nand grandmasters alike (Brynjolfsson and McAfee, 2014). This \napproach involves using AI to enhance, rather than usurp, \nhuman capabilities. Shifting to augmented intelligence leads to \nan emphasis on developing AI technologies that complement \nand expand human cognition, suggests ways that humans and \nAI might work together more effectively, queries how tasks \nshould be divided between humans and machines, and raises \nthe tantalizing possibility that the world’s problems might be \naddressed by means of a judicious mix of artificial and collective \nintelligence (Mulgan, 2018). 2.7 The Fourth Industrial Revolution and impact of AI on employment\nAI is said to be a key enabler of the Fourth Industrial \nRevolution (Industry 4.0): \nOf the many diverse and fascinating challenges we face \ntoday, the most intense and important is how to \nunderstand and shape the new technology revolution, \nwhich entails nothing less than a transformation of humankind. (Schwab, 2017, p. 1) \nIndustry 4.0 technologies include 3D printing, \nautonomous vehicles, biotechnology, nanotechnology, \nquantum computing, robotics, and the Internet of \nThings, all of which are underpinned by AI. In fact, AI \nis already ubiquitous in the modern workplace – from \nmanufacturing to banking, construction to transport, \nand beyond – which has implications that require a \nsystem-wide response. Inevitably, there will be increases \nin both unemployment and new occupations. A recent \nglobal estimate suggests that 30% of work activities \ncould be automated by 2030. Up to 375 million workers \nworldwide could be affected. Both blue-collar workers \nand white-collar employees will be impacted, and it is not \nnecessarily the former who will bear the brunt:\nThe jobs that AI can easily replicate and replace are those \nthat require recently evolved skills like logic and algebra. They tend to be middle-income jobs."
  },
  {
    "id": "af617d83-85fa-46f6-a533-dcb84c7b7e1d",
    "filename": "documents\\376709eng.pdf",
    "page_number": 15,
    "chunk_id": "15_1",
    "chunk_text": "Inevitably, there will be increases \nin both unemployment and new occupations. A recent \nglobal estimate suggests that 30% of work activities \ncould be automated by 2030. Up to 375 million workers \nworldwide could be affected. Both blue-collar workers \nand white-collar employees will be impacted, and it is not \nnecessarily the former who will bear the brunt:\nThe jobs that AI can easily replicate and replace are those \nthat require recently evolved skills like logic and algebra. They tend to be middle-income jobs. Conversely, the jobs \nthat AI cannot easily replicate are those that rely on the deeply \nevolved skills like mobility and perception. They tend to be lower-\nincome jobs. Hence, AI is hollowing out middle-income jobs and \nmaintaining lots of lower-income jobs. (Joshi, 2017 © Courtesy of Guardian News & Media Ltd)\nMeanwhile, however, AI and other frontier technologies are \nincreasing the range of high-skill jobs that require unique creative \nand analytical abilities and human interactions. In short, many \nworkers’ jobs might disappear, and they will need to develop new \nskill sets – upskilling or reskilling – to enable them to enter the \nnew occupations made possible by AI. Education ministries and \ntraining providers need to anticipate these changes, equipping \ntoday’s workers and preparing new generations with the \nnecessary technical and social job skills, to smooth the transition \nto a world dominated by AI, while ensuring social sustainability. In fact, many national agencies across the world have begun \nto develop strategic plans to address the future of AI. For \nexample, in the United States of America, the National Artificial \nIntelligence Research and Development Strategic Plan \n(National Science and Technology Council, 2016) promotes \nlong-term investment and research in a range of theoretical \nand practical AI approaches. These include data analytics, \nAI perception, theoretical limitations, artificial general \nintelligence, scalable AI, AI-driven humanoid robotics, human-\naware AI, and human augmentation. In 2017, the Chinese \nGovernment announced its Next Generation of Artificial \nIntelligence Development Plan (Government of the People’s \nRepublic of China, 2017). Again, this focused on an array of \ntheoretical and practical AI approaches, including big-data-\nbased intelligence, cross-media intelligence, human-machine \nhybrid augmented intelligence, collective intelligence, \nautonomous intelligence, advanced machine learning, \nbrain-inspired intelligence, and quantum intelligence. Most \nimportantly, both plans emphasize the potential of seamless \ninteractions between humans and AI systems, and both aim to \nhelp realize AI’s potential social and economic benefits while \nminimizing the negative impacts."
  },
  {
    "id": "610a9f9d-7c42-4c05-910f-1d65d8167de1",
    "filename": "documents\\376709eng.pdf",
    "page_number": 16,
    "chunk_id": "16_0",
    "chunk_text": "Understanding AI and education:  Emerging practices and benefit-risk assessment – AI and education: Guidance for policy-makers \n13\n3. Understanding AI and education:  \nEmerging practices and benefit-risk assessment\nThe introduction of AI into educational contexts may be traced \nto the 1970s. At that time, researchers were interested in \nseeing how computers might substitute for one-to-one human \ntutoring, which is thought to be the most effective approach to \nteaching but is unavailable to most people (Bloom, 1984). Early \nefforts used rule-based AI techniques to automatically adapt or \npersonalize the learning to each individual learner (Carbonell, \n1970; Self, 1974). Since those beginnings, the application of AI \nin education has developed in multiple directions, beginning \nwith student-facing AI (tools designed to support learning \nand assessment) to also include teacher-facing AI (designed to \nsupport teaching) and system-facing AI (designed to support \nthe management of educational institutions) (Baker et al., 2019). In fact, the interaction between AI and education goes further, \nbeyond the application of AI within classrooms (i.e. learning \nwith AI) to teaching its techniques (i.e. learning about AI) and \npreparing citizens to live in the AI era (i.e. learning for human-AI \ncollaboration). The introduction of AI into education also shines \na spotlight on issues of pedagogy, organizational structures, \naccess, ethics, equity, and sustainability – in order to automate \nsomething, you first need to thoroughly understand it. Furthermore, if the potential of AI to support education \nfor sustainable development is to be fully realized, all of \nthe possible benefits of the tools need to be identified and \nleveraged, and the risks acknowledged and mitigated. As a \nconsequence, the ways in which education is organized also \nneed to be continuously reviewed, which might suggest \na fundamental reshaping of education’s core foundations, \ntowards the central aim of addressing SDG 4. We also need \nto question what the introduction of AI into education might \nachieve: What are the real benefits AI might bring? How do we \nensure that AI meets real needs, and is not just the latest EdTech \nfad? What should we allow AI to do? To fully unleash the opportunities and mitigate the potential \nrisks, system-wide responses to the following key policy \nquestions are needed:\n1. How can AI be leveraged to enhance education? 2. How can we ensure the ethical, inclusive and equitable use \nof AI in education? 3. How can education prepare humans to live and work \nwith AI?"
  },
  {
    "id": "cf1c29f4-3c17-40d8-822d-cce21fcba865",
    "filename": "documents\\376709eng.pdf",
    "page_number": 16,
    "chunk_id": "16_1",
    "chunk_text": "How can AI be leveraged to enhance education? 2. How can we ensure the ethical, inclusive and equitable use \nof AI in education? 3. How can education prepare humans to live and work \nwith AI? To help education systems respond to these complex \nchallenges, UNESCO, in cooperation with the Chinese \nGovernment, organized the International Conference on \nArtificial Intelligence and Education in Beijing (2019) under \nthe theme ‘Planning Education in the AI Era: Lead the Leap’. Its \nparticipants included more than 50 government ministers and \nvice-ministers, and around 500 international representatives \nfrom more than 100 Member States, United Nations agencies, \nacademic institutions, civil society and private sector \norganizations. They examined the system-wide impacts of AI \nin the context of ‘SDG 4 – Education 2030 and the Future of \nEducation Beyond 2030’. The key outcome of the conference was \nthe ‘Beijing Consensus on AI and Education’ (UNESCO, 2019a) \nwhich provides a common understanding of key issues and \npolicy recommendations relating to the three aforementioned \npolicy questions. The main recommendations made in the \nBeijing Consensus are referenced throughout this publication. The remainder of this chapter will review the main trends \nand issues affecting AI in education, as well as the benefit-risk \ndichotomy and implications for policy responses. 3.1 How can AI be leveraged to enhance education? Over the past decade, the use of AI tools to support or enhance \nlearning has grown exponentially (Holmes et al., 2019). This \nhas only increased following the COVID-19 school closures. However, evidence remains scarce on how AI can improve \nlearning outcomes and whether it can help learning scientists \nand practitioners to better understand how effective learning \nhappens (Zawacki-Richter et al., 2019). Many of the claims of the revolutionary potential of AI in \neducation are based on conjecture, speculation, and \noptimism. (Nemorin, 2021)\nFurthermore, we have yet to explore AI’s potential in the \ntracking of learning outcomes across different settings as well as \nassessing competencies, especially those acquired in non-formal \nand informal contexts. AI applications designed for education have elsewhere \nbeen divided into three main categories: system-facing, \nstudent-facing and teacher-facing (Baker et al., 2019). However, \nfor policy-makers, we propose a set of four needs-based \ncategories of emerging and potential applications: (i) education \nmanagement and delivery; (ii) learning and assessment; \n(iii) empowering teachers and enhancing teaching; and (iv) \nlifelong learning. For each of these categories, we also provide \nsome illustrative cases."
  },
  {
    "id": "8e190379-ba97-41ed-8af4-e23a801a1834",
    "filename": "documents\\376709eng.pdf",
    "page_number": 16,
    "chunk_id": "16_2",
    "chunk_text": "Many of the claims of the revolutionary potential of AI in \neducation are based on conjecture, speculation, and \noptimism. (Nemorin, 2021)\nFurthermore, we have yet to explore AI’s potential in the \ntracking of learning outcomes across different settings as well as \nassessing competencies, especially those acquired in non-formal \nand informal contexts. AI applications designed for education have elsewhere \nbeen divided into three main categories: system-facing, \nstudent-facing and teacher-facing (Baker et al., 2019). However, \nfor policy-makers, we propose a set of four needs-based \ncategories of emerging and potential applications: (i) education \nmanagement and delivery; (ii) learning and assessment; \n(iii) empowering teachers and enhancing teaching; and (iv) \nlifelong learning. For each of these categories, we also provide \nsome illustrative cases. It is important to acknowledge that \neach of the proposed categories are intrinsically interlinked; \napplications of AI in education may have the potential to \naddress needs in more than one area. For example, tutorial"
  },
  {
    "id": "9ef01689-3c73-40d0-806b-5999c4feaab9",
    "filename": "documents\\376709eng.pdf",
    "page_number": 17,
    "chunk_id": "17_0",
    "chunk_text": "AI and education: Guidance for policy-makers – Understanding AI and education: Emerging practices and benefit-risk assessment\n14\napplications are may designed with the aim of supporting \nboth teachers and students. It is also proposed that planning \nand policies for the adoption of AI technologies in educational \ncontexts should be based on immediate and long-term local \nneeds, rather than the market, and should be grounded \nin benefit-risk analyses before any of the technologies \nare adopted at scale. In particular, while proponents have \nsuggested that AI provides a ready solution to the issues \ncaused by the COVID-19 school closures and the shift to online \nlearning, there is currently little evidence that such an approach \nis appropriate or effective. The use of AI for education management \nand delivery\nAI technologies are increasingly being used to facilitate \nthe management and delivery of education. Rather than \nsupporting teaching or learning directly, these system-\nfacing applications are designed to automate aspects of \nschool administration, building on Education Management \nInformation Systems (Villanueva, 2003), and including \nadmissions, timetabling, attendance and homework \nmonitoring, and school inspections. Sometimes a data-mining \napproach known as ‘learning analytics’ (du Boulay et al., \n2018) is used to analyse the big data generated in learning \nmanagement systems to provide information for teachers \nand administrators, and sometimes guidance for students. For example, some learning analytics predict which students \nare at risk of failure. Outputs often take the form of visual \n‘dashboards’ (Verbert et al., 2013), and are used to inform \ndata-driven decision making (James et al., 2008; Marsh et al., \n2006). Big data drawn from educational systems might also \ncontribute to policy-making for delivery: \nPublic educational institutions increasingly utilize big data \nfor creating digital and interactive data visualizations that \ncan then give up-to-date information on the education system for \npolicy-makers. (Giest, 2017, p. 377) \nFor example, the data outputs of learning management \nsystems established for refugees might help determine \nthe optimal delivery of educational opportunities and \nsupport. AI has also demonstrated its potential to curate \nlearning content across platforms based on analyses of \nlearners’ personalized needs and level of study. For example, \none project aims to curate the many thousands of open \neducational resources, making them more easily accessible \nto all learners (Kreitmayer et al., 2018)."
  },
  {
    "id": "898c722e-e3d5-444c-aa3c-33c48931e2a2",
    "filename": "documents\\376709eng.pdf",
    "page_number": 17,
    "chunk_id": "17_1",
    "chunk_text": "Big data drawn from educational systems might also \ncontribute to policy-making for delivery: \nPublic educational institutions increasingly utilize big data \nfor creating digital and interactive data visualizations that \ncan then give up-to-date information on the education system for \npolicy-makers. (Giest, 2017, p. 377) \nFor example, the data outputs of learning management \nsystems established for refugees might help determine \nthe optimal delivery of educational opportunities and \nsupport. AI has also demonstrated its potential to curate \nlearning content across platforms based on analyses of \nlearners’ personalized needs and level of study. For example, \none project aims to curate the many thousands of open \neducational resources, making them more easily accessible \nto all learners (Kreitmayer et al., 2018). However, for any data-based analytics to be useful, with \nconclusions that are trustworthy and equitable, the original \ndata and its proxies must be accurate and free from biases \nand poor assumptions, while the applied computational \napproaches must be both appropriate and robust – simple \nrequirements that all too often are not rigorously met (Holmes \net al., 2019). In any case, there are examples of AI companies \ncollecting huge amounts of student interaction data just \nin order to use machine-learning techniques to ‘search for \npatterns’. The aim is to improve student learning by teaching \nthe software to identify when children are confused or \nbored, in order to help them become engaged. Nonetheless, \nthis approach is controversial, with this kind of data \ncollection being characterized as \"borderline mental-health \nassessments..., [that] encourage a view of children as potential \npatients in need of treatment\" (Herold, 2018). In some contexts, AI tools under this category have also been \nused for monitoring student attention in class (Connor, 2018), \nwhile others have been used to track attendance (Harwell, \n2019) and predict teachers’ performance, with worrying \nconsequences (O’Neil, 2017). These aspects of system-facing \napplications should be part of the wider discussion about AI \nand education. Promising examples\n \n Educational chatbots: Chatbots are online computer \nprograms that use cloud-based services and AI techniques \nto hold simulated conversations with people. The human \nuser types or speaks a question, and the chatbot responds, \nproviding information or undertaking a simple task. There are \ntwo levels of chatbot sophistication. While most chatbots use \nrules and keywords to select from pre-programmed scripted \nresponses, virtual-assistant chatbots (such as Siri,20 Alexa,21 \nDuerOS,22 and Xiaoyi)23 use natural language processing \nand machine learning to generate unique responses."
  },
  {
    "id": "e8ce4d8e-0475-46de-ac8d-95c9656ea920",
    "filename": "documents\\376709eng.pdf",
    "page_number": 17,
    "chunk_id": "17_2",
    "chunk_text": "These aspects of system-facing \napplications should be part of the wider discussion about AI \nand education. Promising examples\n \n Educational chatbots: Chatbots are online computer \nprograms that use cloud-based services and AI techniques \nto hold simulated conversations with people. The human \nuser types or speaks a question, and the chatbot responds, \nproviding information or undertaking a simple task. There are \ntwo levels of chatbot sophistication. While most chatbots use \nrules and keywords to select from pre-programmed scripted \nresponses, virtual-assistant chatbots (such as Siri,20 Alexa,21 \nDuerOS,22 and Xiaoyi)23 use natural language processing \nand machine learning to generate unique responses. In \neducational contexts, chatbots are being used in an ever-\ngrowing range of applications. This includes facilitating \nstudent admissions (e.g. \"What computing courses do \nyou have?\"); providing 24/7 information (e.g. \"When is my \nassignment due?\"); and directly supporting learning (perhaps \nas part of a dialogue-based tutoring system or DBTS approach \n(see page 16), engaging the student in a spoken dialogue or \nproviding automated feedback). Educational chatbots include \nAda24 and Deakin Genie.25\n \n OU Analyse,26 an AI application designed by the United \nKingdom's Open University, has been designed to predict \nBeijing Consensus on Artificial Intelligence and Education\n10. Be cognizant of the breakthrough in the use of data in transforming \nevidence-based policy planning processes. Consider integrating \nor developing AI technologies and tools that are relevant for \nupgrading education management information systems (EMIS) in \norder to enhance data collection and processing, making education \nmanagement and provision more equitable, inclusive, open and \npersonalized. 11. Consider also introducing new models for delivering education and \ntraining in different learning institutions and settings that can be \nenabled by the use of AI, in order to serve different actors such as \nstudents, teaching staff, parents and communities. (UNESCO, 2019a, p. 5)"
  },
  {
    "id": "e4941a34-f579-4c7d-b565-a988809a67ed",
    "filename": "documents\\376709eng.pdf",
    "page_number": 18,
    "chunk_id": "18_0",
    "chunk_text": "Understanding AI and education: Emerging practices and benefit-risk assessment – AI and education: Guidance for policy-makers \n15\nstudent outcomes and identify students at risk of failing \nby analysing big data from the university’s education \nmanagement information system (EMIS). The predictions \nare available to the course tutors and support teams, using \neasy-to-access dashboards, so that they might consider the \nmost appropriate support. The overall objective is to enable \nstudents who might be having difficulties to complete their \ncourses (Herodotou et al., 2017).  ‘Swift’ is a set of methods developed by Swift eLearning \nServices in India to help EMIS systems leverage the data \ngenerated in an e-learning module.27 The data collected from \nlearner interactions provide valuable insight into when and \nwhy the learner might be struggling or achieving. Analysing \nthis data helps create personalized learning pathways tailored \nto meet learner preferences.  In the US, the ALP28 system provides back-end AI \nfunctionality to support standard educational technologies. The system analyses user data, aggregating it to create \npsychometric profiles of each individual student’s interactions, \npreferences, and achievements.  Based in the US, but involving organizations from four \ncontinents, the UniTime29 project is a comprehensive \nAI-powered educational scheduling system that develops \ntimetables for university courses and examinations, \nmanages time and room changes, and provides students’ \nindividual schedules. The use of AI for learning and assessment \nThe use of AI technologies that are mostly student-facing, \nhave received the most attention from researchers, \ndevelopers, educators and policy-makers. These applications, \nwhich have been heralded as constituting a ‘fourth education \nrevolution’ (Seldon and Abidoye, 2018), aim to provide \nevery learner, wherever they are in the world, with access to \nhigh-quality, personalized, and ubiquitous lifelong learning \n(formal, informal and non-formal). There is also potential \nfor AI to facilitate new approaches to assessment, such as \nAI-enabled adaptive and continuous assessment (Luckin, \n2017). However, it is important to acknowledge at the outset \nthat the use of AI for learning and assessment also raises \nvarious concerns that are yet to be properly addressed. These \ninclude concerns about their approach to pedagogy, the lack \nof robust evidence for their efficacy and potential impact on \nteachers’ roles, and broader ethical questions (Holmes et al., \n2018b, 2019). Intelligent tutoring systems\nFor several reasons, we begin the discussion of the use of \nAI for learning and assessment with a set of tools known \nas ‘intelligent tutoring systems’ (ITS)."
  },
  {
    "id": "b29f27cd-9ab9-4ed2-a81e-adb3d33f8155",
    "filename": "documents\\376709eng.pdf",
    "page_number": 18,
    "chunk_id": "18_1",
    "chunk_text": "These applications, \nwhich have been heralded as constituting a ‘fourth education \nrevolution’ (Seldon and Abidoye, 2018), aim to provide \nevery learner, wherever they are in the world, with access to \nhigh-quality, personalized, and ubiquitous lifelong learning \n(formal, informal and non-formal). There is also potential \nfor AI to facilitate new approaches to assessment, such as \nAI-enabled adaptive and continuous assessment (Luckin, \n2017). However, it is important to acknowledge at the outset \nthat the use of AI for learning and assessment also raises \nvarious concerns that are yet to be properly addressed. These \ninclude concerns about their approach to pedagogy, the lack \nof robust evidence for their efficacy and potential impact on \nteachers’ roles, and broader ethical questions (Holmes et al., \n2018b, 2019). Intelligent tutoring systems\nFor several reasons, we begin the discussion of the use of \nAI for learning and assessment with a set of tools known \nas ‘intelligent tutoring systems’ (ITS). Of all educational AI \napplications, ITS have been researched the longest (more than \n40 years). They are the most common applications of AI in \neducation and have been experienced by more students than \nany other. Moreover, they have attracted the highest level of \ninvestment and interest from the world’s leading technology \ncompanies, and they have been adopted in education systems \naround the world for use with millions of students. Generally speaking, the way ITS work is by providing step-by-\nstep tutorials, individualized for each student, through topics in \nstructured subjects such as mathematics or physics. The system \ndetermines an optimal pathway through the learning materials \nand activities by drawing on expert knowledge about the \nsubject and cognitive sciences, and by responding to individual \nstudents’ misconceptions and successes. This approach is also \nsometimes implemented in learning management systems, \nsuch as Moodle30 and Open edX,31 and platforms such as \nKhan Academy.32\nAs the student engages with the learning activities, the \nsystem uses knowledge tracing33 and machine learning to \nautomatically adjust the level of difficulty and provide hints \nor guidance according to the individual student’s strengths \nand weaknesses, all of which aim to ensure that the student is \nable to learn the topic efficiently. Some ITSs also capture and \nanalyse data about the student’s affective state, including by \nmonitoring their gaze to infer their level of attention."
  },
  {
    "id": "a385a0d0-2c3b-45b9-9a7b-72d8e787ed15",
    "filename": "documents\\376709eng.pdf",
    "page_number": 18,
    "chunk_id": "18_2",
    "chunk_text": "Moreover, they have attracted the highest level of \ninvestment and interest from the world’s leading technology \ncompanies, and they have been adopted in education systems \naround the world for use with millions of students. Generally speaking, the way ITS work is by providing step-by-\nstep tutorials, individualized for each student, through topics in \nstructured subjects such as mathematics or physics. The system \ndetermines an optimal pathway through the learning materials \nand activities by drawing on expert knowledge about the \nsubject and cognitive sciences, and by responding to individual \nstudents’ misconceptions and successes. This approach is also \nsometimes implemented in learning management systems, \nsuch as Moodle30 and Open edX,31 and platforms such as \nKhan Academy.32\nAs the student engages with the learning activities, the \nsystem uses knowledge tracing33 and machine learning to \nautomatically adjust the level of difficulty and provide hints \nor guidance according to the individual student’s strengths \nand weaknesses, all of which aim to ensure that the student is \nable to learn the topic efficiently. Some ITSs also capture and \nanalyse data about the student’s affective state, including by \nmonitoring their gaze to infer their level of attention. However, although intuitively appealing, it is important to \nrecognize that assumptions embodied in ITS, and their typical \ninstructionist knowledge-transmission approach to teaching, \nignore the possibilities of other approaches valued by the \nlearning sciences, such as collaborative learning, guided \ndiscovery learning, and productive failure (Dean Jr. and Kuhn, \n2007). In particular, the ‘personalized learning’ provided by ITS \ntypically personalises only the pathways to prescribed content, \nrather than promoting student agency by personalising the \nlearning outcomes and enabling the student to achieve their \nown personal ambitions. In addition, although some studies \nhave shown that some ITSs designed by researchers compare \nwell with whole-class teaching (e.g. du Boulay, 2016), and \ndespite the fact that they have been bought into by many \neducation systems around the world, there is actually limited \nrobust evidence that commercial ITS are as effective as their \ndevelopers claim (Holmes et al., 2018a). The extensive use of ITS raises other problems as well. For \nexample, they tend to reduce human contact among students \nand teachers. Also, in a typical ITS classroom, the teacher often \nspends a great deal of time at their desk in order to monitor \nthe dashboard of student interactions."
  },
  {
    "id": "8a3bd1f4-bd95-4ad6-83e7-120e8a7eb16d",
    "filename": "documents\\376709eng.pdf",
    "page_number": 18,
    "chunk_id": "18_3",
    "chunk_text": "In addition, although some studies \nhave shown that some ITSs designed by researchers compare \nwell with whole-class teaching (e.g. du Boulay, 2016), and \ndespite the fact that they have been bought into by many \neducation systems around the world, there is actually limited \nrobust evidence that commercial ITS are as effective as their \ndevelopers claim (Holmes et al., 2018a). The extensive use of ITS raises other problems as well. For \nexample, they tend to reduce human contact among students \nand teachers. Also, in a typical ITS classroom, the teacher often \nspends a great deal of time at their desk in order to monitor \nthe dashboard of student interactions. If they choose to move \naround the room, as they might in a non-ITS classroom, they \nlose their access to what the students are doing, making \nit a challenge to decide where to give personal attention. To address this conundrum, an ITS extension called Lumilo \n(Holstein et al., 2018) uses augmented-reality smart glasses \nto ‘float’ information above each student’s head about their \nlearning (e.g. misconceptions) or behaviour (e.g. inattention), \ngiving the teacher in-depth and continuous information on \nwhich they can act. This is a captivating use of a clever AI"
  },
  {
    "id": "5e86a9f4-156c-4abe-8627-1afb6c99bc9a",
    "filename": "documents\\376709eng.pdf",
    "page_number": 19,
    "chunk_id": "19_0",
    "chunk_text": "AI and education: Guidance for policy-makers – Understanding AI and education: Emerging practices and benefit-risk assessment\n16\ntechnology, but one that has, it is worth noting, been designed \nto address a problem only triggered by another use of AI \ntechnology. It is also an approach that raises issues of human \nrights, especially the right to privacy. Globally, there are more than 60 commercial ITS available \ntoday, including Alef,34 ALEKS,35 Byjus,36 Mathia,37 Qubena,38 \nRiiid,39 and Squirrel AI.40 An approach known as Hi-Tech \nHi-Touch, that aims to leverage the best of ITS and the \nbest of teachers, is currently being tested by the Education \nCommission in schools in Vietnam.41\nDialogue-based tutoring systems\nDialogue-based tutoring systems (DBTS) use natural language \nprocessing and other AI techniques to simulate a spoken \ntutorial dialogue between human tutors and students as \nthey work step-by-step through online tasks most often in \ncomputer science topics, but more recently in less structured \ndomains. DBTS adopt a Socratic approach to tutoring, probing \nwith AI-generated questions rather than providing instruction, \nto develop a conversation in which the students are guided \ntowards discovering for themselves an appropriate solution \nfor a problem. The aim is to encourage students to co-create \nexplanations to reach an in-depth understanding of the topic \nrather than the shallow understanding that can result from \nsome instructional ITS. Currently, there are relatively few DBTS in use. Most exist \nwithin research projects. The most extensively tested \none is AutoTutor (Graesser et al., 2001). Watson Tutor is a \ncommercial system that has been developed by IBM and \nPearson Education.42\nExploratory learning environments\nAn alternative to the step-by-step approaches of ITS and DBTS \nis provided by exploratory learning environments (ELEs). ELEs \nadopt a constructivist philosophy: rather than following a \nstep-by-step sequence such as the ‘knowledge transmission’ \nmodel favoured by ITS, students are encouraged to actively \nconstruct their own knowledge by exploring the learning \nenvironment and making connections with their existing \nknowledge schema. The role of AI in ELEs is to minimize the \ncognitive overload that is often associated with exploratory \nlearning by providing automated guidance and feedback, \nbased on knowledge tracing and machine learning. This \nfeedback addresses misconceptions and proposes alternative \napproaches, to support the student while they explore. Broadly speaking, ELEs have yet to emerge from research \nlaboratories. Examples include ‘ECHOES’ (Bernardini et al., \n2014); ‘Fractions Lab’ (Rummel et al., 2016); and ‘Betty’s Brain’ \n(Leelawong and Biswas, 2008)."
  },
  {
    "id": "7b43cfa7-b4fe-4608-a20d-c600a2e021c3",
    "filename": "documents\\376709eng.pdf",
    "page_number": 19,
    "chunk_id": "19_1",
    "chunk_text": "ELEs \nadopt a constructivist philosophy: rather than following a \nstep-by-step sequence such as the ‘knowledge transmission’ \nmodel favoured by ITS, students are encouraged to actively \nconstruct their own knowledge by exploring the learning \nenvironment and making connections with their existing \nknowledge schema. The role of AI in ELEs is to minimize the \ncognitive overload that is often associated with exploratory \nlearning by providing automated guidance and feedback, \nbased on knowledge tracing and machine learning. This \nfeedback addresses misconceptions and proposes alternative \napproaches, to support the student while they explore. Broadly speaking, ELEs have yet to emerge from research \nlaboratories. Examples include ‘ECHOES’ (Bernardini et al., \n2014); ‘Fractions Lab’ (Rummel et al., 2016); and ‘Betty’s Brain’ \n(Leelawong and Biswas, 2008). Automated writing evaluation\nRather than involving students working on computers while \nreceiving immediate adaptive support, automated writing \nevaluation (AWE) uses natural language processing and other \nAI techniques to provide automatic feedback on writing. Generally, there are two overlapping AWE approaches: \nformative AWE to enable a student to improve their writing \nbefore submitting it for assessment, and summative AWE to \nfacilitate the automatic scoring of students’ writing. In fact, most AWE focuses on scoring over feedback; they \nhave been designed principally to drive down assessment \ncosts, and thus may be considered as a component of \nsystems-facing applications. However, ever since they \nwere introduced, summative AWE have been controversial \n(Feathers, 2019). For example, they have been criticized for \ngiving students credit for surface features such as sentence \nlength, even if the text does not make any sense – they can \nbe ‘fooled by gibberish’. The systems are also unable to assess \ncreativity. Most worryingly, the algorithms underpinning AWE \nare sometimes biased, especially against minority students, \npossibly due to different uses of vocabulary and sentence \nstructure. Summative AWE also does not address easy-to-\naccess ‘deep-fake’ school and university assignments – essays \nthat are written by AI technologies, through drawing on \ndomain expertise while imitating the writing style of the \nindividual student. These are likely to be very difficult to \ndetect.43 Finally, the use of AI to mark assignments also does \nnot acknowledge the value of marking. Even though marking \ncan be time-consuming and tedious, it can also be a teacher’s \nbest opportunity to understand their students’ competencies."
  },
  {
    "id": "dccd7594-89dd-4356-89a0-b268e0c5545a",
    "filename": "documents\\376709eng.pdf",
    "page_number": 19,
    "chunk_id": "19_2",
    "chunk_text": "The systems are also unable to assess \ncreativity. Most worryingly, the algorithms underpinning AWE \nare sometimes biased, especially against minority students, \npossibly due to different uses of vocabulary and sentence \nstructure. Summative AWE also does not address easy-to-\naccess ‘deep-fake’ school and university assignments – essays \nthat are written by AI technologies, through drawing on \ndomain expertise while imitating the writing style of the \nindividual student. These are likely to be very difficult to \ndetect.43 Finally, the use of AI to mark assignments also does \nnot acknowledge the value of marking. Even though marking \ncan be time-consuming and tedious, it can also be a teacher’s \nbest opportunity to understand their students’ competencies. However, some student-facing AWE prioritizes giving \nfeedback that is designed to be actionable – to help the \nstudent improve their writing, and to promote higher-order \nprocesses such as self-regulated learning and metacognition. AWE, both formative and summative, is currently being used \nin many educational contexts through programs such as \nWriteToLearn,44 e-Rater,45 and Turnitin.46 A related approach, \nusing AI to compare a novel student output with a large \ncorpus of previous student output assessed by teachers, has \nbeen used to evaluate musical performances, for example \nwith the program Smartmusic.47\nAI-supported reading and language learning\nReading and language learning tools are increasingly \nusing AI to augment their approach. For example, some \nuse ITS-style pathway personalisation along with AI-driven \nspeech recognition. Typically, speech recognition is used to \ncompare students’ production with sample recordings of \nnative speakers, to provide automatic feedback to help the \nstudent improve their pronunciation. Other uses of automatic \ntranslation involve helping students read learning materials \nin other languages, and enabling students from different \ncultures to more easily interact with each other. Meanwhile, \nother systems detect and automatically analyse reading skills \nin order to give students individual feedback. Reading and language learning AI applications include AI \nTeacher,48 Amazing English,49 Babbel,50 and Duolingo.51"
  },
  {
    "id": "cbc9e9f6-2410-4677-9437-2d88843bd78d",
    "filename": "documents\\376709eng.pdf",
    "page_number": 20,
    "chunk_id": "20_0",
    "chunk_text": "Understanding AI and education: Emerging practices and benefit-risk assessment – AI and education: Guidance for policy-makers \n17\nSmart robots\nThe use of AI-enabled or ‘smart’ robots in education is also \nbeing explored (Belpaeme, 2018), particularly in settings for \nchildren with learning disabilities or difficulties. For example, \nspeech-enabled humanoid robots have been created for \nlearners on the autism spectrum, providing predictable \nmechanical interactions rather than human ones, which can \nbe confusing for such learners. The aim is to develop their \ncommunication and social skills (Dautenhahn et al., 2009). Another example is telepresence robots for students who \nare unable to attend school, perhaps because of an illness or \na humanitarian or refugee crisis, to access the classroom.52 \nA third example is the use of humanoid robots, such as \nNao53 or Pepper54 in kindergarten classes in Singapore \n(Graham, 2018), to introduce young children to computer \nprogramming and other STEM subjects. Teachable agents\nIt has long been known that one may learn a topic more \ndeeply and with better retention by teaching it to others \n(Cohen et al., 1982). This effect has been exploited by \nvarious AI approaches. For example, in the ELE mentioned \nearlier, Betty’s Brain, students are encouraged to teach a \nvirtual fellow student called Betty about a river ecosystem. In another example from a Swedish research project, the \nstudent teaches a virtual agent the rules of an educational \ngame based on mathematics (Pareto, 2009). A third example, \nfrom Switzerland, involves young children teaching \nhandwriting to a humanoid robot,55 an approach which has \nbeen shown to stimulate meta-cognition, empathy, and \nself-esteem (Hood et al., 2015). Educational virtual and augmented reality\nVirtual reality (VR) and augmented reality (AR) are two \nrelated innovations that have been applied in educational \ncontexts, and that are frequently combined with machine \nlearning and other AI techniques to enhance the user \nexperience. VR has been used in the teaching of many \nsubjects, across K-12 and beyond, including astronomy, \nbiology, and geology. VR goggles provide an immersive \nexperience that shuts out the physical world, enabling \nusers to feel as if they have been transported into a range of \nreal-world or imagined environments (such as the surface \nof Mars, the inside of a volcano, or a human womb in \nwhich a foetus is developing). Some VR innovations use AI \ntechniques to control lifelike virtual avatars, enable voice \ncontrol using natural language processing, or generate \nentire environments from a few starting images."
  },
  {
    "id": "8b63a163-02df-4cf9-ba34-0580138c2a3a",
    "filename": "documents\\376709eng.pdf",
    "page_number": 20,
    "chunk_id": "20_1",
    "chunk_text": "A third example, \nfrom Switzerland, involves young children teaching \nhandwriting to a humanoid robot,55 an approach which has \nbeen shown to stimulate meta-cognition, empathy, and \nself-esteem (Hood et al., 2015). Educational virtual and augmented reality\nVirtual reality (VR) and augmented reality (AR) are two \nrelated innovations that have been applied in educational \ncontexts, and that are frequently combined with machine \nlearning and other AI techniques to enhance the user \nexperience. VR has been used in the teaching of many \nsubjects, across K-12 and beyond, including astronomy, \nbiology, and geology. VR goggles provide an immersive \nexperience that shuts out the physical world, enabling \nusers to feel as if they have been transported into a range of \nreal-world or imagined environments (such as the surface \nof Mars, the inside of a volcano, or a human womb in \nwhich a foetus is developing). Some VR innovations use AI \ntechniques to control lifelike virtual avatars, enable voice \ncontrol using natural language processing, or generate \nentire environments from a few starting images. AR, on the other hand, overlays computer-generated images \non the user’s view of the real world (much like a fighter \npilot’s heads-up display). AR is the aforementioned approach \nused by Lumilo to float information about a student’s ITS \nperformance above their head. When a smartphone’s camera \nis pointed at a particular QR code, an AR 3D human heart \nmight be revealed that can be explored in detail. AR might \nalso involve AI-powered image recognition and tracking. This is the technology that makes it possible, on some \nmobile phones and sites such as Instagram or Snapchat, \nto place rabbit ears or cat whiskers on images of people. Examples of VR and AR being used in education include \nBlippar,56 EonReality,57 Google Education,58 NeoBear,59 and \nVR Monkey.60\nLearning network orchestrators\nLearning network orchestrators (LNOs) are tools that enable \nnetworks of students and teachers to engage in learning \nand organize learning activities. LNOs typically match \nparticipants based on their availability, subject domain, and \nexpertise, and can facilitate coordination and cooperation."
  },
  {
    "id": "91fcee46-4144-4bfa-a295-44efed0a2439",
    "filename": "documents\\376709eng.pdf",
    "page_number": 20,
    "chunk_id": "20_2",
    "chunk_text": "When a smartphone’s camera \nis pointed at a particular QR code, an AR 3D human heart \nmight be revealed that can be explored in detail. AR might \nalso involve AI-powered image recognition and tracking. This is the technology that makes it possible, on some \nmobile phones and sites such as Instagram or Snapchat, \nto place rabbit ears or cat whiskers on images of people. Examples of VR and AR being used in education include \nBlippar,56 EonReality,57 Google Education,58 NeoBear,59 and \nVR Monkey.60\nLearning network orchestrators\nLearning network orchestrators (LNOs) are tools that enable \nnetworks of students and teachers to engage in learning \nand organize learning activities. LNOs typically match \nparticipants based on their availability, subject domain, and \nexpertise, and can facilitate coordination and cooperation. One example, ‘Third Space Learning’, connects pupils in \nthe United Kingdom who are at risk of failing maths with \nmathematics tutors from other countries.61 Another is ‘Smart \nLearning Partner’, which involves an AI-driven platform that \nenables students to choose and connect with a human tutor \nvia their mobile phones, somewhat like a dating app, to \nreceive one-to-one support.62\nAI-enabled collaborative learning\nCollaborative learning, where students work together to solve \nproblems, is known to enhance learning outcomes (Luckin et \nal., 2017), but effective collaboration between learners can be \ndifficult to achieve. AI may transform collaborative learning \nin various ways: a tool could help connect learners remotely; \nit could identify the students best suited for particular \ncollaborative tasks and group them accordingly; or it could \nactively contribute to the group discussions, as a virtual \nagent. While no specific examples have been identified, it \nis currently an area of research interest (e.g. Cukurova et \nal., 2017). Beijing Consensus on Artificial Intelligence and Education \n13. Dynamically review and define teachers’ roles and required \ncompetencies in the context of teacher policies, strengthen \nteacher-training institutions, and develop appropriate capacity-\nbuilding programmes to prepare teachers to work effectively in \nAI-rich education settings. 14. Be cognizant of trends regarding the potential of AI to support \nlearning and learning assessments, and review and adjust \ncurricula to promote the in-depth integration of AI and \ntransformation of learning methodologies. Consider applying \navailable AI tools or developing innovative AI solutions, where \nthe benefits of AI use clearly outweigh the risks, to facilitate well-\ndefined learning tasks in different subject areas and supporting \nthe development of AI tools for interdisciplinary skills and \ncompetencies. 16."
  },
  {
    "id": "b53d5f43-b605-44b9-bdbb-437c7dd22417",
    "filename": "documents\\376709eng.pdf",
    "page_number": 20,
    "chunk_id": "20_3",
    "chunk_text": "Dynamically review and define teachers’ roles and required \ncompetencies in the context of teacher policies, strengthen \nteacher-training institutions, and develop appropriate capacity-\nbuilding programmes to prepare teachers to work effectively in \nAI-rich education settings. 14. Be cognizant of trends regarding the potential of AI to support \nlearning and learning assessments, and review and adjust \ncurricula to promote the in-depth integration of AI and \ntransformation of learning methodologies. Consider applying \navailable AI tools or developing innovative AI solutions, where \nthe benefits of AI use clearly outweigh the risks, to facilitate well-\ndefined learning tasks in different subject areas and supporting \nthe development of AI tools for interdisciplinary skills and \ncompetencies. 16. Apply or develop AI tools to support adaptive learning processes; \nto leverage the potential of data to enable the evaluation of the \nmultiple dimensions of students’ competencies; and to support \nlarge-scale and remote assessment. (UNESCO, 2019a, pp. 5-6)"
  },
  {
    "id": "6b383d02-43b7-4a4e-a01b-be380eb879ce",
    "filename": "documents\\376709eng.pdf",
    "page_number": 21,
    "chunk_id": "21_0",
    "chunk_text": "AI and education: Guidance for policy-makers – Understanding AI and education: Emerging practices and benefit-risk assessment\n18\nThe use of AI to empower teachers and enhance \nteaching \nDespite its potential to empower teachers, the use of teacher-\nfacing AI applications to augment and enhance teachers and \nteaching has to date received far less attention than student-\nfacing AI, which by definition replaces the teacher. Currently, \nresearchers and developers often design for teachers only at \nthe end of the process, for example by adding in a dashboard \nto display ITS student data. However, this is slowly beginning \nto be addressed. Many teacher-facing AI applications aim to help teachers \nreduce workloads by automating tasks such as assessment, \nplagiarism detection, administration and feedback. This, it \nis often argued, should free up time for teachers to invest \nin other tasks, such as providing more effective support \nto individual students. However, as the AI develops, it is \npossible that teachers will be relieved of so many more \ntasks that the perceived need for teachers will be reduced \nto next to nothing. While this might have some benefits in \ncontexts where teachers are scarce, the aim of eliminating \nthe need for human teachers reveals a fundamental \nmisunderstanding of their essential social role in the \nlearning process. Nonetheless, it is widely agreed that as AI tools become \nmore available in classroom, it is likely that teacher roles will \nchange. What is not yet clear is how this will happen. However, \nwe know that teachers will need to build new competencies \nto enable them to work effectively with AI, and undertake \nappropriate professional development to foster their human \nand social capabilities. AI-driven discussion forum monitoring\nAI technologies are being used to support online \neducation, especially to help teachers or facilitators \nmonitor asynchronous discussion forums. On these \nforums, students give responses to given tasks, ask their \ntutors about course materials, and engage in collaborative \nlearning opportunities. This typically generates large \nnumbers of posts, all of which must be moderated and \naddressed. AI might help in a number of ways: a tool might \ntriage the forum posts and automatically respond to the \nsimpler ones; aggregate posts that raise overlapping issues; \nor use sentiment analysis to identify posts that reveal \nnegative or non-productive emotional states. Together, \nthese techniques might also enable human tutors to be \nkept informed of student opinions and collective worries."
  },
  {
    "id": "b37009b2-3e10-4c6a-8af4-efde98408500",
    "filename": "documents\\376709eng.pdf",
    "page_number": 21,
    "chunk_id": "21_1",
    "chunk_text": "AI-driven discussion forum monitoring\nAI technologies are being used to support online \neducation, especially to help teachers or facilitators \nmonitor asynchronous discussion forums. On these \nforums, students give responses to given tasks, ask their \ntutors about course materials, and engage in collaborative \nlearning opportunities. This typically generates large \nnumbers of posts, all of which must be moderated and \naddressed. AI might help in a number of ways: a tool might \ntriage the forum posts and automatically respond to the \nsimpler ones; aggregate posts that raise overlapping issues; \nor use sentiment analysis to identify posts that reveal \nnegative or non-productive emotional states. Together, \nthese techniques might also enable human tutors to be \nkept informed of student opinions and collective worries. An example, albeit with some ethical issues, was the AI \nassistant ‘Jill Watson’, which was developed at Georgia \nTech in the United States of America to triage forum posts \nand answer questions where possible (such as \"When \ndo I have to submit my assignment?\"), while referring \nother more complex posts to human teaching assistants. This AI assistant was based on IBM’s Watson platform. It automatically responded to some student questions, \nand sent emails to students about assignments (Goel and \nPolepeddi, 2017). Although it was thought to be successful, \nthe ethics were criticized because it tricked students into \nthinking that the AI assistant was a real person – by, for \nexample, delaying its responses and using humour. AI-human ‘dual teacher’ model\nAlthough there are some notable exceptions, much AI in \neducation has been designed – whether intentionally or not \n– to replace some teacher tasks, rather than to assist teachers \nto teach more effectively. Some schools in China’s remote rural \nareas already use what is known as a ‘dual teacher model’. In \nthis approach, an expert teacher gives a lecture over a video \nlink to students in a distant classroom, who receive additional \nguidance from a less-experienced local teacher (iResearch \nGlobal, 2019). A future possibility is that an AI teaching \nassistant could support one of these roles. The AI could help \nthe human teacher with many tasks, including providing \nspecialist expertise or professional development resources, \ncollaborating with colleagues, both within and outside the \nparticular setting, monitoring the students’ performance, \nand tracking progress over time. What and how to teach the \nstudents would remain the responsibility and prerogative \nof the teacher."
  },
  {
    "id": "5e50b3c5-4311-4477-b92f-0dcc37397829",
    "filename": "documents\\376709eng.pdf",
    "page_number": 21,
    "chunk_id": "21_2",
    "chunk_text": "Some schools in China’s remote rural \nareas already use what is known as a ‘dual teacher model’. In \nthis approach, an expert teacher gives a lecture over a video \nlink to students in a distant classroom, who receive additional \nguidance from a less-experienced local teacher (iResearch \nGlobal, 2019). A future possibility is that an AI teaching \nassistant could support one of these roles. The AI could help \nthe human teacher with many tasks, including providing \nspecialist expertise or professional development resources, \ncollaborating with colleagues, both within and outside the \nparticular setting, monitoring the students’ performance, \nand tracking progress over time. What and how to teach the \nstudents would remain the responsibility and prerogative \nof the teacher. The AI tool’s role would simply be to make \nthe teacher’s job easier and more collegiate. An example is \nthe ‘LeWaijiao AI classroom’,63 which is designed to support \nhuman teachers so that they may conduct all of the key tasks. AI-powered teaching assistants\nAs mentioned, many technologies are designed with the \naim of relieving teachers of time-consuming activities such \nas taking attendance, marking assignments and answering \nthe same questions over and over again. However, in so \ndoing they effectively ‘take over' much of the teaching (some \nclaim to deliver personalized learning activities ‘better than’ \nteachers), interfere with the teacher-student relationship, and \ncan reduce teachers to a functional role. For example, one aim \nof automatic writing evaluation (AWE) is to relieve teachers \nof the burden of marking. However, as we have noted, \nwhile marking can be onerous, it is often a key opportunity \nfor teachers to learn about their students’ strategies and \ncapabilities. This can be lost with the use of AWE. In addition, this approach clearly undervalues teachers’ \nunique skills and experiences, as well as learners’ social and \nguidance needs. Instead of just automating computer-based \nteaching, AI might help open up teaching and learning \npossibilities that are otherwise difficult to achieve, or that \nchallenge or even disrupt existing pedagogies. Such an \napproach would aim to augment a teacher’s expertise, \nperhaps by means of an AI teaching assistant (AI TA) (Luckin \nand Holmes, 2017). There are some AI applications designed \nto empower teachers and schools to facilitate transformation \nin learning. Some research on these has been undertaken, but \nmany technical and ethical issues need to be overcome before \nthey can be harnessed in real settings."
  },
  {
    "id": "d4925dc7-8425-4802-ab0a-4c8d83fa95bb",
    "filename": "documents\\376709eng.pdf",
    "page_number": 22,
    "chunk_id": "22_0",
    "chunk_text": "Understanding AI and education: Emerging practices and benefit-risk assessment – AI and education: Guidance for policy-makers \n19\n3.2 How can AI be best exploited for the common good in education? As has been explored, AI is already being used in educational \ncontexts in multiple ways. However, despite using cutting-\nedge technologies, these applications often do little more \nthan automate some outmoded classroom practices, rather \nthan using the unique affordances of AI to reimagine \nteaching and learning. In other words, the attention of AI \nresearchers and developers working in education has so far \nbeen focused on the relatively easy to address, although \nstill complex, low-hanging fruit of memorising and recalling \nknowledge. Few possibilities that address more complex \neducational issues, such as collaborative learning or new \nways to assess and accredit, have yet to be fully researched, \nlet alone made available as commercial products at scale. Accordingly, here, in order to stimulate a dialogue, some \ninnovative ways in which AI might be exploited for the \ncommon good in education are suggested. AI-driven lifelong learning companions\nThe desire for every student to have their own personalized \nlifelong tutor is what first inspired the use of AI in learning. Technically speaking, it would not necessarily be difficult \nto leverage the capabilities of smartphones and related \ntechnologies to create an AI-driven learning companion that \ncould accompany individual learners throughout their life. Rather than setting out to teach the student in the manner \nof an instructionist ITS, a learning companion would provide \ncontinuous support, building on the individual student’s \ninterests and goals, to help them decide what to learn, as \nwell as where and how. It could also guide the student along \nindividualized learning pathways designed to help them \naddress their emerging goals and connect their learning \ninterests and achievements, while encouraging them to reflect \non and revise their long-term learning aims. However, despite \nthe profound potential, there are currently no commercial \nAI-enabled lifelong learning products, and little research. AI-enabled continuous assessment\nAlthough there is little evidence for their validity, \nreliability or accuracy, high-stakes examinations are \ncentral in educational systems around the world. With \nsuch examinations in place, schools and universities often \nteach to the test, prioritizing routine cognitive skills and \nknowledge acquisition (the types of knowledge being \nsupplanted by AI) over in-depth understanding and \nauthentic application. In fact, AI is already being developed to extend existing \nexamination practices."
  },
  {
    "id": "5148410d-5492-4695-ae32-a5bad57235b1",
    "filename": "documents\\376709eng.pdf",
    "page_number": 22,
    "chunk_id": "22_1",
    "chunk_text": "It could also guide the student along \nindividualized learning pathways designed to help them \naddress their emerging goals and connect their learning \ninterests and achievements, while encouraging them to reflect \non and revise their long-term learning aims. However, despite \nthe profound potential, there are currently no commercial \nAI-enabled lifelong learning products, and little research. AI-enabled continuous assessment\nAlthough there is little evidence for their validity, \nreliability or accuracy, high-stakes examinations are \ncentral in educational systems around the world. With \nsuch examinations in place, schools and universities often \nteach to the test, prioritizing routine cognitive skills and \nknowledge acquisition (the types of knowledge being \nsupplanted by AI) over in-depth understanding and \nauthentic application. In fact, AI is already being developed to extend existing \nexamination practices. For example, AI-driven face \nrecognition, voice recognition, keyboard dynamics, and text \nforensics are increasingly being used to verify candidates in \nexaminations for distance learners.64 Although this might \nhave benefits for some students (e.g. those with disabilities \nwho find it challenging to attend face-to-face examinations), \nthese tools have not proved effective at scale, and they \nperpetuate rather than ameliorate the problems of exam-\nbased assessment practices. An alternative approach to assessment might be possible with \nAI tools designed to constantly monitor student progress, to \nprovide targeted feedback and assess the student’s mastery. All of this information might be collated throughout a \nstudent’s time in formal educational settings. While the use of \nAI-driven continuous assessment to replace high-stakes stop-\nand-test examinations may be attractive, it also illustrates \nthe two sides of applying AI in education : the benefits and \nthe challenges. Allowing students to demonstrate their \ncompetencies while they learn is advantageous in some \nrespects, but how this might be achieved without continuous \nmonitoring – i.e. surveillance – is less clear. Such monitoring \ninvolves many ethical concerns. AI-enabled record of lifelong learning \nachievements\nAn ‘AI-driven e-portfolio’ might be used to collate all of the \ncontinuous assessment information, recorded throughout \na student’s time in formal education, together with data on \nthe student’s engagement with non-formal learning (such \nas learning a musical instrument or a craft) and informal \nlearning (such as acquiring a language). This record would \nfunction as an intelligent and dynamic resumé that could be \nunderwritten and authenticated by blockchain technologies.65 \nIn this way, students would have a robust, accredited record \nof their learning experiences and achievements, potentially \nfar more detailed than a collection of exam certificates."
  },
  {
    "id": "c5aed7ff-846a-47e9-bce4-c6c19267bbf5",
    "filename": "documents\\376709eng.pdf",
    "page_number": 22,
    "chunk_id": "22_2",
    "chunk_text": "Allowing students to demonstrate their \ncompetencies while they learn is advantageous in some \nrespects, but how this might be achieved without continuous \nmonitoring – i.e. surveillance – is less clear. Such monitoring \ninvolves many ethical concerns. AI-enabled record of lifelong learning \nachievements\nAn ‘AI-driven e-portfolio’ might be used to collate all of the \ncontinuous assessment information, recorded throughout \na student’s time in formal education, together with data on \nthe student’s engagement with non-formal learning (such \nas learning a musical instrument or a craft) and informal \nlearning (such as acquiring a language). This record would \nfunction as an intelligent and dynamic resumé that could be \nunderwritten and authenticated by blockchain technologies.65 \nIn this way, students would have a robust, accredited record \nof their learning experiences and achievements, potentially \nfar more detailed than a collection of exam certificates. They would be able to share secure access to relevant parts \nof their e-portfolio with higher education providers and \nprospective employers. Beijing Consensus on Artificial Intelligence and Education\n20. Reaffirm that the guiding principle for achieving SDG 4 is lifelong \nlearning, which encompasses formal, non-formal and informal \nlearning. Adopt AI platforms and data-based learning analytics as \nkey technologies in building integrated lifelong learning systems to \nenable personalized learning anytime, anywhere and potentially for \nanyone, with respect for learners’ agency. Exploit the potential of AI to \nenable flexible learning pathways and the accumulation, recognition, \ncertification and transfer of individual learning outcomes. 21. Be mindful of the need to give appropriate policy attention to the \nneeds of older people, especially older women, and to engage them \nin developing the values and skills needed for living with AI in order \nto break the barriers to digital life. Plan and implement well-funded \nprogrammes to equip older workers with skills and options that enable \nthem to remain economically active for as long as they choose and to \nengage in their societies. (UNESCO, 2019a, p. 7)"
  },
  {
    "id": "a06929f1-0545-4f2d-b92a-5c1ad97edcf4",
    "filename": "documents\\376709eng.pdf",
    "page_number": 23,
    "chunk_id": "23_0",
    "chunk_text": "AI and education: Guidance for policy-makers – Understanding AI and education: Emerging practices and benefit-risk assessment\n20\n3.3 How can we ensure the ethical, inclusive and equitable use of AI in education? The ethical, inclusive and equitable use of AI in education \nimpacts upon each of the Sustainable Development \nGoals. There are issues centred on data and algorithms, on \npedagogical choices, on inclusion and the ‘digital divide’, \non children’s right to privacy, liberty and unhindered \ndevelopment, and on equity in terms of gender, disability, \nsocial and economic status, ethnic and cultural background, \nand geographic location. Emerging ethical and legal issues relating to \neducational data and algorithms\nThe widespread deployment of AI technologies brings \nmultiple risks and challenges, such as those centred on data \nownership (e.g. the exploitation of data for commercial \ngain), consent (e.g. whether students are capable, either \ndevelopmentally or legally, of giving genuinely informed \nconsent), and privacy (e.g. the use of intrusive emotion-\ndetection systems). Another risk is that algorithmic biases \nmight undermine basic human rights. There is also the \nadditional concern that AI data and expertise are being \naccumulated by a small number of international technology \nand military superpowers. Nonetheless, while the range of AI \ntechnologies in education is extensive and growing,\nAround the world, virtually no research has been \nundertaken, no guidelines have been agreed, no policies \nhave been developed, and no regulations have been enacted to \naddress the specific ethical issues raised by the use of artificial \nintelligence in education. (Holmes et al., 2018b, p. 552)\nAs with mainstream AI, concerns exist about the large \nvolumes of personal data collected to support the \napplication of AI in education – a process that has been called \n‘dataveillance’ (Lupton and Williamson, 2017). Who owns \nand who is able to access this data, what are the privacy \nand confidentiality concerns, and how should the data be \nanalysed, interpreted, and shared? All learners are susceptible \nto having their personal data misused or compromised, \nespecially given that less than 30% of countries across \nthe world (excluding Europe) have comprehensive data \nprotection laws in place. Another major concern is the potential for conscious or \nunconscious bias incorporated into AI algorithms (i.e. how the \ndata is analysed). In fact, algorithms are playing an increasingly widespread \nrole in society, automating a wide range of tasks ranging \nfrom decisions that impact whether someone gets a job \nto how long someone should remain in prison."
  },
  {
    "id": "5d67e333-5cc6-4614-8fbf-ea0c52766d86",
    "filename": "documents\\376709eng.pdf",
    "page_number": 23,
    "chunk_id": "23_1",
    "chunk_text": "Who owns \nand who is able to access this data, what are the privacy \nand confidentiality concerns, and how should the data be \nanalysed, interpreted, and shared? All learners are susceptible \nto having their personal data misused or compromised, \nespecially given that less than 30% of countries across \nthe world (excluding Europe) have comprehensive data \nprotection laws in place. Another major concern is the potential for conscious or \nunconscious bias incorporated into AI algorithms (i.e. how the \ndata is analysed). In fact, algorithms are playing an increasingly widespread \nrole in society, automating a wide range of tasks ranging \nfrom decisions that impact whether someone gets a job \nto how long someone should remain in prison. However, \npeople are increasingly recognising that algorithms are not \nas neutral as they are often presented; and that, for example, \nthey can automate biases with varying degrees of negative \nconsequences for individuals (Hume, 2017). Any biased analysis might impact negatively on the human \nrights of individual students (in terms of their gender, age, race, \nsocio-economic status, income inequality, and so on). However, \nthese particular ethical concerns, centred on data and bias, are \nthe ‘known unknowns’ and are the subject of much discussion \nin mainstream AI.66 But there are suggestions that leading \ntechnology companies’ interest in ‘ethics washing’ is growing, in \nan attempt to avoid national or international regulation (Hao, \n2019). We must also consider the ‘unknown unknowns’, those \nethical issues raised by the interaction of AI and education that \nhave yet to be identified. Ethical questions include:\n \n What criteria should be considered in defining and \ncontinuously updating the ethical boundaries of the collection \nand use of learners’ data?  How might schools, students, and teachers opt out from, or \nchallenge, their representation in large datasets?  What are the ethical implications of not being able to \neasily interrogate how AI makes decisions (using multi-level \nneural networks)?  What are the ethical obligations of private organizations \n(product developers) and public authorities (schools and \nuniversities involved in research)?  How does the transient nature of students’ interests and \nemotions as well as the complexity of the learning process \nimpact on the interpretation of data and ethics of AI applied in \neducational contexts?  What pedagogical approaches are ethically warranted? Beijing Consensus on Artificial Intelligence and Education \nEnsuring ethical, transparent and auditable use of education data and \nalgorithms:\n28."
  },
  {
    "id": "f79d2daf-9361-493e-9646-dc8c7d3577b1",
    "filename": "documents\\376709eng.pdf",
    "page_number": 23,
    "chunk_id": "23_2",
    "chunk_text": " What are the ethical implications of not being able to \neasily interrogate how AI makes decisions (using multi-level \nneural networks)?  What are the ethical obligations of private organizations \n(product developers) and public authorities (schools and \nuniversities involved in research)?  How does the transient nature of students’ interests and \nemotions as well as the complexity of the learning process \nimpact on the interpretation of data and ethics of AI applied in \neducational contexts?  What pedagogical approaches are ethically warranted? Beijing Consensus on Artificial Intelligence and Education \nEnsuring ethical, transparent and auditable use of education data and \nalgorithms:\n28. Be cognizant that AI applications can impose different kinds of bias that \nare inherent in the data the technology is trained on and uses as input, \nas well as in the way that the processes and algorithms are constructed \nand used. Be cognizant of the dilemmas of balancing between open \naccess to data and data privacy protection. Be mindful of the legal \nissues and ethical risks related to data ownership, data privacy and \ndata availability for the public good. Be mindful of the importance of \nadopting principles of ethics-, privacy- and security-by-design. 29. Test and adopt emerging AI technologies and tools for ensuring \nteachers’ and learners’ data privacy protection and data security. Support robust and long-term study of deeper issues of ethics in AI, \nensuring AI is used for good and preventing its harmful applications. Develop comprehensive data protection laws and regulatory \nframeworks to guarantee the ethical, non-discriminatory, equitable, \ntransparent and auditable use and reuse of learners’ data. 30. Adjust existing regulatory frameworks or adopt new ones to ensure \nresponsible development and use of AI tools for education and \nlearning. Facilitate research on issues related to AI ethics, data privacy \nand security, and on concerns about AI’s negative impact on human \nrights and gender equality. (UNESCO, 2019a, pp. 8-9)"
  },
  {
    "id": "c2d2efb6-0a11-4ff4-b797-12e960a1af1c",
    "filename": "documents\\376709eng.pdf",
    "page_number": 24,
    "chunk_id": "24_0",
    "chunk_text": "Understanding AI and education: Emerging practices and benefit-risk assessment – AI and education: Guidance for policy-makers \n21\nIn addition, the application of AI in education has been \ncriticised for being both intrusive and de-humanising: intrusive \nbecause some applications require continual monitoring \nof student actions, gestures and emotions; de-humanising \nbecause some AI requires students to fit into prescriptive \nmethods of teaching, with minimal human interaction, \nfollowing structured pathways of atomized content, which \nreduces learner agency. There are cases that have exposed \nethical controversies, such as recording lessons and using AI \nto analyse how the quality of classroom talk contributes to \nlearning (Kelly et al., 2018). The use of AI to identify learning \npatterns and problems is perhaps less ethically problematic \nif devices are not introduced to classrooms in an intrusive \nmanner. However, in some schools AI-driven classroom cameras \nare used to monitor student behaviour (Loizos, 2017). This \nhas crossed ethical boundaries because facial recognition \ntechnology is installed to check how attentive students \nare in class. Every movement of the students is watched by \nmultiple cameras positioned above the blackboard. The \nsystem works by identifying facial expressions and feeding that \ninformation into a computer to assess whether the students are \nconcentrating or if their minds are wandering. In one example, \nthe computer targets seven different emotions: neutral, happy, \nsad, disappointed, angry, scared and surprised. If it concludes \nthat the student is distracted, it will send a notification to the \nteacher to take action. However, these cameras have raised \nanxiety levels and changed students’ natural behaviours. Students have reported that they feel like a pair of mystery eyes \nare constantly watching them. Another AI-driven approach goes further still, by using \nelectroencephalography (EEG)67 sensors in headbands \nto detect brain activity when the student is engaged in a \ntask. Again, the developers claim that this technology has \nthe potential to improve learning – a claim that has been \nquestioned by neuroscientists. These headbands might \nlead to inaccurate results or unintended consequences. Of note is that, in October 2019, China’s Cyberspace \nAdministration and Ministry of Education introduced \nregulations designed to curb the use of AI-powered cameras, \nheadbands, and other devices in schools (Feng, 2019). These regulations require parental consent to be obtained \nbefore AI technologies are used with students. They also \nrequire all data to be encrypted."
  },
  {
    "id": "f0aa99a2-dd3c-40f1-8568-e9255efe2e32",
    "filename": "documents\\376709eng.pdf",
    "page_number": 24,
    "chunk_id": "24_1",
    "chunk_text": "Again, the developers claim that this technology has \nthe potential to improve learning – a claim that has been \nquestioned by neuroscientists. These headbands might \nlead to inaccurate results or unintended consequences. Of note is that, in October 2019, China’s Cyberspace \nAdministration and Ministry of Education introduced \nregulations designed to curb the use of AI-powered cameras, \nheadbands, and other devices in schools (Feng, 2019). These regulations require parental consent to be obtained \nbefore AI technologies are used with students. They also \nrequire all data to be encrypted. This has had the effect of \nhalting, although possibly only temporarily, the use of facial \nrecognition and EEG technologies in Chinese schools. In the Beijing Consensus, the ethics of AI in education are \narticulated in paragraphs 28 to 30. The Consensus also \nrecommends that all governments should develop and \nimplement regulatory frameworks to ensure the responsible \ndevelopment and use of AI tools for education and learning. This should build on UNESCO’s ‘Recommendation on the \nEthics of Artificial Intelligence’ (2020), which is currently \nin development. The divide between those with and without access to core \ndigital technologies, such as the Internet and AI, is a concern \nthat impacts upon each of the SDGs. To complicate matters, \nthis digital divide exists in many dimensions, for example: \nbetween developed and developing countries, between \ndifferent socio-economic groups within countries, between \nthe owners and users of the technologies, and between those \nwhose jobs are enhanced by AI and those whose jobs are \nsusceptible to being replaced. To focus briefly on one example, disparities in access to \ntelecommunications networks affect many people in \ndeveloping countries as well as people in rural settings in \ndeveloped countries. In addition, although broadband prices \nhave reduced significantly in recent years, digital services \nand devices remain unaffordable for many, creating a barrier \nto widespread AI uptake. In fact, poor broadband can lead \nto a vicious cycle: without broadband, there is limited \naccess to digital technologies, and those without access do \nnot appear in the data sets upon which machine learning \ndepends. In this way, the hopes, interests, and values of those \non the wrong side of the digital divide are excluded in the \nAI era, and new AI is unintentionally biased against them. The digital divide is further exacerbated by the increasing \nconcentration of power and profitability in a small number \nof international technology superpowers, across just a \nfew countries."
  },
  {
    "id": "844227d8-ee28-4f5c-b0a3-820e49ea9639",
    "filename": "documents\\376709eng.pdf",
    "page_number": 24,
    "chunk_id": "24_2",
    "chunk_text": "To focus briefly on one example, disparities in access to \ntelecommunications networks affect many people in \ndeveloping countries as well as people in rural settings in \ndeveloped countries. In addition, although broadband prices \nhave reduced significantly in recent years, digital services \nand devices remain unaffordable for many, creating a barrier \nto widespread AI uptake. In fact, poor broadband can lead \nto a vicious cycle: without broadband, there is limited \naccess to digital technologies, and those without access do \nnot appear in the data sets upon which machine learning \ndepends. In this way, the hopes, interests, and values of those \non the wrong side of the digital divide are excluded in the \nAI era, and new AI is unintentionally biased against them. The digital divide is further exacerbated by the increasing \nconcentration of power and profitability in a small number \nof international technology superpowers, across just a \nfew countries. Without effective policy intervention, the \ndeployment of AI in education is likely to mirror this inexorable \nprocess, inevitably magnifying rather than ameliorating existing \nlearning inequalities. Opportunities for AI to advance inclusion and equity \nin education\nIn addition to focusing on equitable access to AI technologies \nfor all, we also need to consider the potential of AI to help \nachieve SDG 4, to help ‘ensure inclusive and equitable quality \neducation and promote lifelong learning opportunities for \nall’. To achieve universal primary and secondary education \nby 2030, 68.8 million more teachers need to be recruited \nglobally (UNESCO, 2016). In this challenging context, many \nAI technologies might be used, or further developed, to help \nimprove education – especially for older people, refugees, \nmarginalized or isolated communities, and people with \nspecial educational needs.68 However, we must be cognisant \nthat increasing access to education remains predominantly \na political and social issue. AI technologies might help, but \nthey are unlikely to offer a solution. For example, focusing on \nAI technologies that replace teacher functions, rather than \nthose that augment teacher capabilities, might contribute \ntoward a short-term fix for contexts where teachers are scarce, \nbut might unintentionally exacerbate rather than address the \nlong-term challenges in achieving SDG 4. Accordingly, it is incumbent upon policy-makers to ensure \nthat the currently hyped potential of AI to improve education \nand learning is considered critically. To begin with, the"
  },
  {
    "id": "6c0225b2-833b-4ab2-9b16-021d99e3df42",
    "filename": "documents\\376709eng.pdf",
    "page_number": 25,
    "chunk_id": "25_0",
    "chunk_text": "AI and education: Guidance for policy-makers – Understanding AI and education: Emerging practices and benefit-risk assessment\n22\nBeijing Consensus on Artificial Intelligence and Education\n22. Reaffirm that ensuring inclusion and equity in and through education, \nand offering lifelong learning opportunities to all, are the cornerstones \nof achieving SDG 4 – Education 2030. Reaffirm that technological \nbreakthroughs in the field of AI in education are an opportunity to \nimprove access to education for the most vulnerable groups. 23. Ensure that AI promotes high-quality education and learning \nopportunities for all, irrespective of gender, disability, social or \neconomic status, ethnic or cultural background, or geographic \nlocation. The development and use of AI in education should not \ndeepen the digital divide and must not display bias against any \nminority or vulnerable groups. 24. Ensure that AI tools in teaching and learning enable the effective \ninclusion of students with learning impairments or disabilities and \nthose studying in a language other than their mother tongue. 33. Monitor and assess the impact of the AI divide and disparities in AI \ndevelopment across countries based on data voluntarily submitted \nby countries, and be mindful of the risks of polarization between \nthose who have access to AI and those who do not. Reiterate the \nimportance of addressing these concerns, giving special priority to \nAfrica, least developed countries (LDCs), small island developing \nstates (SIDS) and countries affected by conflict and disaster. 34. Coordinate collective actions to promote the equitable use of AI in \neducation in the context of the global and regional Education 2030 \narchitecture, including through sharing AI technology, programmes \nand resources for capacity-building, with due respect for human \nrights and gender equality. 35. Support forward-looking reviews of frontier issues related to \nthe implications of emerging AI development, and facilitate the \nexploration of effective strategies and practices for using AI to \ninnovate in education, with an aim of building an international \ncommunity with common views on AI and education. 36. Align international cooperation with national needs for the use of AI \nin education and for cross-sectoral cooperation, in order to enhance \nownership of the development of AI technology among AI professionals. Strengthen the sharing of information and promising practices, as well as \ncoordination and complementary actions among countries. (UNESCO, 2019a, pp."
  },
  {
    "id": "f2dcbaa9-2f9d-487e-9998-52df3bb74464",
    "filename": "documents\\376709eng.pdf",
    "page_number": 25,
    "chunk_id": "25_1",
    "chunk_text": "Support forward-looking reviews of frontier issues related to \nthe implications of emerging AI development, and facilitate the \nexploration of effective strategies and practices for using AI to \ninnovate in education, with an aim of building an international \ncommunity with common views on AI and education. 36. Align international cooperation with national needs for the use of AI \nin education and for cross-sectoral cooperation, in order to enhance \nownership of the development of AI technology among AI professionals. Strengthen the sharing of information and promising practices, as well as \ncoordination and complementary actions among countries. (UNESCO, 2019a, pp. 7 & 9)\nUNESCO's ROAM framework (‘Rights, Openness, Access and \nMulti-stakeholder Governance’) should be applied, to ensure \nthat the application of AI in education addresses broader \nhuman rights and emerging ethical issues in a holistic \nmanner (UNESCO, 2019b). For example, and in particular, \nAI in education should be made accessible to all citizens \n(irrespective of gender, disability, social or economic status, \nethnic or cultural background, or geographic location), \nespecially for vulnerable groups (such as refugees or \nstudents with learning disabilities), without exacerbating \nexisting inequalities. There are various examples of AI being used to advance \ninclusion and equity in education:\n \n The Global Digital Library,69 which uses Google Voice \nAssistant to enable people with literacy difficulties to search for \nbooks using only voice commands, and then to have the books \nread out loud to them, giving them access to knowledge; \n \n Dytective, an AI-powered screening tool using machine \nlearning for the early detection of dyslexia. Developed by \nChange Dyslexia, a Spanish company, it also provides a \ngame-based learning environment for practising 24 key \nliteracy skills;70\n \n AI-powered artificial voices for people who are unable \nto speak or who have speech impediments,71 sometimes \ndesigned to match the person’s original voice."
  },
  {
    "id": "a0524d31-f7d2-4e96-9194-3d506459635a",
    "filename": "documents\\376709eng.pdf",
    "page_number": 25,
    "chunk_id": "25_2",
    "chunk_text": "(UNESCO, 2019a, pp. 7 & 9)\nUNESCO's ROAM framework (‘Rights, Openness, Access and \nMulti-stakeholder Governance’) should be applied, to ensure \nthat the application of AI in education addresses broader \nhuman rights and emerging ethical issues in a holistic \nmanner (UNESCO, 2019b). For example, and in particular, \nAI in education should be made accessible to all citizens \n(irrespective of gender, disability, social or economic status, \nethnic or cultural background, or geographic location), \nespecially for vulnerable groups (such as refugees or \nstudents with learning disabilities), without exacerbating \nexisting inequalities. There are various examples of AI being used to advance \ninclusion and equity in education:\n \n The Global Digital Library,69 which uses Google Voice \nAssistant to enable people with literacy difficulties to search for \nbooks using only voice commands, and then to have the books \nread out loud to them, giving them access to knowledge; \n \n Dytective, an AI-powered screening tool using machine \nlearning for the early detection of dyslexia. Developed by \nChange Dyslexia, a Spanish company, it also provides a \ngame-based learning environment for practising 24 key \nliteracy skills;70\n \n AI-powered artificial voices for people who are unable \nto speak or who have speech impediments,71 sometimes \ndesigned to match the person’s original voice.  AI-powered automatic speech recognition and transcription \nto convert raw spoken language into fluent, punctuated text, \nand make live lectures more accessible for deaf and hard-of-\nhearing students;72\n \n AI and augmented reality applications to help deaf \nchildren read by translating texts into sign languages, such as \nStorySign,73 a mobile app developed by Huawei;\n \n AI-enabled ‘smart’ robots, such as speech-enabled robots \nfor learners on the autism spectrum,74 that provide predictable \nmechanical interactions to help learners develop their \ncommunication and social skills; \n \n Telepresence robots for students who are unable to attend \nschool (Heikkila, 2018); and\n \n AI-powered intelligent tutoring systems (ITS), the most \ncommon AI tools in education, some of which are used to \ndiagnose specific learning difficulties and personalize learning \npathways (ITS are discussed in section 3.1 on p. 15). The complexity of ensuring the inclusive and equitable \nuse of AI in education has been reflected in the Beijing \nConsensus. Guiding principles and strategies are \nrecommended to steer AI towards inclusion and equity."
  },
  {
    "id": "ee28d4b9-4c7d-4b98-96dd-68efeb311f5e",
    "filename": "documents\\376709eng.pdf",
    "page_number": 26,
    "chunk_id": "26_0",
    "chunk_text": "Understanding AI and education: Emerging practices and benefit-risk assessment – AI and education: Guidance for policy-makers \n23\nBeijing Consensus on Artificial Intelligence and Education\n6. We also recognize the distinctive features of human intelligence. Recalling the principles set forth in the Universal Declaration of Human \nRights, we reaffirm UNESCO’s humanistic approach to the use of AI with \na view towards protecting human rights and preparing all people with \nthe appropriate values and skills needed for effective human–machine \ncollaboration in life, learning and work. 17. Be mindful of the systemic and long-term transformation of the labour \nmarket, including its gender dynamics, due to AI adoption. Update and \ndevelop mechanisms and tools to identify current and future skills needs \nin relation to AI development, in order to ensure the relevance of curricula \nto changing economies, labour markets and societies. Integrate AI-\nrelated skills into the school curricula and qualifications of technical and \nvocational education and training (TVET) and higher education, taking into \nconsideration the ethical aspects and interrelated humanistic disciplines. 18. Be cognizant of the emergence of a set of AI literacy skills required \nfor effective human–machine collaboration, without losing sight of \nthe need for foundational skills such as literacy and numeracy. Take \ninstitutional actions to enhance AI literacy across all layers of society. 19. Set up mid- or long-term plans and take urgent actions to support \nhigher education and research institutions in developing or enhancing \ncourses and research programmes to foster local AI talent, in order to \ncreate a pool of local professionals who have the expertise to design, \nprogramme and develop AI systems. (UNESCO, 2019a, pp. 4 & 6)\n3.4 How can education prepare humans to live and work with AI? As we noted earlier, computers are better at tasks that depend \non data, pattern discovery, and statistical reasoning, while \nhumans continue to be more accomplished at tasks that require \nempathy, self-direction, common sense, and value judgements. In other words, helping students learn how to live effectively \nin a world increasingly impacted by AI requires a pedagogy \nthat, rather than focusing on what computers are good at \n(e.g. memorizing and computation), puts more emphasis on \nhuman skills (e.g. critical thinking, communication, collaboration \nand creativity) and the ability to collaborate with pervasive AI \ntools in life, learning, and work. As noted earlier, the Fourth Industrial Revolution is impacting \non many aspects of modern life, especially the labour market."
  },
  {
    "id": "67ef1ca6-526e-4bf7-ae08-4b3a69c6bef3",
    "filename": "documents\\376709eng.pdf",
    "page_number": 26,
    "chunk_id": "26_1",
    "chunk_text": "As we noted earlier, computers are better at tasks that depend \non data, pattern discovery, and statistical reasoning, while \nhumans continue to be more accomplished at tasks that require \nempathy, self-direction, common sense, and value judgements. In other words, helping students learn how to live effectively \nin a world increasingly impacted by AI requires a pedagogy \nthat, rather than focusing on what computers are good at \n(e.g. memorizing and computation), puts more emphasis on \nhuman skills (e.g. critical thinking, communication, collaboration \nand creativity) and the ability to collaborate with pervasive AI \ntools in life, learning, and work. As noted earlier, the Fourth Industrial Revolution is impacting \non many aspects of modern life, especially the labour market. In many countries, AI is already taking over standardized and \nrepetitive work, revolutionizing efficiencies but displacing many \njobs. Yet, according to some of the world’s leading consultancies,75 \nAI is also likely to create many new job opportunities and have an \noverall positive economic benefit, although they disagree about \nhow many jobs will be supplanted and created. Whatever the long-term outcomes, the very nature of \nemployment is likely to change (\"working life is impermanent \nand unpredictable\", Barrett, 2017), with millions of workers \nbeing significantly and often negatively affected. Many will \nhave to retrain; multiple careers in a lifetime is fast becoming \nthe new normal.76 At the same time, the skills gap77 between \nthose who can and cannot work with the new technologies \nwill continue to grow, such that increasing numbers of workers \nwill be excluded from the job market, and there will be a \n‘hollowing-out’ of the middle classes (Smith and Anderson, \n2014). The combination of opportunities and risks also requires \ncollective work to determine how developments can benefit \neverybody. The recent ILO report, ‘Work for a Brighter Future: \nGlobal Commission on the Future of Work’ (ILO, 2019) states: \nCountless opportunities lie ahead to improve the quality \nof working lives, expand choice, close the gender gap, \n[and] reverse the damages wreaked by global inequality. Yet none of \nthis will happen by itself. Without decisive action we will be \nsleepwalking into a world that widens existing inequalities \nand uncertainties."
  },
  {
    "id": "28aa3d94-6789-4ece-a4a0-dde9f7d25b0e",
    "filename": "documents\\376709eng.pdf",
    "page_number": 26,
    "chunk_id": "26_2",
    "chunk_text": "Many will \nhave to retrain; multiple careers in a lifetime is fast becoming \nthe new normal.76 At the same time, the skills gap77 between \nthose who can and cannot work with the new technologies \nwill continue to grow, such that increasing numbers of workers \nwill be excluded from the job market, and there will be a \n‘hollowing-out’ of the middle classes (Smith and Anderson, \n2014). The combination of opportunities and risks also requires \ncollective work to determine how developments can benefit \neverybody. The recent ILO report, ‘Work for a Brighter Future: \nGlobal Commission on the Future of Work’ (ILO, 2019) states: \nCountless opportunities lie ahead to improve the quality \nof working lives, expand choice, close the gender gap, \n[and] reverse the damages wreaked by global inequality. Yet none of \nthis will happen by itself. Without decisive action we will be \nsleepwalking into a world that widens existing inequalities \nand uncertainties. In fact, if the world is to ensure that AI does not exacerbate \nexisting inequalities, it will be increasingly important for \nevery citizen to have the opportunity to develop a robust \nunderstanding of AI – what it is, how it works, and how \nit might impact on their lives. This is sometimes called ‘AI \nliteracy’. For this, teachers will play a key role, and educational \nprovision will have to shift toward supporting lifelong \nlearning so that people can build their agency, employability, \nand ability to contribute to society. In other words, education \nand training approaches worldwide will need to take a \nsystem-wide response to help prepare all citizens to live and \nwork harmoniously in the AI era. Mainstreaming the necessary human values and skills will \nrequire a system-wide, even a society-wide, framework \ninvolving several complementary dimensions: \n(i) \nfacilitating lifelong learning, so that everyone \n(especially older people) gains a robust understanding of \nAI78 (in particular, how data are selected, manipulated by AI \nalgorithms, and interpreted, and how this may be biased) \nand its implications for individuals and wider society; \n(ii) \nintegrating fundamental AI learning into K-12 school \ncurricula79 (including computational thinking, data and \nalgorithm literacy, coding and statistics, to enable young \npeople to generate their own AI tools), which we look at in \nmore detail later;"
  },
  {
    "id": "94ca4db3-6d35-48f9-8cf0-0a39eea9c96e",
    "filename": "documents\\376709eng.pdf",
    "page_number": 27,
    "chunk_id": "27_0",
    "chunk_text": "AI and education: Guidance for policy-makers – Understanding AI and education: Emerging practices and benefit-risk assessment\n24\n(iii) training the next generation of AI professionals to \naddress the growing skills gap and fill the AI jobs being \ncreated worldwide; \n(iv) fostering higher education and research institutions to \ndevelop ground-breaking equitable AI; \n(v) \nensuring that the growing AI workforce is diverse and \ninclusive (involving women and other groups that are often \nexcluded); and \n(vi) anticipating the emerging needs of employees and \nemployers and providing opportunities for on-the-job \nupskilling or reskilling (as AI automates low-skill and middle-\nskill functions). There are various promising examples of programmes to \nprepare humans to live and work with AI, which include \nhelping very young learners to build AI skills. Meanwhile, \nvarious AI platforms and tools are also being produced to \nsupport these skills:\n \n In China, ‘algorithms and computational thinking’ has \nbeen included in the Ministry of Education’s ‘ICT Curriculum \nStandards for Senior High School’ (Ministry of Education, \nPeople's Republic of China, 2017), while the 'Innovative \nAction Plan for Artificial Intelligence in Higher Education \nInstitutions' (Ministry of Education, People's Republic of \nChina, 2018) aims to enhance the AI capability of China’s \nuniversities. In addition the Ministry has released a pilot \nprogramme ‘AI Boosts Teachers’ Team Development’ which \naims to enhance innovation in teacher education.  In the United States of America, the Montour School \nDistrict in Pennsylvania teaches AI coding to children, \nproviding students with opportunities to experience \ndesigning AI to increase the public good.80\n \n In Singapore, humanoid robots (such as Nao53 and \nPepper)54 are being used in kindergarten classes to \nintroduce children to programming and other STEM subjects \n(Graham, 2018).  In the United Kingdom and Kenya, the Teens In AI \ninitiative81 aims to inspire the next generation of AI \nresearchers, entrepreneurs and leaders. It gives young \npeople exposure to socially-aware AI deployment, through \na combination of hackathons, accelerators, bootcamps \nand mentoring.  In Singapore, the SkillsFuture82 initiative focuses on digital \nupskilling and reskilling. In particular, it provides skill sets for \nAI scientists and engineers and a foundational understanding \nof AI, including how to live well in an AI world.  In Finland, an AI application called Headai was \ndeveloped in association with Helsinki Metropolitan \nUniversity of Applied Sciences."
  },
  {
    "id": "a02653c0-2aa7-435c-a2c4-53e978c3bf05",
    "filename": "documents\\376709eng.pdf",
    "page_number": 27,
    "chunk_id": "27_1",
    "chunk_text": " In the United Kingdom and Kenya, the Teens In AI \ninitiative81 aims to inspire the next generation of AI \nresearchers, entrepreneurs and leaders. It gives young \npeople exposure to socially-aware AI deployment, through \na combination of hackathons, accelerators, bootcamps \nand mentoring.  In Singapore, the SkillsFuture82 initiative focuses on digital \nupskilling and reskilling. In particular, it provides skill sets for \nAI scientists and engineers and a foundational understanding \nof AI, including how to live well in an AI world.  In Finland, an AI application called Headai was \ndeveloped in association with Helsinki Metropolitan \nUniversity of Applied Sciences. It monitors and analyses \njob advertisements and the university’s curricula to create \ncompetency maps83 that compare the demand and supply of \nAI skills, which in turn enables the university to quickly pivot \nits courses to address the needs of the market.  The US AI4K1284 initiative, jointly sponsored by the \nAssociation for the Advancement of Artificial Intelligence \n(AAAI) and the Computer Science Teachers Association \n(CSTA), provides a set of resources designed to help teachers \nintroduce their students to AI.  UNESCO's 'Teaching AI for K12'85 portal, which brings \ntogether AI teaching resources from around the world for \nany teacher, or home-schooler, to use to help their students \nlearn about AI.  Free online courses have been designed to familiarize \ncitizens with how AI works. These include:\n – Elements of AI:86 a series of free online courses created \nby Reaktor and the University of Helsinki. The courses \nare available in several languages and aim to encourage \npeople to learn what AI is, what it can and cannot do, and \nhow to start creating AI methods. – OKAI:87 a series of online courses available in English \nand Chinese. The project aims to demystify AI and \nintroduce its concepts to an audience with limited or no \nbackground in computer science. It utilizes web-based \ninteractive graphics and animations to illustrate the \nworking principles of AI. – AI-4-All:88 a US-based non-profit programme dedicated \nto increasing diversity and inclusion in AI education, \nresearch, development, and policy, with the aim of \ncreating more access for under-represented people in the \nfield of AI."
  },
  {
    "id": "fc599d39-247d-4116-97ea-2f2d44643cde",
    "filename": "documents\\376709eng.pdf",
    "page_number": 28,
    "chunk_id": "28_0",
    "chunk_text": "The challenges of harnessing AI to achieve SDG 4 – AI and education: Guidance for policy-makers \n25\n4. The challenges of harnessing AI to achieve SDG 4\nDespite the potential of AI for education, there are many challenges specific to harnessing AI to \nachieve SDG 4. There are also broader obstacles that society must surmount to unleash the \npotential of AI and mitigate its downsides, and build future-proof education systems. To begin \nwith, AI’s impact on students, teachers and wider society is yet to be determined. This includes \nquestions about the efficacy of AI interventions, the choice of pedagogies used in AI tools, \nstudents’ privacy, teachers’ jobs, and what we should be teaching at schools and universities. In this chapter, we briefly explore some of the key issues that still need to be addressed. 4.1 Data ethics and algorithmic biases \nAs has been discussed, data is at the heart of contemporary \napproaches to AI, which raises numerous challenging issues \ncentred on data protection, privacy, and ownership, and on \ndata analysis. These ethical issues have received a great deal \nof attention (summarized by Jobin et al., 2019). Similarly, the \nethics of educational data has also been the focus of much \nresearch (e.g. Ferguson et al., 2016), raising further issues \ncentred on informed consent, the management of data, and \nperspectives (e.g. institutional vs individual) on data. Any \napplication of AI in educational contexts should properly \naddress these many data issues, together with other issues \nspecific to education, such as choice of pedagogy. In addition, it has long been recognized that by design, AI \namplifies hidden features of its initial data and effectively \nreinforces its underlying assumptions. In particular, \nif the algorithms \nare trained on data which contains human bias then of \ncourse the algorithms will learn it, but furthermore they \nare likely to amplify it. This is a huge problem, especially if people \nassume that algorithms are impartial. (Douglas, 2017) \nIn short, AI is not biased in itself. Instead, if its data are biased \nor analysed with inappropriate algorithms, the original and \nperhaps unidentified biases can become more noticeable \nand have a greater impact. Making the biases noticeable \nis probably helpful, because it can lead to corrections, but \nallowing the biases to have a greater impact can lead to \nprejudicial outcomes and so should be carefully mitigated."
  },
  {
    "id": "2aac68d8-ad56-4df3-bb50-66518e5bb5c3",
    "filename": "documents\\376709eng.pdf",
    "page_number": 28,
    "chunk_id": "28_1",
    "chunk_text": "In particular, \nif the algorithms \nare trained on data which contains human bias then of \ncourse the algorithms will learn it, but furthermore they \nare likely to amplify it. This is a huge problem, especially if people \nassume that algorithms are impartial. (Douglas, 2017) \nIn short, AI is not biased in itself. Instead, if its data are biased \nor analysed with inappropriate algorithms, the original and \nperhaps unidentified biases can become more noticeable \nand have a greater impact. Making the biases noticeable \nis probably helpful, because it can lead to corrections, but \nallowing the biases to have a greater impact can lead to \nprejudicial outcomes and so should be carefully mitigated. 4.2 Gender-equitable AI and AI for gender equality\nBeijing Consensus on Artificial Intelligence and Education \n25. Underline that the gender gap in digital skills contributes to the low \nshare of women among AI professionals and exacerbates existing \ngender inequalities. 26. Affirm our commitment to developing AI applications in education \nthat are free from gender bias and ensuring that the data used for AI \ndevelopment are gender sensitive. AI applications should drive the \npromotion of gender equality. 27. Promote gender equality in the development of AI tools and empower \ngirls and women with AI skills to promote gender equality among \nworkforces and employers. (UNESCO, 2019a, p. 8)\nIf AI is to be of genuine benefit to society, every effort must be \ntaken to ensure that fairness and gender equality are among \nits fundamental principles. Yet, various uses of AI have been \nshown to be gender biased. For example, in 2018 the tech \ngiant Amazon abandoned the use of machine learning in \nits recruitment because it was systematically discriminating \nagainst female candidates. The root cause was the fact that \nthe original data, based on historical records of the company’s \nrecruitment, had always been unknowingly biased against \nwomen. The AI, in automating selection, inevitably amplified \nand made obvious those original prejudices. Some have \nsuggested that Amazon should not have abandoned their use \nof AI in recruitment but instead should have worked to address \nthe bias."
  },
  {
    "id": "c76aa70f-cf5a-4679-b55b-d314c282003e",
    "filename": "documents\\376709eng.pdf",
    "page_number": 28,
    "chunk_id": "28_2",
    "chunk_text": "Yet, various uses of AI have been \nshown to be gender biased. For example, in 2018 the tech \ngiant Amazon abandoned the use of machine learning in \nits recruitment because it was systematically discriminating \nagainst female candidates. The root cause was the fact that \nthe original data, based on historical records of the company’s \nrecruitment, had always been unknowingly biased against \nwomen. The AI, in automating selection, inevitably amplified \nand made obvious those original prejudices. Some have \nsuggested that Amazon should not have abandoned their use \nof AI in recruitment but instead should have worked to address \nthe bias. Another example centres on the development of AI \npersonal assistants, such as Apple’s Siri,20 Amazon’s Alexa,21 and \nBaidu’s DuerOS.22 Many of these tools are given female names \nand voices, leading to subtle but serious implications: \nWith their female names, voices and programmed \nflirtatiousness, the design of virtual personal assistants \nreproduces discriminatory stereotypes of female secretaries who, \naccording to the gender stereotype, is often more than just a \nsecretary to her male boss. It also reinforces the role of women as \nsecondary and submissive to men. These AI assistants operate on \nthe command of their user. They have no right to refuse these \ncommands. They are programmed only to obey. Arguably, they \nalso raise expectations for how real women ought to behave. (Adams, 2019)"
  },
  {
    "id": "3d83a103-4c29-4117-8b99-943a6da3987c",
    "filename": "documents\\376709eng.pdf",
    "page_number": 29,
    "chunk_id": "29_0",
    "chunk_text": "AI and education: Guidance for policy-makers – The challenges of harnessing AI to achieve SDG 4\n26\nWhat the impact might be of using these gender-stereotyped \ntechnologies in classrooms is an open question. Addressing these issues of gender equity is a critical goal \nthat is only likely to be realized if women are adequately \nrepresented in the AI workforce, which is itself the subject of \nmuch disquiet. A recent LinkedIn analysis revealed that only \n22% of AI professionals globally are female (World Economic \nForum, 2018). Advancing women’s representation in AI is \nessential for fundamental human rights and to help prevent \nthe proliferation and amplification of AI-driven biases. 4.3 Monitoring, evaluation and research into the use of AI in education\nAlthough the application of AI in education has been researched \nfor more than 50 years, it is notable that it still remains relatively \nuncommon in schools and universities—even in developed \ncountries. In fact, it is not even clear yet whether the technologies \nbeing imported into education are actually up to the task. Much of what exists now as “evidence-based” is mostly \nrelated to how AI can work in education in a technical \ncapacity without pausing to ask and comprehensively answer the \nquestion of whether AI is needed in education at all. (Nemorin, 2021)\nThere are few examples of cumulative or replicable research \non the application of AI in education, and little available robust \nevidence of its efficacy at scale, although some ITS have been \nshown to be broadly effective when compared against traditional \nclassroom teaching (du Boulay, 2016). In fact, the purported \nefficacy of many AI tools may be due more to their novelty than \ntheir substance. We simply do not have sufficient evidence \n(Holmes et al., 2018a). While there appears little doubt that AI will have a major impact \non the delivery and management of educational opportunities, \ncontent and outcomes, we are still unsure about how AI \nsolutions can improve those outcomes, and whether they can \nhelp scientists better understand how learning happens. In particular, many have suggested that AI has a major role to \nplay in addressing the educational problems, such as rising \ninequities, caused by the COVID-19 school closures. During \nthe early months of the pandemic, many commercial AI in \neducation companies reported large increases in registered \nusers."
  },
  {
    "id": "185f9a01-5328-4fbb-8ea5-2de2f8314875",
    "filename": "documents\\376709eng.pdf",
    "page_number": 29,
    "chunk_id": "29_1",
    "chunk_text": "In fact, the purported \nefficacy of many AI tools may be due more to their novelty than \ntheir substance. We simply do not have sufficient evidence \n(Holmes et al., 2018a). While there appears little doubt that AI will have a major impact \non the delivery and management of educational opportunities, \ncontent and outcomes, we are still unsure about how AI \nsolutions can improve those outcomes, and whether they can \nhelp scientists better understand how learning happens. In particular, many have suggested that AI has a major role to \nplay in addressing the educational problems, such as rising \ninequities, caused by the COVID-19 school closures. During \nthe early months of the pandemic, many commercial AI in \neducation companies reported large increases in registered \nusers. However, there remains little evidence that these systems \nwere being used for much more than virtual child-minding, \nor that young people gained much from engaging with them. Accordingly, before policy-makers assume that AI can solve the \neducational problems caused by the pandemic, much further \nresearch and evaluation is required to distinguish the reality \nfrom the hyperbole. Ultimately, AI is likely to be able to play \na useful role, but at present we simply do not have enough \ninformation to know how helpful it will be. Beijing Consensus on Artificial Intelligence and Education \n15. Support school-wide pilot tests on the use of AI to facilitate \ninnovation in teaching and learning, drawing lessons from successful \ncases and scaling up evidence-based practices. 31. Be mindful of the lack of systematic studies on the impacts of AI \napplications in education. Support research, innovation and analysis \non the effects of AI on learning practices and outcomes, and on \nthe emergence and validation of new forms of learning. Take an \ninterdisciplinary approach to research on AI in education. Encourage \ncross-national comparative research and collaboration. 32. Consider the development of monitoring and evaluation mechanisms \nto measure the impact of AI on education, teaching and learning, in \norder to provide a valid and robust evidence-based foundation for \npolicy-making. (UNESCO, 2019a, pp. 6 & 9)"
  },
  {
    "id": "584593c6-2731-4571-88ad-f7bdb2eb3e73",
    "filename": "documents\\376709eng.pdf",
    "page_number": 30,
    "chunk_id": "30_0",
    "chunk_text": "The challenges of harnessing AI to achieve SDG 4 – AI and education: Guidance for policy-makers \n27\n4.4 What impact will AI have on teacher roles? Beijing Consensus on Artificial Intelligence and Education \n12. Be mindful that while AI provides opportunities to support teachers in \ntheir educational and pedagogical responsibilities, human interaction and \ncollaboration between teachers and learners must remain at the core of \neducation. Be aware that teachers cannot be displaced by machines, and \nensure that their rights and working conditions are protected. 13. Dynamically review and define teachers’ roles and required competencies \nin the context of teacher policies, strengthen teacher training institutions, \nand develop appropriate capacity-building programmes to prepare \nteachers to work effectively in AI-rich education settings. (UNESCO, 2019a, p. 5)\nDespite the commercial aims of using intelligent tutorial \nsystems to do teacher tasks, it is still unlikely that teachers \nwill be replaced by machines any time soon. Nonetheless, \nthe ambition of many AI developers is to relieve teachers of \nvarious burdens (such as monitoring progress and marking \nassignments), so that they may focus on the human aspects of \nteaching (such as social engagement, interacting with empathy, \nand offering personal guidance). However, as AI functionalities \nimprove, they will inevitably relieve teachers of increasing \nnumbers of burdens. Accordingly, as the AI tools take over the \nknowledge transmission tasks, facilitating students’ lower-order \nthinking, teachers will play a reduced role. Theoretically, this will \nallow teachers to focus more on the design and facilitation of \nlearning activities that require higher-order thinking, creativity, \ninterpersonal collaboration, and social values – although, no \ndoubt, AI developers are already working to automate these \ntasks too. Accordingly, to ensure that teachers continue their \ncritical role in the education of young people policy-makers \nmust review strategically how AI might transform teachers’ \nroles, and how teachers might prepare to work in AI-rich \neducation environments. 4.5 What impact will AI have on learner agency? Even if the dystopian scenario of replacing teachers with AI is \navoided, learners’ agency might be undermined by more use \nof adaptive AI in education. This means less time for learners \nto interact with each other, more decisions made by machines, \nand more focus on the type of knowledge that is easiest to \nautomate."
  },
  {
    "id": "511ec062-e159-46d1-ba01-4017d7b0ccee",
    "filename": "documents\\376709eng.pdf",
    "page_number": 30,
    "chunk_id": "30_1",
    "chunk_text": "Theoretically, this will \nallow teachers to focus more on the design and facilitation of \nlearning activities that require higher-order thinking, creativity, \ninterpersonal collaboration, and social values – although, no \ndoubt, AI developers are already working to automate these \ntasks too. Accordingly, to ensure that teachers continue their \ncritical role in the education of young people policy-makers \nmust review strategically how AI might transform teachers’ \nroles, and how teachers might prepare to work in AI-rich \neducation environments. 4.5 What impact will AI have on learner agency? Even if the dystopian scenario of replacing teachers with AI is \navoided, learners’ agency might be undermined by more use \nof adaptive AI in education. This means less time for learners \nto interact with each other, more decisions made by machines, \nand more focus on the type of knowledge that is easiest to \nautomate. This could deprive learners of opportunities to \ncultivate their resourcefulness, self-efficacy, self-regulation, \nmetacognition, critical thinking, independent thought and \nother 21st century skills that are key to developing the whole \nperson (World Economic Forum and Boston Consulting Group, \n2016). It is currently unknown what long-term effects this will \nhave on student, civic and educational formulations. One ITS, Summit Learning, which was developed by engineers \nfrom Facebook and is being used in around 400 schools, \nhas been the focus of student protests and boycotts. In \nmore than one school, the students walked out in protest \nsaying that they didn’t have a good experience using the \nprogramme, which required hours of classroom time sitting in \nfront of computers. They were especially concerned that the \nprogramme eliminated much of the human interaction and \nteacher support needed to develop critical thinking (Robinson \nand Hernandez, 2018). The Chan Zuckerberg Initiative, which \nfunded the Summit Learning project, disputes these claims. In addition, as already noted, AI amplifies hidden features \nof its initial data and effectively reinforces its underlying \nassumptions. In this respect, rule-based and machine-learning \nAI technologies are similar (Holmes et al., 2019). Their very \ndesign, their implementation of mostly instructionist methods \nthat focus on knowledge transfer and content delivery while \nignoring contextual and social factors, amplifies existing yet \ncontested assumptions about approaches to teaching and \nlearning. This is a critical set of issues with which the AI-in-\neducation community needs to fully engage. All applications of \nAI in education should enhance, not threaten, what it means to \nbe fully human."
  },
  {
    "id": "f5d1be18-eef0-4f76-893b-bd111560ca3f",
    "filename": "documents\\376709eng.pdf",
    "page_number": 31,
    "chunk_id": "31_0",
    "chunk_text": "AI and education: Guidance for policy-makers – A review of policy responses\n28\n5. A review of policy responses\nAs noted by the OECD,89 there exists more than 300 AI policy \ninitiatives from 60 countries all around the world, and from \nthe EU. Most of these make some reference to education. For example, many refer to the need for AI capacity building \n(i.e. 'learning about AI'), although mostly in Higher Education. Some also mention the retraining that is becoming increasingly \nnecessary to mitigate the impact of AI on workers. However, despite SDG 4, few initiatives focus on learning \nabout AI in K12 contexts, how AI is being implemented in \neducation (i.e. 'learning with AI'), or preparing citizens to \nlive in a world increasingly impacted on by AI (i.e. 'learning \nfor human-AI collaboration'). In this chapter we summarize some national and regional \npolices that do specifically address AI and education, to \ninform the work of decision-makers in other countries as \nthey develop strategies by building on existing generic \nAI initiatives. 5.1 Approaches to policy responses\nCross-national and regional policies addressing AI and \neducation developments are diverse, but may be loosely \ncategorized as adopting one of three approaches: independent, \nintegrated or thematic (see Table 3).  Independent approach \nHaving stand-alone AI policies and strategies, such as the EU’s \n‘The Impact of Artificial Intelligence on Learning, Teaching, \nand Education’ (Tuomi, 2018), and China’s (2017) ‘New-\nGeneration Artificial Intelligence Development Plan’.  Integrated approach \nIntegrating the elements of AI into existing Education or \nICT policies and strategies, such as Argentina’s ‘Aprender \nConectados’ (Ministry of Education, Argentina, 2017).  Thematic approach \nFocusing on one specific topic relating to AI and education, \nsuch as the EU’s General Data Protection Regulation (GDPR). Each of these three approaches will now be explored in \nmore detail. Independent approach \n \n In 2016, the United States launched the ‘National \nArtificial Intelligence Research and Development Strategic \nPlan’. With regard to AI in education, the plan emphasizes \nimproving educational opportunities and quality of life. More \nspecifically, it argues that (i) adaptive automated tutoring \ncan become universally available, by means of AI-enhanced \nlearning technologies; (ii) AI tutors can complement human \nteachers, helping to provide advanced and remedial learning \nappropriate to the individual; and (iii) AI tools can foster \nlifelong learning and the acquisition of new skills for all \nmembers of society."
  },
  {
    "id": "ef8239ef-d2bc-4750-a5c2-7dd19a37d36f",
    "filename": "documents\\376709eng.pdf",
    "page_number": 31,
    "chunk_id": "31_1",
    "chunk_text": " Thematic approach \nFocusing on one specific topic relating to AI and education, \nsuch as the EU’s General Data Protection Regulation (GDPR). Each of these three approaches will now be explored in \nmore detail. Independent approach \n \n In 2016, the United States launched the ‘National \nArtificial Intelligence Research and Development Strategic \nPlan’. With regard to AI in education, the plan emphasizes \nimproving educational opportunities and quality of life. More \nspecifically, it argues that (i) adaptive automated tutoring \ncan become universally available, by means of AI-enhanced \nlearning technologies; (ii) AI tutors can complement human \nteachers, helping to provide advanced and remedial learning \nappropriate to the individual; and (iii) AI tools can foster \nlifelong learning and the acquisition of new skills for all \nmembers of society.  In 2016, the Republic of Korea launched the ‘Mid- to \nLong-Term Plan in Preparation for the Intelligent Information \nSociety’. This plan includes the training of 5,000 new AI \ngraduates every year, beginning in 2020, to add 50,000 new AI \nspecialists to its talent pool by 2030.  In 2017, China launched the ‘New-Generation Artificial \nIntelligence Development Plan’. It argues for what it calls \n‘intelligent education’. Specifically, the plan involves making \nuse of AI to (i) develop a new education system that involves \nthe reform of educational practices and delivers intelligent \nand interactive learning; (ii) carry out intelligent campus \nconstruction and promote AI in teaching, management \nand resource construction; (iii) develop a three-dimensional \ncomprehensive teaching methodology and an intelligent online \nlearning platform based on big data; (iv) develop AI assistants \nand establish a comprehensive educational analysis system; \nand (v) establish a learner-centred education environment, and \nachieve personalized education for every learner.  In 2017, the United Arab Emirates (UAE) launched the \n‘UAE Strategy for Artificial Intelligence’. This plan covers the \ndevelopment and application of AI in nine main sectors, one \nof which is education. It emphasizes the potential of AI to \nreduce costs and enhance learning.  In 2018, the EU released ‘The Impact of Artificial \nIntelligence on Learning, Teaching, and Education’, a \ndocument that firstly addresses the impact of AI on learning, \nespecially on the human cognitive capacities of children and \nadults. It argues that AI can support existing cognitive skills, \nspeed up cognitive development and create new capacities, \nand might reduce the importance of some capacities or \nmake them obsolete."
  },
  {
    "id": "3ae717f8-fe97-491c-9efd-3e33c8bfedf0",
    "filename": "documents\\376709eng.pdf",
    "page_number": 31,
    "chunk_id": "31_2",
    "chunk_text": " In 2017, the United Arab Emirates (UAE) launched the \n‘UAE Strategy for Artificial Intelligence’. This plan covers the \ndevelopment and application of AI in nine main sectors, one \nof which is education. It emphasizes the potential of AI to \nreduce costs and enhance learning.  In 2018, the EU released ‘The Impact of Artificial \nIntelligence on Learning, Teaching, and Education’, a \ndocument that firstly addresses the impact of AI on learning, \nespecially on the human cognitive capacities of children and \nadults. It argues that AI can support existing cognitive skills, \nspeed up cognitive development and create new capacities, \nand might reduce the importance of some capacities or \nmake them obsolete. Secondly, it addresses the need for \nfuture-oriented vision regarding AI, and the impact of AI on \nthe future of learning, especially on AI-generated student \nmodels and new pedagogical opportunities. Furthermore, \nthis document emphasizes that AI is likely to have a \nprofound impact on a systemic level. It acknowledges that \nAI is just one aspect of the ongoing broader transformations \nknown as the Fourth Industrial Revolution. In order to cope \nin such a context, the authors argue that it is essential to \nrethink the role of education in society, how it might be \norganized, and what aims and needs it should address."
  },
  {
    "id": "a276dc9f-b2c4-48df-9bff-ea33a1eed1bb",
    "filename": "documents\\376709eng.pdf",
    "page_number": 32,
    "chunk_id": "32_0",
    "chunk_text": "A review of policy responses – AI and education: Guidance for policy-makers \n29\n \n In 2019, Malta launched 'Towards an AI Strategy'. This is \nbuilt on three strategic pillars: (i) investment, start-ups and \ninnovation; (ii) public sector adoption; and (iii) private sector \nadoption, with education being a key enabler. It states that \nthe country’s education system must \nEvolve and adapt to the requirements of the Fourth \nIndustrial Revolution. A high percentage of young \nchildren today learn to expertly interact with electronic \ndevices and navigate mobile operating systems, before they can \nspeak. They grow up viewing technology as integral to their life. In fact, they are rarely sentimental about the idea of ‘disconnecting’, \nhaving never known a world without continuously streamed \npersonalized content to an always-connected mobile device. As such, \ndigital tools are commonplace across most of Malta’s schools, with \nteachers augmenting the educational experience with interactive \nwhiteboards and tablets. However… Malta must [also] consider how \nto expand the curriculum itself and better prepare children for a \nfuture workplace where decision making is assisted, supported and \nenhanced by the application of AI. (Government of Malta, 2019)\nIntegrated approach\n \n In 2016, Malaysia launched the #mydigitalmaker \nmovement, which integrates computational thinking in its \neducational programme. It proposes collaborations across \nthe private sector, public sector and academia to ‘help \ncreate and encourage the development of digital making \ncurriculums that are mapped to the objectives set by the \nMinistry of Education’ (Ministry of Education & Malaysia \nDigital Economy Corporation, 2017) (Pedro et al., 2019).  In 2017, Argentina launched 'Aprender Conectados', which \naims to integrate digital learning across all levels of compulsory \neducation. It proposed that all schools should embed \nprogramming and robotics by 2019. The curriculum prescribes \nspecific, age-appropriate learning competencies at each level, \nfrom pre-school to secondary school, building towards full \ncompetency in using computing methods and techniques, \nindividually and collaboratively, to solve problems. Thematic approach\n \n In 2016, the EU Parliament approved the 'General Data \nProtection Regulation' (GDPR), which came into force in 2018. It is designed to (i) harmonize data privacy laws across Europe; \n(ii) protect the data privacy of all EU citizens; and (iii) reshape \nthe way organizations across Europe approach data privacy."
  },
  {
    "id": "68b97108-2044-4765-a297-8e7122962619",
    "filename": "documents\\376709eng.pdf",
    "page_number": 32,
    "chunk_id": "32_1",
    "chunk_text": " In 2017, Argentina launched 'Aprender Conectados', which \naims to integrate digital learning across all levels of compulsory \neducation. It proposed that all schools should embed \nprogramming and robotics by 2019. The curriculum prescribes \nspecific, age-appropriate learning competencies at each level, \nfrom pre-school to secondary school, building towards full \ncompetency in using computing methods and techniques, \nindividually and collaboratively, to solve problems. Thematic approach\n \n In 2016, the EU Parliament approved the 'General Data \nProtection Regulation' (GDPR), which came into force in 2018. It is designed to (i) harmonize data privacy laws across Europe; \n(ii) protect the data privacy of all EU citizens; and (iii) reshape \nthe way organizations across Europe approach data privacy.  In 2017, the EU launched the 'European Digital \nCompetence Framework' ('DigComp') (Carretero et al., \n2017), in which digital competence is understood to include \n(i) information and data literacy; (ii) communication and \ncollaboration; (iii) digital content creation; (iv) safety; and (v) \nproblem solving. TABLE 3: OVERVIEW OF POLICY GUIDELINES ASSOCIATED WITH AI IN EDUCATION\nAPPROACHES\nIndependent\nIntegrated \nThematic\nArgentina\nAprender Conectados (Ministry of Education, \nArgentina, 2017)\nChina \nNext Generation Artificial Intelligence Plan \n(Government of the People’s Republic of \nChina, 2017). New ICT Curriculum Standards for Senior High \nSchool (Ministry of Education, People's Republic of \nChina, 2017)\nInnovative Action Plan for Artificial Intelligence in \nHigher Education Institutions (Ministry of Education, \nPeople's Republic of China, 2018)\nEstonia\nProgeTiger Programme (HITSA, 2017)\nEuropean Union\nThe Impact of Artificial Intelligence on Learning, \nTeaching, and Education (Tuomi, 2018)\nGDPR (European Union, 2016, 2018)\nDigComp (Carretero et al., 2017)\nMalaysia\n#mydigitalmaker (Ministry of Education & Malaysia \nDigital Economy Corporation, 2017)\nMalta\nTowards an AI Strategy. High-level policy document \nfor public consultation (Government of Malta, 2019)\nRepublic \nof Korea\nMid- to Long-Term Plan in Preparation for the \nIntelligent Information Society (Government of the \nRepublic of Korea, 2016)\nSingapore\nCode@SG Movement-Developing Computational \nThinking as a National Capability (Infocomm Media \nDevelopment Authority, 2017)\nUnited \nArab Emirates\nUAE Strategy for Artificial Intelligence (United Arab \nEmirates, 2017)\nUnited States \nof America\nNational Artificial Intelligence Research and \nDevelopment Strategic Plan (National Science and \nTechnology Council, 2016)"
  },
  {
    "id": "5482d5e2-1074-41bd-aefc-608004b4bceb",
    "filename": "documents\\376709eng.pdf",
    "page_number": 33,
    "chunk_id": "33_0",
    "chunk_text": "AI and education: Guidance for policy-makers – A review of policy responses\n30\n \n In 2017, China launched the ‘New ICT Curriculum Standards \nfor Senior High School' (Ministry of Education, People's \nRepublic of China, 2017). This document promotes students’ \n(i) information consciousness; (ii) computational thinking; \n(iii) digital learning and innovation; and (iv) responsibilities in \nan information society. According to the 'New ICT Curriculum Standards for Senior \nHigh School,' the ICT curriculum involves the ICT Compulsory \nCourse, ICT Selective Course I, and ICT Selective Course II. The ICT Compulsory Course includes two modules: (i) Data \nand Calculation, (ii) Information System and Society. The ICT \nSelective Course consists of a basic module and an application \nmodule. The basic module includes (i) Data and data structures, \n(ii) Network basics, and (iii) Data Management and Analysis. The application module includes (i) APP Design, (ii) 3D Design \nand Creativity and (iii) Design for Open Hardware Project. The ICT Selective Course II involves Algorithm basics and \nIntroduction to Intelligent Systems.  In 2018, China launched the 'Innovative Action Plan \nfor Artificial Intelligence in Higher Education Institutions' \n(Ministry of Education, People's Republic of China, 2018), \nwhich pushes forward AI development in universities. It aims \nto (i) optimize innovation system in the field of AI in college \nand universities; (ii) improve AI talent training system; and \n(iii) strengthen the application of the science and technology \nachievement of colleges and universities in the field of AI.  In 2017, Singapore launched ‘The Code@SG Movement - \nDeveloping Computational Thinking as a National Capability’ \n(Infocomm Media Development Authority, 2017), which \nemphasizes the importance of promoting students’ coding and \ncomputational thinking from an early age, as it becomes an \nincreasingly essential part of people’s lives and careers.  In 2012, Estonia launched the 'ProgeTiger' Programme \nmanaged by the Education Information Technology Foundation \n(Hariduse Infotehnoloogia Sihtasutuse, HITSA), and funded by \nthe Estonian Ministry of Education and Research. It proposes to \nintroduce programming and robotics into the national curricula \nfor pre-school, primary and vocational education."
  },
  {
    "id": "0b30250e-22f9-4bd6-849d-c408a4771087",
    "filename": "documents\\376709eng.pdf",
    "page_number": 33,
    "chunk_id": "33_1",
    "chunk_text": " In 2018, China launched the 'Innovative Action Plan \nfor Artificial Intelligence in Higher Education Institutions' \n(Ministry of Education, People's Republic of China, 2018), \nwhich pushes forward AI development in universities. It aims \nto (i) optimize innovation system in the field of AI in college \nand universities; (ii) improve AI talent training system; and \n(iii) strengthen the application of the science and technology \nachievement of colleges and universities in the field of AI.  In 2017, Singapore launched ‘The Code@SG Movement - \nDeveloping Computational Thinking as a National Capability’ \n(Infocomm Media Development Authority, 2017), which \nemphasizes the importance of promoting students’ coding and \ncomputational thinking from an early age, as it becomes an \nincreasingly essential part of people’s lives and careers.  In 2012, Estonia launched the 'ProgeTiger' Programme \nmanaged by the Education Information Technology Foundation \n(Hariduse Infotehnoloogia Sihtasutuse, HITSA), and funded by \nthe Estonian Ministry of Education and Research. It proposes to \nintroduce programming and robotics into the national curricula \nfor pre-school, primary and vocational education. 5.2 Common areas of concern\nFrom the national and regional policies described above, four \nmain areas of concern emerge: \n \n the importance of governance for data and privacy (as \naddressed by, for example, the EU’s GDPR);\n \n the importance of openness as a core value, in terms both \nof AI technologies and data, to ensure equal universal access \nand opportunities to bridge information inequalities and to \npromote transparency (UNESCO, 2019b);\n \n curriculum innovation that can address the potential \nand implications of AI, such as Malta's 'Towards an AI \nStrategy. High-level policy document for public consultation' \n(Government of Malta, 2018), which asserts that \"Malta’s \neducation system will also need to evolve and adapt to the \nrequirements of the Fourth Industrial Revolution\"; and \n \n financial support for the effective implementation of AI, \nsuch as the Republic of Korea’s creation of 4,500 domestic \nscholarships for AI students and its commitment of around \nUS$2 billion to establish six new AI graduate institutions and \n$4 million for AI research. 5.3 Financing, partnership and international cooperation\nTo maximize the benefits and mitigate the risks of AI’s growth \nin educational contexts, it is essential to have system-wide \nplanning, critical evaluations, collective actions, sustained \nfunding, robust targeted research and international \ncooperation. The reality is that few countries or stakeholders \nare ready."
  },
  {
    "id": "c61fd843-2dc8-4158-a3f7-1b82e44c5874",
    "filename": "documents\\376709eng.pdf",
    "page_number": 33,
    "chunk_id": "33_2",
    "chunk_text": "It proposes to \nintroduce programming and robotics into the national curricula \nfor pre-school, primary and vocational education. 5.2 Common areas of concern\nFrom the national and regional policies described above, four \nmain areas of concern emerge: \n \n the importance of governance for data and privacy (as \naddressed by, for example, the EU’s GDPR);\n \n the importance of openness as a core value, in terms both \nof AI technologies and data, to ensure equal universal access \nand opportunities to bridge information inequalities and to \npromote transparency (UNESCO, 2019b);\n \n curriculum innovation that can address the potential \nand implications of AI, such as Malta's 'Towards an AI \nStrategy. High-level policy document for public consultation' \n(Government of Malta, 2018), which asserts that \"Malta’s \neducation system will also need to evolve and adapt to the \nrequirements of the Fourth Industrial Revolution\"; and \n \n financial support for the effective implementation of AI, \nsuch as the Republic of Korea’s creation of 4,500 domestic \nscholarships for AI students and its commitment of around \nUS$2 billion to establish six new AI graduate institutions and \n$4 million for AI research. 5.3 Financing, partnership and international cooperation\nTo maximize the benefits and mitigate the risks of AI’s growth \nin educational contexts, it is essential to have system-wide \nplanning, critical evaluations, collective actions, sustained \nfunding, robust targeted research and international \ncooperation. The reality is that few countries or stakeholders \nare ready. Few are genuinely engaging with the technologies \nor mobilizing resources to ensure that the application of \nAI is grounded in large-scale academic research. Most are \nyet to acknowledge let alone explore the fact that AI may \ndemand a fundamental reinvention of learning. Instead, the \ndiscussion remains rather superficial. For example, many \nargue that ‘personalisation’ of learning is welcome, but this \nis ill-defined; do they mean personalized routes to learning \nstandardised content, or personalized outcomes, agency \nand self-actualization? In short, it is not sufficient to argue \nthat AI should be used in educational contexts. Instead, \nstakeholders must also consider which AI technologies \nshould be used, how they should be used, and what they can \ngenuinely achieve. Beijing Consensus on Artificial Intelligence and Education \n37. Provide adequate platforms for the international exchange of \nregulatory frameworks, instruments and approaches to AI in \neducation, including through UNESCO’s Mobile Learning Week and \nthrough other United Nations agencies, and thereby support and \nbenefit from South–South and North–South–South cooperation to \nleverage AI for SDG 4. 38."
  },
  {
    "id": "d2c1ef6a-4dd3-4d51-8932-adeda8c76a82",
    "filename": "documents\\376709eng.pdf",
    "page_number": 33,
    "chunk_id": "33_3",
    "chunk_text": "In short, it is not sufficient to argue \nthat AI should be used in educational contexts. Instead, \nstakeholders must also consider which AI technologies \nshould be used, how they should be used, and what they can \ngenuinely achieve. Beijing Consensus on Artificial Intelligence and Education \n37. Provide adequate platforms for the international exchange of \nregulatory frameworks, instruments and approaches to AI in \neducation, including through UNESCO’s Mobile Learning Week and \nthrough other United Nations agencies, and thereby support and \nbenefit from South–South and North–South–South cooperation to \nleverage AI for SDG 4. 38. Create multi stakeholder partnerships and mobilize resources to \nreduce the AI divide and increase investment in the application of AI \nin education. (UNESCO, 2019a, p. 10)"
  },
  {
    "id": "95ba5332-801f-49ab-9077-4ffd9079cf99",
    "filename": "documents\\376709eng.pdf",
    "page_number": 34,
    "chunk_id": "34_0",
    "chunk_text": "Policy recommendations – AI and education: Guidance for policy-makers \n31\n6. Policy recommendations\n6.1 A system-wide vision and strategic priorities \nDEFINE A SYSTEM-WIDE VISION OF AI AND EDUCATION \nPOLICIES\nThe primary purpose of applying AI in education should be \nto enhance learning, enabling every learner to develop their \nindividual potential, which policies should reflect and support. However, if countries are to meet the challenges of achieving \nSDG 4, policies need to go beyond the application of AI in \neducational contexts, to include all the connections between AI \nand education. In particular, this means teaching how AI works \nand how it might be created, and about the wider implications \nthat AI has for local and global society. Four strategic targets need to be met, interpreted for the local \ncontext (i.e. for many low and middle-income countries, the \nfocus might need to be on identifying and addressing gaps in \nAI readiness such as those around infrastructure and funding):\n \n Ensuring the inclusive and equitable use of AI in education; \n \n Leveraging AI to enhance education and learning; \n \n  Promoting the development of skills for life in the age of \nAI, including teaching how AI works and its implications for \nhumanity; and\n \n  Safeguarding the transparent and auditable use of \neducation data. However, AI is not a magic bullet. There is much hyperbole to \nnegotiate, and a large number of challenges to address. The following overarching principle and policy \nrecommendations also draw on the the Beijing Consensus \n(UNESCO, 2019a), which was agreed at the International \nConference on AI and Education in Beijing (16-18 May 2019). Accordingly, after setting out the overarching principle for \nAI and education policies, we make some recommendations \nas follows:\n \n Interdisciplinary planning and inter-sectoral governance;\n \n policies on equitable, inclusive, and ethical use of AI;\n \n  develop a master plan for using AI for education \nmanagement, teaching, learning, and assessment;\n \n  pilot testing, monitoring and evaluation, and building an \nevidence base; and\n \n fostering local AI innovations for education."
  },
  {
    "id": "b7663cdf-e61a-44dc-b246-2a3ed8afebdc",
    "filename": "documents\\376709eng.pdf",
    "page_number": 34,
    "chunk_id": "34_1",
    "chunk_text": "for many low and middle-income countries, the \nfocus might need to be on identifying and addressing gaps in \nAI readiness such as those around infrastructure and funding):\n \n Ensuring the inclusive and equitable use of AI in education; \n \n Leveraging AI to enhance education and learning; \n \n  Promoting the development of skills for life in the age of \nAI, including teaching how AI works and its implications for \nhumanity; and\n \n  Safeguarding the transparent and auditable use of \neducation data. However, AI is not a magic bullet. There is much hyperbole to \nnegotiate, and a large number of challenges to address. The following overarching principle and policy \nrecommendations also draw on the the Beijing Consensus \n(UNESCO, 2019a), which was agreed at the International \nConference on AI and Education in Beijing (16-18 May 2019). Accordingly, after setting out the overarching principle for \nAI and education policies, we make some recommendations \nas follows:\n \n Interdisciplinary planning and inter-sectoral governance;\n \n policies on equitable, inclusive, and ethical use of AI;\n \n  develop a master plan for using AI for education \nmanagement, teaching, learning, and assessment;\n \n  pilot testing, monitoring and evaluation, and building an \nevidence base; and\n \n fostering local AI innovations for education. ASSESS SYSTEM-WIDE READINESS AND CHOOSE \nSTRATEGIC PRIORITIES\n \n Consider the trade-offs on strategic priorities for \neducation policy planning, including between the \napplication of AI and other priorities, and between different \nfocus areas or building blocks of the policies: The trade-offs \nshould be based on a thoughtful examination of the potential \nof AI technologies to support the achievement of the SDGs in \nthe local context, moderated by the investment requirements \nfor implementing policies and programmes centred on the \napplication of AI in educational contexts. Thereafter, set \nstrategic priorities based on an analysis of whether existing \nand emerging AI technologies are suitable solutions to the \nchallenges of achieving SDG 4 and its targets. Consider other \nSDGs according to the urgency of developing the AI skills and \nvalues needed in all local sectors. Apply or create cost-value \nevaluation schemas to assess whether the educational \nbenefits of implementing AI policies and programmes \n(e.g. increased effectiveness, enhanced efficiency, and \nexpanded accessibility) outweigh the costs (e.g. infrastructure \nrefurbishments, training, integration, and the risks of \ndecreased trust and autonomy, lower-quality content, and the \nmisuse of educational data."
  },
  {
    "id": "c6cb5a96-e026-4226-af31-7c8c480c7e79",
    "filename": "documents\\376709eng.pdf",
    "page_number": 34,
    "chunk_id": "34_2",
    "chunk_text": "Thereafter, set \nstrategic priorities based on an analysis of whether existing \nand emerging AI technologies are suitable solutions to the \nchallenges of achieving SDG 4 and its targets. Consider other \nSDGs according to the urgency of developing the AI skills and \nvalues needed in all local sectors. Apply or create cost-value \nevaluation schemas to assess whether the educational \nbenefits of implementing AI policies and programmes \n(e.g. increased effectiveness, enhanced efficiency, and \nexpanded accessibility) outweigh the costs (e.g. infrastructure \nrefurbishments, training, integration, and the risks of \ndecreased trust and autonomy, lower-quality content, and the \nmisuse of educational data. à EXAMPLES\nThe Global AI Strategy Landscape – Explores 50 National \nArtificial Intelligence strategies shaping the future of humanity: \nhttps://www.holoniq.com/notes/the-global-ai-strategy-landscape/;  \nDeciphering China’s AI Dream – The context, components, \ncapabilities, and consequences of China’s strategy to lead the world \nin AI (Ding, 2018): https://www.fhi.ox.ac.uk/wp-content/uploads/\nDeciphering_Chinas_AI-Dream.pdf \n \n Define the strategic objectives of the policy based \non system-wide readiness and cost-value assessment: \nApply or develop tools to assess system-wide AI readiness \nincluding infrastructure; Internet connectivity; the availability \nof data, AI tools, and local AI talent; the skills of key policy \nimplementers; and stakeholders’ awareness. When defining \nthe time-bound goals, maintain realistic expectations of the \nbenefits that AI systems are able to deliver, in the context of \nlocal systemic shortcomings in staffing levels, infrastructure \nand processes. Take into account the conceptual unknowns \nand limitations of educational paradigms that are likely to \nimpact the capabilities of AI systems. Mitigate against the lack \nof systematic studies on the impact of AI in education. à EXAMPLE\nGlobal AI Readiness Index: https://bit.ly/2UR2HXp"
  },
  {
    "id": "9c33bd82-2393-46d1-a2f0-57ec7a7e8918",
    "filename": "documents\\376709eng.pdf",
    "page_number": 35,
    "chunk_id": "35_0",
    "chunk_text": "AI and education: Guidance for policy-makers – Policy recommendations\n32\n6.2 Overarching principle for AI and education policies\nADOPT A HUMANISTIC APPROACH AS AN OVERARCHING \nPRINCIPLE FOR AI AND EDUCATION POLICIES\n \n Steer AI-and-education policy development and practices \ntowards protecting human rights and equipping people with \nthe values and skills needed for sustainable development \nand effective human-machine collaboration in life, learning \nand work; Ensure that AI is human-controlled and centred on \nserving people, and that it is deployed to enhance capacities \nfor students and teachers. Design AI applications in an ethical, \nnon-discriminatory, equitable, transparent and auditable \nmanner; and monitor and evaluate the impact of AI on people \nand society throughout the value chains.  Foster the human values needed to develop and apply AI. Analyse the potential tension between market rewards and \nhuman values, skills, and social well-being in the context \nof AI technologies that increase productivity. Define values \nthat prioritize people and the environment over efficiency, \nand human interaction over human-machine interaction. Foster broad corporate and civic responsibility for addressing \nthe critical societal issues raised by AI technologies (such as \nfairness, transparency, accountability, human rights, democratic \nvalues, bias, and privacy). Ensure that people remain at the \ncore of education as an implicit part of the technology design; \nand protect against automating tasks without identifying and \ncompensating for the values of current practices. à EXAMPLES\nAI for Humanity – French Strategy for Artificial Intelligence: \nhttps://www.aiforhumanity.fr/en/ \nEU Ethics Guidelines for Trustworthy AI:  \nhttps://ec.europa.eu/digital-single-market/en/news/ethics-\nguidelines-trustworthy-ai\nOECD Principles on AI:  \nhttps://www.oecd.org/going-digital/ai/principles\n6.3 Interdisciplinary planning and inter-sectoral governance\nMOBILIZE INTERDISCIPLINARY AND MULTI-\nSTAKEHOLDER EXPERTISE TO INFORM POLICY PLANNING \nAND BUILD THE CAPACITIES OF POLICY-MAKERS\n \n Build the knowledge and confidence of policy-makers \nand education managers so that they can navigate and \nmake decisions in an increasingly AI-rich educational \necosystem: Provide continuous training opportunities for \ndecision-makers including finance planners, policy shapers, \nand policy implementation managers; facilitate expertise \nand best-practice exchange among stakeholders in and \nacross countries; and align stakeholders’ understandings of \neducational challenges to be addressed using AI technologies."
  },
  {
    "id": "a70f19dc-0b87-442d-acfa-7d68e3a2f5ca",
    "filename": "documents\\376709eng.pdf",
    "page_number": 35,
    "chunk_id": "35_1",
    "chunk_text": "Analyse the potential tension between market rewards and \nhuman values, skills, and social well-being in the context \nof AI technologies that increase productivity. Define values \nthat prioritize people and the environment over efficiency, \nand human interaction over human-machine interaction. Foster broad corporate and civic responsibility for addressing \nthe critical societal issues raised by AI technologies (such as \nfairness, transparency, accountability, human rights, democratic \nvalues, bias, and privacy). Ensure that people remain at the \ncore of education as an implicit part of the technology design; \nand protect against automating tasks without identifying and \ncompensating for the values of current practices. à EXAMPLES\nAI for Humanity – French Strategy for Artificial Intelligence: \nhttps://www.aiforhumanity.fr/en/ \nEU Ethics Guidelines for Trustworthy AI:  \nhttps://ec.europa.eu/digital-single-market/en/news/ethics-\nguidelines-trustworthy-ai\nOECD Principles on AI:  \nhttps://www.oecd.org/going-digital/ai/principles\n6.3 Interdisciplinary planning and inter-sectoral governance\nMOBILIZE INTERDISCIPLINARY AND MULTI-\nSTAKEHOLDER EXPERTISE TO INFORM POLICY PLANNING \nAND BUILD THE CAPACITIES OF POLICY-MAKERS\n \n Build the knowledge and confidence of policy-makers \nand education managers so that they can navigate and \nmake decisions in an increasingly AI-rich educational \necosystem: Provide continuous training opportunities for \ndecision-makers including finance planners, policy shapers, \nand policy implementation managers; facilitate expertise \nand best-practice exchange among stakeholders in and \nacross countries; and align stakeholders’ understandings of \neducational challenges to be addressed using AI technologies. à EXAMPLE\nElements of AI course: https://www.elementsofai.com \n \n Infuse inter-sectoral, interdisciplinary and multi-\nstakeholder expertise to inform the key decisions in policy \nplanning: Bring together communities of expertise including \neducators, learning scientists and AI engineers from different \nareas of research such as neuroscience, cognitive science, \nsocial psychology, and the humanities, to design user-\ncentred and result-based AI technologies that meet genuine \nclassroom needs; reach out to international organizations \nto inform and advise on AI policy-making; and consider the \npotential of AI to combine and analyse multiple data sources \nto improve the efficiency of decision-making."
  },
  {
    "id": "d5a1a0ef-42a4-4b8a-aa48-7071917adc26",
    "filename": "documents\\376709eng.pdf",
    "page_number": 35,
    "chunk_id": "35_2",
    "chunk_text": "Define values \nthat prioritize people and the environment over efficiency, \nand human interaction over human-machine interaction. Foster broad corporate and civic responsibility for addressing \nthe critical societal issues raised by AI technologies (such as \nfairness, transparency, accountability, human rights, democratic \nvalues, bias, and privacy). Ensure that people remain at the \ncore of education as an implicit part of the technology design; \nand protect against automating tasks without identifying and \ncompensating for the values of current practices. à EXAMPLES\nAI for Humanity – French Strategy for Artificial Intelligence: \nhttps://www.aiforhumanity.fr/en/ \nEU Ethics Guidelines for Trustworthy AI:  \nhttps://ec.europa.eu/digital-single-market/en/news/ethics-\nguidelines-trustworthy-ai\nOECD Principles on AI:  \nhttps://www.oecd.org/going-digital/ai/principles\n6.3 Interdisciplinary planning and inter-sectoral governance\nMOBILIZE INTERDISCIPLINARY AND MULTI-\nSTAKEHOLDER EXPERTISE TO INFORM POLICY PLANNING \nAND BUILD THE CAPACITIES OF POLICY-MAKERS\n \n Build the knowledge and confidence of policy-makers \nand education managers so that they can navigate and \nmake decisions in an increasingly AI-rich educational \necosystem: Provide continuous training opportunities for \ndecision-makers including finance planners, policy shapers, \nand policy implementation managers; facilitate expertise \nand best-practice exchange among stakeholders in and \nacross countries; and align stakeholders’ understandings of \neducational challenges to be addressed using AI technologies. à EXAMPLE\nElements of AI course: https://www.elementsofai.com \n \n Infuse inter-sectoral, interdisciplinary and multi-\nstakeholder expertise to inform the key decisions in policy \nplanning: Bring together communities of expertise including \neducators, learning scientists and AI engineers from different \nareas of research such as neuroscience, cognitive science, \nsocial psychology, and the humanities, to design user-\ncentred and result-based AI technologies that meet genuine \nclassroom needs; reach out to international organizations \nto inform and advise on AI policy-making; and consider the \npotential of AI to combine and analyse multiple data sources \nto improve the efficiency of decision-making. à EXAMPLE\nHigh-Level Expert Group on Artificial Intelligence, European \nAI Alliance: https://ec.europa.eu/digital-single-market/en/high-\nlevel-expert-group-artificial-intelligence\nSET UP INTER-SECTORAL GOVERNANCE AND \nCOORDINATION MECHANISMS\n \n Adopt a whole-government and system-wide approach to \nthe planning and governance of policies for the application \nof AI in educational contexts: Coherent system-wide strategies \nand evidence-based inclusive approaches (such as participatory \ndesign and co-creation frameworks, Pobiner and Murphy, 2018) \nshould be exploited to ensure that AI and education will be \naligned and integrated with existing education policies and any \nbroader national AI strategies; if a consensus is reached on the \nuse of AI for the whole education system or broader inter-\nsectoral strategies, consider ways to adopt AI for system-wide \ntransformation."
  },
  {
    "id": "734e786e-e5ea-40b9-b4fd-e019df12cc5e",
    "filename": "documents\\376709eng.pdf",
    "page_number": 35,
    "chunk_id": "35_3",
    "chunk_text": "Foster broad corporate and civic responsibility for addressing \nthe critical societal issues raised by AI technologies (such as \nfairness, transparency, accountability, human rights, democratic \nvalues, bias, and privacy). Ensure that people remain at the \ncore of education as an implicit part of the technology design; \nand protect against automating tasks without identifying and \ncompensating for the values of current practices. à EXAMPLES\nAI for Humanity – French Strategy for Artificial Intelligence: \nhttps://www.aiforhumanity.fr/en/ \nEU Ethics Guidelines for Trustworthy AI:  \nhttps://ec.europa.eu/digital-single-market/en/news/ethics-\nguidelines-trustworthy-ai\nOECD Principles on AI:  \nhttps://www.oecd.org/going-digital/ai/principles\n6.3 Interdisciplinary planning and inter-sectoral governance\nMOBILIZE INTERDISCIPLINARY AND MULTI-\nSTAKEHOLDER EXPERTISE TO INFORM POLICY PLANNING \nAND BUILD THE CAPACITIES OF POLICY-MAKERS\n \n Build the knowledge and confidence of policy-makers \nand education managers so that they can navigate and \nmake decisions in an increasingly AI-rich educational \necosystem: Provide continuous training opportunities for \ndecision-makers including finance planners, policy shapers, \nand policy implementation managers; facilitate expertise \nand best-practice exchange among stakeholders in and \nacross countries; and align stakeholders’ understandings of \neducational challenges to be addressed using AI technologies. à EXAMPLE\nElements of AI course: https://www.elementsofai.com \n \n Infuse inter-sectoral, interdisciplinary and multi-\nstakeholder expertise to inform the key decisions in policy \nplanning: Bring together communities of expertise including \neducators, learning scientists and AI engineers from different \nareas of research such as neuroscience, cognitive science, \nsocial psychology, and the humanities, to design user-\ncentred and result-based AI technologies that meet genuine \nclassroom needs; reach out to international organizations \nto inform and advise on AI policy-making; and consider the \npotential of AI to combine and analyse multiple data sources \nto improve the efficiency of decision-making. à EXAMPLE\nHigh-Level Expert Group on Artificial Intelligence, European \nAI Alliance: https://ec.europa.eu/digital-single-market/en/high-\nlevel-expert-group-artificial-intelligence\nSET UP INTER-SECTORAL GOVERNANCE AND \nCOORDINATION MECHANISMS\n \n Adopt a whole-government and system-wide approach to \nthe planning and governance of policies for the application \nof AI in educational contexts: Coherent system-wide strategies \nand evidence-based inclusive approaches (such as participatory \ndesign and co-creation frameworks, Pobiner and Murphy, 2018) \nshould be exploited to ensure that AI and education will be \naligned and integrated with existing education policies and any \nbroader national AI strategies; if a consensus is reached on the \nuse of AI for the whole education system or broader inter-\nsectoral strategies, consider ways to adopt AI for system-wide \ntransformation.  Set up a system-wide organizational structure for \npolicy governance and coordination to ensure that the \nimplementation balances top-down and bottom-up methods, \nwhich involve the key partners and stakeholders maximizing \ntheir cross-sector collaboration and resource sharing."
  },
  {
    "id": "a23aef08-2e0e-4a19-be5f-68ebd27b313d",
    "filename": "documents\\376709eng.pdf",
    "page_number": 35,
    "chunk_id": "35_4",
    "chunk_text": "Ensure that people remain at the \ncore of education as an implicit part of the technology design; \nand protect against automating tasks without identifying and \ncompensating for the values of current practices. à EXAMPLES\nAI for Humanity – French Strategy for Artificial Intelligence: \nhttps://www.aiforhumanity.fr/en/ \nEU Ethics Guidelines for Trustworthy AI:  \nhttps://ec.europa.eu/digital-single-market/en/news/ethics-\nguidelines-trustworthy-ai\nOECD Principles on AI:  \nhttps://www.oecd.org/going-digital/ai/principles\n6.3 Interdisciplinary planning and inter-sectoral governance\nMOBILIZE INTERDISCIPLINARY AND MULTI-\nSTAKEHOLDER EXPERTISE TO INFORM POLICY PLANNING \nAND BUILD THE CAPACITIES OF POLICY-MAKERS\n \n Build the knowledge and confidence of policy-makers \nand education managers so that they can navigate and \nmake decisions in an increasingly AI-rich educational \necosystem: Provide continuous training opportunities for \ndecision-makers including finance planners, policy shapers, \nand policy implementation managers; facilitate expertise \nand best-practice exchange among stakeholders in and \nacross countries; and align stakeholders’ understandings of \neducational challenges to be addressed using AI technologies. à EXAMPLE\nElements of AI course: https://www.elementsofai.com \n \n Infuse inter-sectoral, interdisciplinary and multi-\nstakeholder expertise to inform the key decisions in policy \nplanning: Bring together communities of expertise including \neducators, learning scientists and AI engineers from different \nareas of research such as neuroscience, cognitive science, \nsocial psychology, and the humanities, to design user-\ncentred and result-based AI technologies that meet genuine \nclassroom needs; reach out to international organizations \nto inform and advise on AI policy-making; and consider the \npotential of AI to combine and analyse multiple data sources \nto improve the efficiency of decision-making. à EXAMPLE\nHigh-Level Expert Group on Artificial Intelligence, European \nAI Alliance: https://ec.europa.eu/digital-single-market/en/high-\nlevel-expert-group-artificial-intelligence\nSET UP INTER-SECTORAL GOVERNANCE AND \nCOORDINATION MECHANISMS\n \n Adopt a whole-government and system-wide approach to \nthe planning and governance of policies for the application \nof AI in educational contexts: Coherent system-wide strategies \nand evidence-based inclusive approaches (such as participatory \ndesign and co-creation frameworks, Pobiner and Murphy, 2018) \nshould be exploited to ensure that AI and education will be \naligned and integrated with existing education policies and any \nbroader national AI strategies; if a consensus is reached on the \nuse of AI for the whole education system or broader inter-\nsectoral strategies, consider ways to adopt AI for system-wide \ntransformation.  Set up a system-wide organizational structure for \npolicy governance and coordination to ensure that the \nimplementation balances top-down and bottom-up methods, \nwhich involve the key partners and stakeholders maximizing \ntheir cross-sector collaboration and resource sharing. This should include a central governing board charged \nwith commanding, supporting and overseeing the policy \nimplementation; a coordination body to manage the partners \nand collaboration; and a team of representatives charged with \nimplementing the policy."
  },
  {
    "id": "cdfa5415-8dd4-4551-84f4-98c9464ab399",
    "filename": "documents\\376709eng.pdf",
    "page_number": 35,
    "chunk_id": "35_5",
    "chunk_text": "à EXAMPLES\nAI for Humanity – French Strategy for Artificial Intelligence: \nhttps://www.aiforhumanity.fr/en/ \nEU Ethics Guidelines for Trustworthy AI:  \nhttps://ec.europa.eu/digital-single-market/en/news/ethics-\nguidelines-trustworthy-ai\nOECD Principles on AI:  \nhttps://www.oecd.org/going-digital/ai/principles\n6.3 Interdisciplinary planning and inter-sectoral governance\nMOBILIZE INTERDISCIPLINARY AND MULTI-\nSTAKEHOLDER EXPERTISE TO INFORM POLICY PLANNING \nAND BUILD THE CAPACITIES OF POLICY-MAKERS\n \n Build the knowledge and confidence of policy-makers \nand education managers so that they can navigate and \nmake decisions in an increasingly AI-rich educational \necosystem: Provide continuous training opportunities for \ndecision-makers including finance planners, policy shapers, \nand policy implementation managers; facilitate expertise \nand best-practice exchange among stakeholders in and \nacross countries; and align stakeholders’ understandings of \neducational challenges to be addressed using AI technologies. à EXAMPLE\nElements of AI course: https://www.elementsofai.com \n \n Infuse inter-sectoral, interdisciplinary and multi-\nstakeholder expertise to inform the key decisions in policy \nplanning: Bring together communities of expertise including \neducators, learning scientists and AI engineers from different \nareas of research such as neuroscience, cognitive science, \nsocial psychology, and the humanities, to design user-\ncentred and result-based AI technologies that meet genuine \nclassroom needs; reach out to international organizations \nto inform and advise on AI policy-making; and consider the \npotential of AI to combine and analyse multiple data sources \nto improve the efficiency of decision-making. à EXAMPLE\nHigh-Level Expert Group on Artificial Intelligence, European \nAI Alliance: https://ec.europa.eu/digital-single-market/en/high-\nlevel-expert-group-artificial-intelligence\nSET UP INTER-SECTORAL GOVERNANCE AND \nCOORDINATION MECHANISMS\n \n Adopt a whole-government and system-wide approach to \nthe planning and governance of policies for the application \nof AI in educational contexts: Coherent system-wide strategies \nand evidence-based inclusive approaches (such as participatory \ndesign and co-creation frameworks, Pobiner and Murphy, 2018) \nshould be exploited to ensure that AI and education will be \naligned and integrated with existing education policies and any \nbroader national AI strategies; if a consensus is reached on the \nuse of AI for the whole education system or broader inter-\nsectoral strategies, consider ways to adopt AI for system-wide \ntransformation.  Set up a system-wide organizational structure for \npolicy governance and coordination to ensure that the \nimplementation balances top-down and bottom-up methods, \nwhich involve the key partners and stakeholders maximizing \ntheir cross-sector collaboration and resource sharing. This should include a central governing board charged \nwith commanding, supporting and overseeing the policy \nimplementation; a coordination body to manage the partners \nand collaboration; and a team of representatives charged with \nimplementing the policy. Most importantly, a comprehensive \nset of integrated principles on policy governance should be \ndeveloped and consistently applied to allow the board to \nassume ownership and accountability."
  },
  {
    "id": "6f377efd-4039-439d-9b42-8c0966063d73",
    "filename": "documents\\376709eng.pdf",
    "page_number": 35,
    "chunk_id": "35_6",
    "chunk_text": "à EXAMPLE\nElements of AI course: https://www.elementsofai.com \n \n Infuse inter-sectoral, interdisciplinary and multi-\nstakeholder expertise to inform the key decisions in policy \nplanning: Bring together communities of expertise including \neducators, learning scientists and AI engineers from different \nareas of research such as neuroscience, cognitive science, \nsocial psychology, and the humanities, to design user-\ncentred and result-based AI technologies that meet genuine \nclassroom needs; reach out to international organizations \nto inform and advise on AI policy-making; and consider the \npotential of AI to combine and analyse multiple data sources \nto improve the efficiency of decision-making. à EXAMPLE\nHigh-Level Expert Group on Artificial Intelligence, European \nAI Alliance: https://ec.europa.eu/digital-single-market/en/high-\nlevel-expert-group-artificial-intelligence\nSET UP INTER-SECTORAL GOVERNANCE AND \nCOORDINATION MECHANISMS\n \n Adopt a whole-government and system-wide approach to \nthe planning and governance of policies for the application \nof AI in educational contexts: Coherent system-wide strategies \nand evidence-based inclusive approaches (such as participatory \ndesign and co-creation frameworks, Pobiner and Murphy, 2018) \nshould be exploited to ensure that AI and education will be \naligned and integrated with existing education policies and any \nbroader national AI strategies; if a consensus is reached on the \nuse of AI for the whole education system or broader inter-\nsectoral strategies, consider ways to adopt AI for system-wide \ntransformation.  Set up a system-wide organizational structure for \npolicy governance and coordination to ensure that the \nimplementation balances top-down and bottom-up methods, \nwhich involve the key partners and stakeholders maximizing \ntheir cross-sector collaboration and resource sharing. This should include a central governing board charged \nwith commanding, supporting and overseeing the policy \nimplementation; a coordination body to manage the partners \nand collaboration; and a team of representatives charged with \nimplementing the policy. Most importantly, a comprehensive \nset of integrated principles on policy governance should be \ndeveloped and consistently applied to allow the board to \nassume ownership and accountability. à EXAMPLE\nAustralia: https://education.nsw.gov.au/content/dam/main-\neducation/teaching-and-learning/education-for-a-changing-\nworld/media/documents/Future_Frontiers_discussion_paper.pdf."
  },
  {
    "id": "9190c7f1-be44-48b7-90ee-583fddd861eb",
    "filename": "documents\\376709eng.pdf",
    "page_number": 36,
    "chunk_id": "36_0",
    "chunk_text": "Policy recommendations – AI and education: Guidance for policy-makers \n33\n \n Build an open and iterative cycle composed of key steps \nin planning, implementing, monitoring, and updating policy: \nThese steps should create a continuous learning process; \nmonitoring and research should be integrated within the \nmaster plan focusing on concrete outcomes and gains in skills, \nknowledge and values. Monitoring and research must be \ncommunicated strategically and reach the decision-makers in \norder to feed back into a valid and robust evidence-informed \nfoundation for development. The policy implementation \nprocess must be open to review and modification.  Promote the localization and reuse of open-source AI to \nincubate local development: Curate open-source AI tools and \nplatforms that can be tailored to the national and cultural context, \nkey because so many AI technologies are proprietary intellectual \nproperty. Employ open-source strategies of sharing data and \nalgorithms to incubate local innovations, and mitigate the digital \ndivide between countries and within groups of learners. à EXAMPLES\nGlobal South AI Directory, Knowledge 4 All Foundation: \nhttps://www.k4all.org/;  \nX5gon project (cross modal, cross cultural, cross lingual, cross \ndomain, and cross site global OER network):  \nhttps://www.x5gon.org/; \nSociety 5.0 of Japan:  \nhttps://www8.cao.go.jp/cstp/english/society5_0/index.html\n6.4 Policies and regulations for equitable, inclusive, and ethical use of AI \nSET OUT CROSS-CUTTING STRATEGIC OBJECTIVES, \nAND PLAN REGULATIONS AND PROGRAMMES, TO ENSURE \nTHE EQUITABLE AND INCLUSIVE USE OF AI IN EDUCATION\n \n Establish and monitor measurable targets to ensure \ninclusion, diversity and equality in teaching and \ndeveloping AI services: Identify those who stand to \nbenefit from its implementation; strengthen appropriate \ninfrastructure such as Internet access, hardware, and \nsoftware to allow the equitable leveraging of educational \nAI benefits. Implement measures to reach out to the most \nvulnerable groups of society; and focus on educational AI \nthat has a proven track record of including students with \ndifferent backgrounds and abilities. à EXAMPLE\nDigital Bangladesh: https://a2i.gov.bd\n \n Review AI’s ability to either alleviate or exaggerate biases: \nReveal uncharted risks and mitigate against them; test AI tools \nand verify that they are free of biases (Pennington, 2018), and \ntrained on data representative of diversity in terms of gender, \ndisability, social and economic status, ethnic and cultural \nbackground, and geographic location. Foster mindsets that value \nfair and equitable AI that is respectful of such diversity. Stimulate \na design approach that incorporates ethics, privacy, and security \ninto the research and development of AI in education."
  },
  {
    "id": "36f8c3aa-dcd6-40ad-9ccc-f168ace3f386",
    "filename": "documents\\376709eng.pdf",
    "page_number": 36,
    "chunk_id": "36_1",
    "chunk_text": "à EXAMPLES\nGlobal South AI Directory, Knowledge 4 All Foundation: \nhttps://www.k4all.org/;  \nX5gon project (cross modal, cross cultural, cross lingual, cross \ndomain, and cross site global OER network):  \nhttps://www.x5gon.org/; \nSociety 5.0 of Japan:  \nhttps://www8.cao.go.jp/cstp/english/society5_0/index.html\n6.4 Policies and regulations for equitable, inclusive, and ethical use of AI \nSET OUT CROSS-CUTTING STRATEGIC OBJECTIVES, \nAND PLAN REGULATIONS AND PROGRAMMES, TO ENSURE \nTHE EQUITABLE AND INCLUSIVE USE OF AI IN EDUCATION\n \n Establish and monitor measurable targets to ensure \ninclusion, diversity and equality in teaching and \ndeveloping AI services: Identify those who stand to \nbenefit from its implementation; strengthen appropriate \ninfrastructure such as Internet access, hardware, and \nsoftware to allow the equitable leveraging of educational \nAI benefits. Implement measures to reach out to the most \nvulnerable groups of society; and focus on educational AI \nthat has a proven track record of including students with \ndifferent backgrounds and abilities. à EXAMPLE\nDigital Bangladesh: https://a2i.gov.bd\n \n Review AI’s ability to either alleviate or exaggerate biases: \nReveal uncharted risks and mitigate against them; test AI tools \nand verify that they are free of biases (Pennington, 2018), and \ntrained on data representative of diversity in terms of gender, \ndisability, social and economic status, ethnic and cultural \nbackground, and geographic location. Foster mindsets that value \nfair and equitable AI that is respectful of such diversity. Stimulate \na design approach that incorporates ethics, privacy, and security \ninto the research and development of AI in education.  Create AI applications that are free from gender biases \nand ensure that the data used for development are gender-\nsensitive: Incentivize AI applications that promote gender \nequality; empower girls and women with AI skills to increase \ngender equality among workforces and employers. à EXAMPLE\nUNESCO’s publication ‘I’d blush if I could’, which shares strategies \nfor closing gender divides in digital skills:  \nhttps://unesdoc.unesco.org/ark:/48223/pf0000367416\n \n Establish data protection laws which make educational \ndata collection and analysis visible, traceable, and auditable \nby teachers, students and parents: Formulate clear policies \nregarding data ownership, privacy and availability for the \npublic good. Follow international guidelines created by \nexpert groups around wider AI data issues; and abide by \ninternationally recognized ethics."
  },
  {
    "id": "873e4e0f-5b7a-4d41-866b-3e59be616815",
    "filename": "documents\\376709eng.pdf",
    "page_number": 36,
    "chunk_id": "36_2",
    "chunk_text": "Foster mindsets that value \nfair and equitable AI that is respectful of such diversity. Stimulate \na design approach that incorporates ethics, privacy, and security \ninto the research and development of AI in education.  Create AI applications that are free from gender biases \nand ensure that the data used for development are gender-\nsensitive: Incentivize AI applications that promote gender \nequality; empower girls and women with AI skills to increase \ngender equality among workforces and employers. à EXAMPLE\nUNESCO’s publication ‘I’d blush if I could’, which shares strategies \nfor closing gender divides in digital skills:  \nhttps://unesdoc.unesco.org/ark:/48223/pf0000367416\n \n Establish data protection laws which make educational \ndata collection and analysis visible, traceable, and auditable \nby teachers, students and parents: Formulate clear policies \nregarding data ownership, privacy and availability for the \npublic good. Follow international guidelines created by \nexpert groups around wider AI data issues; and abide by \ninternationally recognized ethics. à EXAMPLES\nThe General Data Protection Regulation applicable as of 25 May \n2018 in all EU member states to harmonize data privacy laws across \nEurope: https://gdpr-info.eu/; \nEthics guidelines for trustworthy AI, European Union:  \nhttps://ec.europa.eu/digital-single-market/en/news/ethics-\nguidelines-trustworthy-ai\n \n Investigate options for striking a balance between \nopen access and data privacy: Test and adopt emerging \nAI technologies and tools for ensuring teachers’ and \nlearners’ data privacy and security. Develop comprehensive \nregulatory frameworks to guarantee the ethical, non-\ndiscriminatory, equitable, transparent and auditable use and \nreuse of learners’ data.  Facilitate open debates on issues related to AI ethics, \ndata privacy and security, and concerns about AI’s negative \nimpact on human rights and gender equality: Ensure that \nAI is used for good and prevent its harmful applications. Address the complex issue of informed consent – particularly \nin educational contexts where many of the users (e.g. children \nand students with learning difficulties) are not capable of \ngiving genuinely informed consent. à EXAMPLE\nDataKind, which advocates for social organizations to have \nthe same access to data science resources as large technology \ncompanies: https://www.datakind.org"
  },
  {
    "id": "4dfc5116-6213-471f-ac72-aec1f9056d28",
    "filename": "documents\\376709eng.pdf",
    "page_number": 37,
    "chunk_id": "37_0",
    "chunk_text": "AI and education: Guidance for policy-makers – Policy recommendations\n34\n6.5 Master plans for using AI in education management, teaching, learning, and assessment\nLEVERAGE AI TO BOOST AND UPGRADE EDUCATION \nMANAGEMENT AND DELIVERY\n \n Explore how AI technologies can improve educational \nmanagement information systems (EMIS): Leverage AI to \nmake EMIS more robust, accessible, streamlined, capable, \nuser-friendly and efficient. Gear the evidence-based \ndecision-making and management towards a more flexible, \ndynamic and democratized set of processes and data \nflows that are more responsive to changes in social and \neducational paradigms. Invest in the possibility of leveraging \nAI capabilities to enable system-wide predictions about \nskills and demand, to allow governments to prepare to meet \nrelevant local educational needs and integrate them with \nsectors such as finance, economics, law and medicine. à EXAMPLE\nThe Open University’s OU Analyse, which predicts student \noutcomes and identifies students at risk of failing by analysing big \ndata from the university’s EMIS: https://analyse.kmi.open.ac.uk\n \n Enable the holistic transformation of EMIS and their \nintegration with learning management systems (LMS): \nEnsure EMIS are kept up to date with changes triggered by \nAI-powered pedagogy, providing the means to integrate LMS \nwith EMIS to support progress towards more comprehensive, \nrich, well-rounded means of evaluation. à EXAMPLE\nZhixue (Intelligent Learning), a LMS developed by iFlyTek of \nChina to enable personalized online tutorial courses:  \nhttps://www.zhixue.com/login.html\n \n Empower managers, teachers and students to promote \nthe application of AI-powered EMIS and LMS: Analyse \nthe cost of introducing AI-powered EMIS and LMS into \nschools. Ensure low-cost entry for school managers and \nteachers so that they can see benefits rather than increased \nadministrative tasks. Set up and monitor visible, transparent \nprocesses of automatically collecting data on teachers’ \npractices and students’ activities. Promote the use of AI \nto support personalized resources and outcomes, so that \nlearners can have personal insights and leverage their skills \nand knowledge across contexts while staying in control of \ntheir own data and digital identities."
  },
  {
    "id": "4ad2636a-ecf6-40a2-b6bf-7a1c78339ab2",
    "filename": "documents\\376709eng.pdf",
    "page_number": 37,
    "chunk_id": "37_1",
    "chunk_text": "à EXAMPLE\nThe Open University’s OU Analyse, which predicts student \noutcomes and identifies students at risk of failing by analysing big \ndata from the university’s EMIS: https://analyse.kmi.open.ac.uk\n \n Enable the holistic transformation of EMIS and their \nintegration with learning management systems (LMS): \nEnsure EMIS are kept up to date with changes triggered by \nAI-powered pedagogy, providing the means to integrate LMS \nwith EMIS to support progress towards more comprehensive, \nrich, well-rounded means of evaluation. à EXAMPLE\nZhixue (Intelligent Learning), a LMS developed by iFlyTek of \nChina to enable personalized online tutorial courses:  \nhttps://www.zhixue.com/login.html\n \n Empower managers, teachers and students to promote \nthe application of AI-powered EMIS and LMS: Analyse \nthe cost of introducing AI-powered EMIS and LMS into \nschools. Ensure low-cost entry for school managers and \nteachers so that they can see benefits rather than increased \nadministrative tasks. Set up and monitor visible, transparent \nprocesses of automatically collecting data on teachers’ \npractices and students’ activities. Promote the use of AI \nto support personalized resources and outcomes, so that \nlearners can have personal insights and leverage their skills \nand knowledge across contexts while staying in control of \ntheir own data and digital identities. à EXAMPLE\nLabXchange by Amgen Foundation and Harvard University’s \nFaculty of Arts and Sciences, a free online science education \nplatform that provides users with personalized instruction, \nvirtual lab experiences, and networking opportunities across the \nglobal scientific community: https://www.multivu.com/players/\nEnglish/8490258-amgen-foundation-harvard-labxchange\nCULTIVATE LEARNER-CENTRED USE OF AI TO ENHANCE \nLEARNING AND ASSESSMENT \n \n Reinforce and reiterate humans’ authority and autonomy \nover their own learning in the context of increasingly \nknowledgeable machines and computer agents: Consult \nteachers and students about their views on AI technologies \nand use the feedback to decide how AI should be deployed \nin learning environments. Inform students about the types \nof data collected on them, how these are used, and the \nimpact this may have on their learning, careers and social \nlives. Prevent institutions from using AI technologies for \nsurveillance purposes – instead, cultivate trust among \nstudents and use AI for bolstering their progress instead of \nincreasing scrutiny.  Emphasize students’ agency and social well-being in \nthe process of integrating AI-based tools: Protect students’ \nagency and motivation to grow as individuals; protect play \nand leisure time, social interaction, and school breaks. Use \nAI-based tools to minimize the pressure of homework and \nexams, rather than exacerbating it."
  },
  {
    "id": "f3176b70-818e-426d-a76a-6f78dde22e14",
    "filename": "documents\\376709eng.pdf",
    "page_number": 37,
    "chunk_id": "37_2",
    "chunk_text": "à EXAMPLE\nLabXchange by Amgen Foundation and Harvard University’s \nFaculty of Arts and Sciences, a free online science education \nplatform that provides users with personalized instruction, \nvirtual lab experiences, and networking opportunities across the \nglobal scientific community: https://www.multivu.com/players/\nEnglish/8490258-amgen-foundation-harvard-labxchange\nCULTIVATE LEARNER-CENTRED USE OF AI TO ENHANCE \nLEARNING AND ASSESSMENT \n \n Reinforce and reiterate humans’ authority and autonomy \nover their own learning in the context of increasingly \nknowledgeable machines and computer agents: Consult \nteachers and students about their views on AI technologies \nand use the feedback to decide how AI should be deployed \nin learning environments. Inform students about the types \nof data collected on them, how these are used, and the \nimpact this may have on their learning, careers and social \nlives. Prevent institutions from using AI technologies for \nsurveillance purposes – instead, cultivate trust among \nstudents and use AI for bolstering their progress instead of \nincreasing scrutiny.  Emphasize students’ agency and social well-being in \nthe process of integrating AI-based tools: Protect students’ \nagency and motivation to grow as individuals; protect play \nand leisure time, social interaction, and school breaks. Use \nAI-based tools to minimize the pressure of homework and \nexams, rather than exacerbating it. Support students to adapt \nto new AI tools and methodologies so that these can have \na positive impact on their learning; and allow them to make \nobservations and give feedback on the challenges created by \nthe use of AI in the classroom. à EXAMPLES\nAlphaEgg, an intelligent robot for child care, developed by iFlyTek:  \nhttps://ifworlddesignguide.com/entry/203859-alphaegg; \nThe CoWriter: Learning to write with a robot, developed by \nCHILI (Computer-Human Interaction in Learning and Instruction), \nEPFL Technical University, Switzerland: https://www.epfl.ch/labs/\nchili/index-html/research/cowriter; https://www.youtube.com/\nwatch?v=E_iozVysl5g\n \n Review and adjust curricula to reflect pedagogical and \nassessment changes brought by the increasingly wide \nadoption of AI in teaching and learning: Collaborate with \nAI providers and educators to identify the most appropriate \nways of responding to changes in curriculum frameworks and \nassessment methodologies, to provide an enabling policy \nenvironment and curricular spaces for exploring AI. Facilitate \nthe participation of student representatives in countrywide \ninitiatives that promote new competencies in the curriculum. à EXAMPLE\nDigital Education, Programming and Robotics for all Argentine \nstudents: https://www.argentina.gob.ar/educacion/aprender-\nconectados/nucleos-de-aprendizajes-prioritarios-nap \n \n Test and deploy AI technologies to support the assessment \nof multiple dimensions of competencies and outcomes: \nIntegrate AI into psychometric assessments, possibly including \nchatbot-type conversations with students in situational \njudgment tests."
  },
  {
    "id": "a1b72baf-9bed-45c9-9a58-b37b3c1ae990",
    "filename": "documents\\376709eng.pdf",
    "page_number": 37,
    "chunk_id": "37_3",
    "chunk_text": "Use \nAI-based tools to minimize the pressure of homework and \nexams, rather than exacerbating it. Support students to adapt \nto new AI tools and methodologies so that these can have \na positive impact on their learning; and allow them to make \nobservations and give feedback on the challenges created by \nthe use of AI in the classroom. à EXAMPLES\nAlphaEgg, an intelligent robot for child care, developed by iFlyTek:  \nhttps://ifworlddesignguide.com/entry/203859-alphaegg; \nThe CoWriter: Learning to write with a robot, developed by \nCHILI (Computer-Human Interaction in Learning and Instruction), \nEPFL Technical University, Switzerland: https://www.epfl.ch/labs/\nchili/index-html/research/cowriter; https://www.youtube.com/\nwatch?v=E_iozVysl5g\n \n Review and adjust curricula to reflect pedagogical and \nassessment changes brought by the increasingly wide \nadoption of AI in teaching and learning: Collaborate with \nAI providers and educators to identify the most appropriate \nways of responding to changes in curriculum frameworks and \nassessment methodologies, to provide an enabling policy \nenvironment and curricular spaces for exploring AI. Facilitate \nthe participation of student representatives in countrywide \ninitiatives that promote new competencies in the curriculum. à EXAMPLE\nDigital Education, Programming and Robotics for all Argentine \nstudents: https://www.argentina.gob.ar/educacion/aprender-\nconectados/nucleos-de-aprendizajes-prioritarios-nap \n \n Test and deploy AI technologies to support the assessment \nof multiple dimensions of competencies and outcomes: \nIntegrate AI into psychometric assessments, possibly including \nchatbot-type conversations with students in situational \njudgment tests. Avoid using AI as the sole means of predicting \nstudents’ future educational and career development. Use"
  },
  {
    "id": "9723df94-8311-4590-8cb7-a8c49bc59ac4",
    "filename": "documents\\376709eng.pdf",
    "page_number": 38,
    "chunk_id": "38_0",
    "chunk_text": "Policy recommendations – AI and education: Guidance for policy-makers \n35\ncaution when adopting algorithm-based automatic grading of \nresponses to ‘rule-based’ closed questions; support teachers to \nuse AI-based formative assessment as an integrated function \nof AI-powered LMS to analyse data on students’ learning with \nhigher precision and efficiency and reduced human bias. Explore the potential of AI-based progressive assessments to \nprovide regular updates for teachers, students and parents. Using a humanistic perspective, test and evaluate the use of \nfacial recognition and other AI for user authentication and \ninvigilation in remote online assessments. à PARTIAL EXAMPLE\nTowards AI-based assessment systems:  \nhttps://www.researchgate.net/publication/314088884_Towards_\nartificial_intelligence-based_assessment_systems \nENSURE THAT AI IS USED TO EMPOWER TEACHERS\nProtect the rights of teachers and the value of their practices: \nConduct consultations with educators to ensure their rights \nare protected and their opinions are taken into account \nwhen deploying AI technologies. Carry out pilot studies \nand at-scale trials focused on attending to teachers’ daily \npractical requirements when integrating AI technologies; \nfacilitate the development of AI tools to support teaching \nrather than to replace core teacher functions. Provide \nevidence-based guidance that allows teachers to navigate \nthe private-sector offerings of AI-based technologies; and \ndevelop criteria and ratings to help them make informed \ndecisions on what tools are most suitable for their needs.  Analyse and review teachers’ roles in facilitating \nknowledge transfer, human interaction, higher-order \nthinking, and human values: Analyse the benefits of \nautomating certain tasks against the risks of reducing or \nharming learning practices. Mitigate against the automation \nof tasks that are time-consuming but also informative for \nteachers; identify concrete aspects that rely on teachers’ \nautonomy and motivation; preserve and enhance these \nelements in the process of introducing AI into pedagogical \npractices, and maintain a high level of trust in teachers’ \nauthority and capabilities.  Define the skill sets that teachers need in order to search \nfor and apply AI tools in their design and organization \nof learning activities and in their own professional \ndevelopment: Analyse the skills needed for human-machine \ncollaboration in teaching environments. Evaluate the \nparadigm changes that are required for applying AI to \nteachers’ professional development, administration of \nAI-based assessment, and design and implementation of \nAI-enhanced learning activities. Update teachers’ frameworks \nand training programmes with reference to the UNESCO ICT \nCompetency Framework for Teachers (UNESCO, 2018)."
  },
  {
    "id": "646ece97-4555-43c7-aa49-6ab83174a1d7",
    "filename": "documents\\376709eng.pdf",
    "page_number": 38,
    "chunk_id": "38_1",
    "chunk_text": " Analyse and review teachers’ roles in facilitating \nknowledge transfer, human interaction, higher-order \nthinking, and human values: Analyse the benefits of \nautomating certain tasks against the risks of reducing or \nharming learning practices. Mitigate against the automation \nof tasks that are time-consuming but also informative for \nteachers; identify concrete aspects that rely on teachers’ \nautonomy and motivation; preserve and enhance these \nelements in the process of introducing AI into pedagogical \npractices, and maintain a high level of trust in teachers’ \nauthority and capabilities.  Define the skill sets that teachers need in order to search \nfor and apply AI tools in their design and organization \nof learning activities and in their own professional \ndevelopment: Analyse the skills needed for human-machine \ncollaboration in teaching environments. Evaluate the \nparadigm changes that are required for applying AI to \nteachers’ professional development, administration of \nAI-based assessment, and design and implementation of \nAI-enhanced learning activities. Update teachers’ frameworks \nand training programmes with reference to the UNESCO ICT \nCompetency Framework for Teachers (UNESCO, 2018).  Deliver training and ensure continuous support to help \nteachers gain skills to use AI effectively: Develop and deliver \ntraining programmes on the required skills before deploying \nAI platforms or tools; prevent situations where teachers \nare left unable to conduct their role due to unavailable or \nunreliable AI functionality. Plan ahead to enable teachers \nto apply new AI technologies to their current practices and \ntransition to new ways of working; encourage the formation \nof communities of educators who share experiences and \nday-to-day best practice and foster innovative uses of AI tools. Provide simplified guidelines based on emerging technology \nresearch to update teachers on the latest findings that they \nmight apply in classroom settings, and increase lifelong-\nlearning opportunities for teachers to keep up with the \nchanges brought by AI inside and outside of the classroom. à EXAMPLES\nUNESCO ICT Competency Framework for Teachers:  \nhttps://unesdoc.unesco.org/ark:/48223/pf0000265721; \nResources on AI in K-12 education, International Society for \nTechnology in Education (ISTE): https://www.iste.org/learn/AI-in-\neducation \nPLAN THE USE OF AI TO SUPPORT LIFELONG LEARNING \nACROSS AGES, LOCATIONS AND BACKGROUNDS\n \n Actively seek and promote the use of AI to support \na wide range of educational approaches and diverse \npathways for lifelong learning: Initiate and sustain the \nability of institutions to leverage AI to become more \ndynamic, serve higher numbers of non-traditional learners, \nand provide lifelong learning across formal, non-formal and \ninformal settings."
  },
  {
    "id": "654e023a-cf50-46fd-8e60-4180ba853f26",
    "filename": "documents\\376709eng.pdf",
    "page_number": 38,
    "chunk_id": "38_2",
    "chunk_text": "Update teachers’ frameworks \nand training programmes with reference to the UNESCO ICT \nCompetency Framework for Teachers (UNESCO, 2018).  Deliver training and ensure continuous support to help \nteachers gain skills to use AI effectively: Develop and deliver \ntraining programmes on the required skills before deploying \nAI platforms or tools; prevent situations where teachers \nare left unable to conduct their role due to unavailable or \nunreliable AI functionality. Plan ahead to enable teachers \nto apply new AI technologies to their current practices and \ntransition to new ways of working; encourage the formation \nof communities of educators who share experiences and \nday-to-day best practice and foster innovative uses of AI tools. Provide simplified guidelines based on emerging technology \nresearch to update teachers on the latest findings that they \nmight apply in classroom settings, and increase lifelong-\nlearning opportunities for teachers to keep up with the \nchanges brought by AI inside and outside of the classroom. à EXAMPLES\nUNESCO ICT Competency Framework for Teachers:  \nhttps://unesdoc.unesco.org/ark:/48223/pf0000265721; \nResources on AI in K-12 education, International Society for \nTechnology in Education (ISTE): https://www.iste.org/learn/AI-in-\neducation \nPLAN THE USE OF AI TO SUPPORT LIFELONG LEARNING \nACROSS AGES, LOCATIONS AND BACKGROUNDS\n \n Actively seek and promote the use of AI to support \na wide range of educational approaches and diverse \npathways for lifelong learning: Initiate and sustain the \nability of institutions to leverage AI to become more \ndynamic, serve higher numbers of non-traditional learners, \nand provide lifelong learning across formal, non-formal and \ninformal settings. Suggest viable mechanisms for traditional \ninstitutions to move towards hybrid methods, combining \nface-to-face teaching with dynamically evolving, AI-powered \ncourses; and provide incentives for partnerships between \ninstitutions and AI providers, to foster the development of AI \ntools that maximize opportunities for lifelong learning.  Build AI tools and systems to track learning outcomes \nand credentials across levels and locations of study: Develop \nAI platforms, tools and systems to track learning outcomes \nand enable easier skill specialization; and explore ways to use \nAI to expand the availability of educational credentials and \nqualification pathways. à PARTIAL EXAMPLES\nSkillsFuture initiative, Singaporean Government:  \nhttps://www.skillsfuture.gov.sg; OpenCert (Singapore), which \nsupports the verification of lifelong-learning certificates obtained \nfrom ‘any’ institution: https://opencerts.io\n \n Address imbalances in access to AI across age groups: \nSet up campaigns to combat barriers to entry for the most \nvulnerable groups, including older people, and initiate \nprojects that generate interest in AI among learners of \ndifferent ages and backgrounds."
  },
  {
    "id": "6ab7c9a5-94df-4a53-8e9c-fd3f4dcb5979",
    "filename": "documents\\376709eng.pdf",
    "page_number": 39,
    "chunk_id": "39_0",
    "chunk_text": "AI and education: Guidance for policy-makers – Policy recommendations\n36\nDEVELOP VALUES AND SKILLS FOR LIFE AND WORK \nIN THE AI ERA\n \n Build prediction models to identify trends in \nemployment and skills, and develop retraining \nprogrammes for those in jobs at risk of AI automation: \nIdentify the social costs of job automation, and increase \npublic awareness of the resulting national and global shifts \nin skills demand. Establish a national focus on enhancing \nfuture-proof skills at all levels of education; provide options \nfor re-skilling pathways and build resilience in the workforce \nto cope with the systemic and long-term transformation \nof the labour market. Provide special protections for older \nworkers who may find it more challenging to learn new \nskills and adapt to new environments. Encourage training \nprogrammes to include a focus on how AI will impact every \nprofession. à EXAMPLE\nCEDEFOP Skills Forecast: EU tool for skills prediction and \npreparation: https://www.cedefop.europa.eu/en/publications-and-\nresources/data-visualisations/skills-forecast\n \n Integrate AI-related skills into school curricula and \ntechnical and vocational education and training (TVET) \nqualifications: Enact changes in curricula to prepare \nstudents for the future, ensuring their relevance to shifting \neconomies, labour markets and societies across all subjects \nand competencies. Develop courses, programmes and \nqualifications to provide awareness and expertise around \nhow AI technologies work, their ethical implications, and \nhow they should be designed. Support the development \nof tools for learning about AI that are underpinned by \npedagogical research and sound methodologies. à EXAMPLES\nThe Wekinator, a free, open-source software created by Rebecca \nFiebrink, with which one may use machine learning to build new \nmusical instruments, gestural game controllers, and computer \nvision and listening systems: http://www.wekinator.org/\nTeaching AI for K12, a portal created by UNESCO and Ericsson of \nlinks to free resources that teachers can use to teach about AI, plus \nsome information to help teachers learn about AI:  \nhttp://teachingaifork12.org\n \n Take institutional actions to enhance AI literacy across \nall sectors of society: Provide basic AI education to all \ncitizens, educating them on thinking critically and responsibly \nabout their choices, rights and privileges in the context of \nAI and its impact on their day-to-day lives. Inform them \non how to protect their privacy and control their own data \nand decisions. Dismantle the myths and hype around AI by \neducating the population about its limitations, as well as the \ndifferences between AI and human intelligence."
  },
  {
    "id": "d5c27329-1d80-43bf-ae3a-6954d3e8194d",
    "filename": "documents\\376709eng.pdf",
    "page_number": 39,
    "chunk_id": "39_1",
    "chunk_text": "Develop courses, programmes and \nqualifications to provide awareness and expertise around \nhow AI technologies work, their ethical implications, and \nhow they should be designed. Support the development \nof tools for learning about AI that are underpinned by \npedagogical research and sound methodologies. à EXAMPLES\nThe Wekinator, a free, open-source software created by Rebecca \nFiebrink, with which one may use machine learning to build new \nmusical instruments, gestural game controllers, and computer \nvision and listening systems: http://www.wekinator.org/\nTeaching AI for K12, a portal created by UNESCO and Ericsson of \nlinks to free resources that teachers can use to teach about AI, plus \nsome information to help teachers learn about AI:  \nhttp://teachingaifork12.org\n \n Take institutional actions to enhance AI literacy across \nall sectors of society: Provide basic AI education to all \ncitizens, educating them on thinking critically and responsibly \nabout their choices, rights and privileges in the context of \nAI and its impact on their day-to-day lives. Inform them \non how to protect their privacy and control their own data \nand decisions. Dismantle the myths and hype around AI by \neducating the population about its limitations, as well as the \ndifferences between AI and human intelligence. Carefully \nintegrate emerging AI literacy skills with existing foundational \nskills such as media and information literacies, and identify \nways of merging the different required literacies to prevent \noverloading the curricula. à EXAMPLE\n1 Percent: Finland’s plan to train its population in AI:  \nhttps://www.politico.eu/article/finland-one-percent-ai-artificial-\nintelligence-courses-learning-training/ \n \n Help higher education and research institutions to \nfoster local AI talent: Set up plans to help higher education \nand research institutions build or enhance programmes to \ndevelop local AI talent, and create a gender-balanced pool \nof professionals from diverse socio-economic backgrounds \nwho have the expertise to design AI systems. Develop \nexecutive master programmes to reskill engineers in AI, and \nincentivize engineering companies to invest in retraining \ntheir workforces in AI.  Retain local AI talent: Incentivize AI companies to base \nthemselves locally; mitigate against regional differences in \nsalaries and rewards; and retain AI professionals by providing \ninteresting intellectual challenges and a good work-life balance."
  },
  {
    "id": "ecbf3a79-8858-4d05-99a7-11e20fb11b36",
    "filename": "documents\\376709eng.pdf",
    "page_number": 39,
    "chunk_id": "39_2",
    "chunk_text": "Dismantle the myths and hype around AI by \neducating the population about its limitations, as well as the \ndifferences between AI and human intelligence. Carefully \nintegrate emerging AI literacy skills with existing foundational \nskills such as media and information literacies, and identify \nways of merging the different required literacies to prevent \noverloading the curricula. à EXAMPLE\n1 Percent: Finland’s plan to train its population in AI:  \nhttps://www.politico.eu/article/finland-one-percent-ai-artificial-\nintelligence-courses-learning-training/ \n \n Help higher education and research institutions to \nfoster local AI talent: Set up plans to help higher education \nand research institutions build or enhance programmes to \ndevelop local AI talent, and create a gender-balanced pool \nof professionals from diverse socio-economic backgrounds \nwho have the expertise to design AI systems. Develop \nexecutive master programmes to reskill engineers in AI, and \nincentivize engineering companies to invest in retraining \ntheir workforces in AI.  Retain local AI talent: Incentivize AI companies to base \nthemselves locally; mitigate against regional differences in \nsalaries and rewards; and retain AI professionals by providing \ninteresting intellectual challenges and a good work-life balance. à EXAMPLES\nNext AI, a programme delivered on campuses in Toronto and \nMontréal in Canada to identify talented teams and leverage Canada’s \nresources and provide them with the necessary capital, mentorship, \neducation and network: https://www.nextcanada.com/next-ai/; \nA Chinese Government initiative to train 500 university \nteachers and 5,000 students in AI: https://www.ecns.cn/2018/04-\n07/298280.shtml\n6.6 Pilot testing, monitoring and evaluation, and building an evidence base\nBUILD A TRUSTED EVIDENCE BASE TO SUPPORT  \nTHE USE OF AI IN EDUCATION \n \n Test and scale up evidence-based avenues of applying \nAI in learning: In accordance with educational priorities, \nrather than novelty or hype, encourage the pilot testing \nand evidence-informed adoption of technologies such as \nAI-enhanced personalized learning models, dialogue-based \ntutoring systems, exploratory learning systems, automatic \nwriting evaluation systems, language learning tools, AI-based \nartwork and music generators, chatbots, augmented and virtual \nreality tools, and learning network orchestrators. Incentivize the \nadoption of AI tools that encourage open-ended, exploratory \nand diverse learning environments. Foster broad, transferable \nabilities including social-emotional skills, meta-cognition, \ncollaboration, problem-solving, and creativity. Ensure that the \napplication of AI in education is strategic (i.e. has long-term \npedagogical aims) rather than short-term or ad hoc."
  },
  {
    "id": "bf5d8253-14d6-4392-b700-d9f3e584b8fe",
    "filename": "documents\\376709eng.pdf",
    "page_number": 40,
    "chunk_id": "40_0",
    "chunk_text": "Policy recommendations – AI and education: Guidance for policy-makers \n37\n \nà EXAMPLES\nITalk2Learn, a three-year collaborative European project (Nov \n2012 – Oct 2015) that aimed to develop an open-source intelligent \ntutoring platform that supports maths learning for students aged 5 \nto 11: https://www.italk2learn.com/; \nFractionsLab, UK, an exploratory learning environment to teach \nfractions with AI-driven feedback: http://fractionslab.lkl.ac.uk; \nSquirrel AI Learning, developed by China’s Yixue Group, an \nadaptive learning engine based on the pattern recognition \nalgorithm: http://squirrelai.com/; https://www.technologyreview. com/s/614057/china-squirrel-has-started-a-grand-experiment-in-ai-\neducation-it-could-reshape-how-the/; \nSmartMusic, a web-based suite of music education tools that \nsupport musicians’ practice and development: https://www. smartmusic.com/; \nAIArtists.org, which provides creative tools to generate AI art: \nhttps://aiartists.org/ai-generated-art-tools \n \n Establish AI-specific criteria based on proven \npedagogical research and methodologies, to systematically \nand rigorously verify vendors’ claims about AI’s potentials: \nDevelop AI-specific criteria catering for the human, social \nand ethical concerns that relate to each of the three core \ncomponents of applying AI in education: data, algorithmic \nanalyses, and educational practices.  Facilitate local pilot evaluations of AI systems to evaluate \ntheir relevance and effectiveness: Design and conduct large-\nscale pilot evaluations of AI systems supplied by external \nproviders. Test whether they are relevant to the local context \nand effective in terms of educational practices, objectives, \ndiversity, culture, and demographics. Use the results to \ncustomize the AI system’s data, design and integration in \nresponse to local needs. Monitor the application of the system \nto protect against conflicts in interests or partnerships, and \ndiscrepancies related to data protection or ownership.  Calculate and analyse the environmental cost of \nleveraging AI technologies at scale: Develop sustainable \ntargets to be met by AI corporations in a bid to avoid \ncontributing to climate change and damage to the natural \nenvironment. Incentivize environmentally friendly means of \nproducing the energy and resources required for large-scale AI \ndeployment. STRENGTHEN RESEARCH AND EVALUATION IN THE FIELD \nOF AI AND EDUCATION\n \n Enable the use of AI to promote and improve educational \nresearch and innovation: Leverage AI data collection \npractices and methodologies to improve research on \neducation technologies. Draw lessons from successful cases \nand scale up evidence-based practices.  Review the comprehensive impacts of AI on education: \nExploit research and review processes to fully understand the \nsocial and ethical implications of incorporating AI into local \neducational contexts; conduct critical reviews of uncharted \nchallenges and risks, including changes in teacher-student \nand student-student collaboration and social dynamics."
  },
  {
    "id": "2295a5f4-5b84-4963-a8a2-356de96bf282",
    "filename": "documents\\376709eng.pdf",
    "page_number": 40,
    "chunk_id": "40_1",
    "chunk_text": " Calculate and analyse the environmental cost of \nleveraging AI technologies at scale: Develop sustainable \ntargets to be met by AI corporations in a bid to avoid \ncontributing to climate change and damage to the natural \nenvironment. Incentivize environmentally friendly means of \nproducing the energy and resources required for large-scale AI \ndeployment. STRENGTHEN RESEARCH AND EVALUATION IN THE FIELD \nOF AI AND EDUCATION\n \n Enable the use of AI to promote and improve educational \nresearch and innovation: Leverage AI data collection \npractices and methodologies to improve research on \neducation technologies. Draw lessons from successful cases \nand scale up evidence-based practices.  Review the comprehensive impacts of AI on education: \nExploit research and review processes to fully understand the \nsocial and ethical implications of incorporating AI into local \neducational contexts; conduct critical reviews of uncharted \nchallenges and risks, including changes in teacher-student \nand student-student collaboration and social dynamics.  Encourage investment and provide targeted funding \nin order to build an evidence-based ecosystem for AI in \neducation: Help stimulate and support the research and \ndevelopment of AI applications in the commercial and \nuniversity sectors, enhancing local expertise while minimizing \nthe influence of vested interests.  Fund and incentivize research on AI and education \noutside the realm of government- and corporate-driven \ndevelopment: Protect the evolution and expansion of local \nAI-in-education expertise within research and university \nsettings, and minimize the influence of vested interests on \nwhat AI is developed and how it is evaluated. à EXAMPLE\nInternational Research Centre on Artificial Intelligence (IRCAI) \nunder the auspices of UNESCO, whose mission is to undertake \nresearch, advocacy, capacity-building and dissemination of \ninformation about AI. https://ircai.org/\n6.7 Fostering local AI innovations for education \nPROMOTE THE LOCAL DEVELOPMENT  \nOF AI TECHNOLOGIES FOR EDUCATION\n \n Attract corporate investment and provide funding \nto create an evidence base: Help stimulate and support \nthe development of human-centric AI-in-education tools, \nbringing together learners, funders, commercial developers, \neducators, and learning scientists, in order to address market \nfailures, the complexity of educational practices worldwide, \nand the challenges of scaling initiatives.  Foster innovations and incubate the local development \nof AI technologies and tools: Synergize expertise, resources \nand capacities, and leverage evidence-driven research \nmethodologies across corporate AI design. Generate \nindependent evaluations of consumer-targeted AI and \nencourage progress towards an aligned, human-centric future \nfor AI development."
  },
  {
    "id": "b8105c90-3d81-4315-ae04-bd6a4046f5b7",
    "filename": "documents\\376709eng.pdf",
    "page_number": 40,
    "chunk_id": "40_2",
    "chunk_text": " Fund and incentivize research on AI and education \noutside the realm of government- and corporate-driven \ndevelopment: Protect the evolution and expansion of local \nAI-in-education expertise within research and university \nsettings, and minimize the influence of vested interests on \nwhat AI is developed and how it is evaluated. à EXAMPLE\nInternational Research Centre on Artificial Intelligence (IRCAI) \nunder the auspices of UNESCO, whose mission is to undertake \nresearch, advocacy, capacity-building and dissemination of \ninformation about AI. https://ircai.org/\n6.7 Fostering local AI innovations for education \nPROMOTE THE LOCAL DEVELOPMENT  \nOF AI TECHNOLOGIES FOR EDUCATION\n \n Attract corporate investment and provide funding \nto create an evidence base: Help stimulate and support \nthe development of human-centric AI-in-education tools, \nbringing together learners, funders, commercial developers, \neducators, and learning scientists, in order to address market \nfailures, the complexity of educational practices worldwide, \nand the challenges of scaling initiatives.  Foster innovations and incubate the local development \nof AI technologies and tools: Synergize expertise, resources \nand capacities, and leverage evidence-driven research \nmethodologies across corporate AI design. Generate \nindependent evaluations of consumer-targeted AI and \nencourage progress towards an aligned, human-centric future \nfor AI development. Invest in the education and training of \nlocal talent and build an appetite for AI start-up ecosystems to \nbe formed locally, within a network of investment and access \nto labour and consumer markets. Engage in international \ncollaborations to build resources and capacity for deploying \nAI-based technologies at scale, to enable the development of \nlocal AI tools and expertise. à EXAMPLE\nIBM Research–Africa is IBM’s 12th global research lab and the \ncontinent’s first industrial research facility. It is driving innovation \nby developing commercially viable solutions to transform lives \nand spark new business opportunities in key areas including \neducation: https://www.research.ibm.com/labs/africa"
  },
  {
    "id": "a2f18631-3e50-4a6a-b1ec-6d85ecb97d24",
    "filename": "documents\\376709eng.pdf",
    "page_number": 41,
    "chunk_id": "41_0",
    "chunk_text": "AI and education: Guidance for policy-makers – References\n38\n7. References\nAdams, R. 2019. Artificial intelligence has a gender bias \nproblem – just ask Siri. The Conversation. Available at: \nhttps://theconversation.com/artificial-intelligence-has-a-\ngender-bias-problem-just-ask-siri-123937 (Accessed 28 \nMarch 2021). AIArtists.org. 2019. AIArtists. Available at: https://aiartists.org/\nai-generated-art-tools (Accessed 28 March 2021). Baker, T., Smith, L. and Anissa, N. 2019. Educ-AI-tion Rebooted? Exploring the future of artificial intelligence in schools \nand colleges. London, NESTA. Available at: https://www. nesta.org.uk/report/education-rebooted (Accessed 28 \nMarch 2021). Barrett, H. 2017. Plan for five careers in a lifetime. Financial Times. Available at: https://www.ft.com/\ncontent/0151d2fe-868a-11e7-8bb1-5ba57d47eff7 \n(Accessed 29 December 2020). Belpaeme, T., Kennedy, J., Ramachandran, A., Scassellati, B. and \nTanaka, F. 2018. Social robots for education:  \nA review. Science Robotics, Vol. 3, No. 21, pp. 1–9. Bernardini, S., Porayska-Pomsta, K. and Smith, T. J. 2014. ECHOES: An intelligent serious game for fostering social \ncommunication in children with autism. Information \nSciences, Vol. 264, pp. 41–60. Bhutani, A. and Wadhwani P. 2018. Artificial Intelligence (AI) in \nEducation Market Size, By Model (Learner, Pedagogical, \nDomain), By Deployment (On-Premise, Cloud), By \nTechnology (Machine Learning, Deep Learning, Natural \nLanguage Processing (NLP)), By Application (Learning \nPlatform & Virtual Facilitators, Intelligent Tutoring System \n(ITS), Smart Content, Fraud & Risk Management), By \nEnd-Use (Higher Education, K-12 Education, Corporate \nLearning), Industry Analysis Report, Regional Outlook, \nGrowth Potential Competitive Market Share & Forecast, \n2018 – 2024. Available at: https://www.gminsights.com/\nindustry-analysis/artificial-intelligence-ai-in-education-\nmarket (Accessed 29 December 2020). Bloom, B. S. 1984. The 2 Sigma Problem: The search for methods \nof group instruction as effective as one-to-one tutoring. Educational Researcher, Vol. 13, no. 6, pp. 4–16. Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., \nDhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, \nA., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, \nT., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., … \nAmodei, D. 2020. Language Models are Few-Shot Learners. ArXiv:2005.14165 [Cs]. Available at: http://arxiv.org/\nabs/2005.14165 (Accessed 22 February 2021). Brynjolfsson, E. and McAfee, A., 2014. The Second Machine \nAge: Work, Progress, and Prosperity in a Time of Brilliant \nTechnologies. WW Norton & Company, New York, NY. Burt, A. 2019. The AI Transparency Paradox, Harvard Business \nReview [Online]. Available at: https://hbr.org/2019/12/the-\nai-transparency-paradox (Accessed 28 December 2020). Carbonell, J. R. 1970. AI in CAI: An artificial-intelligence \napproach to computer-assisted instruction. IEEE \nTransactions on Man-Machine Systems, Vol. 11, No. 4, \npp. 190–202. Carretero, S., Vuorikari, R., and Punie, Y. 2017."
  },
  {
    "id": "019b1e87-1525-4c1f-b449-67be5c2b2054",
    "filename": "documents\\376709eng.pdf",
    "page_number": 41,
    "chunk_id": "41_1",
    "chunk_text": "11, No. 4, \npp. 190–202. Carretero, S., Vuorikari, R., and Punie, Y. 2017. DigComp 2.1: \nThe digital competence framework for citizens with \neight proficiency levels and examples of use, EUR 28558 \nEN. Available at: http://publications.jrc.ec.europa.eu/\nrepository/bitstream/JRC106281/web-digcomp2.1pdf_\n(online).pdf (Accessed 22 February 2021). CEDEFOP, 2019. Skills Forecast: EU tool for skills prediction and \npreparation. Available at: https://www.cedefop.europa. eu/en/publications-and-resources/data-visualisations/\nskills-forecast (Accessed 29 December 2020). Cohen, P.A., Kulik, J.A. and Kulik, C.-L.C. 1982. Educational \nOutcomes of Tutoring: A Meta-Analysis of Findings. American Educational Research Journal 19, 237–248. COMEST (UNESCO World Commission on the Ethics of Scientific \nKnowledge and Technology) 2019. Preliminary Study on \nthe Ethics of Artificial Intelligence. Available at: \nhttps://unesdoc.unesco.org/ark:/48223/pf0000367823. (Accessed 28 December 2020). Connor, N. 2018. Chinese school uses facial recognition \nto monitor student attention in class. The Telegraph. Available at: https://www.telegraph.co.uk/\nnews/2018/05/17/chinese-school-uses-facial-recognition-\nmonitor-student-attention (Accessed 28 December 2020). Cukurova, M., Luckin, R., Mavrikis, M. and Millán, E., 2017. Machine and human observable differences in groups’ \ncollaborative problem-solving behaviours, in: European \nConference on Technology Enhanced Learning. Springer, \npp. 17–29. DataKind, 2013. DataKind. Available at: https://www.datakind. org (Accessed 29 December 2020). Dautenhahn, K., Nehaniv, C. L., Walters, M. L., Robins, B., \nKose-Bagci, H., Mirza, N. A. and Blow, M. 2009. KASPAR – \na minimally expressive humanoid robot for human–robot \ninteraction research. Applied Bionics and Biomechanics, Vol. 6, No. 3-4, Special Issue on Humanoid Robots, pp. 369–397. Dean Jr., D. and Kuhn, D. 2007. Direct instruction vs. discovery: \nThe long view. Science Education, Vol. 91, No. 3, \npp. 384–397. Ding, J. 2018. Deciphering China’s AI Dream. The Context, \nComponents, Capabilities, and Consequences of China’s \nStrategy to Lead the World in AI. Centre for the Governance \nof AI, Future of Humanity Institute, University of Oxford. Available at: https://www.fhi.ox.ac.uk/wp-content/\nuploads/Deciphering_Chinas_AI-Dream.pdf (Accessed 22 \nFebruary 2021)."
  },
  {
    "id": "8415a5b8-a914-41cd-af70-2c6623171ed7",
    "filename": "documents\\376709eng.pdf",
    "page_number": 42,
    "chunk_id": "42_0",
    "chunk_text": "References – AI and education: Guidance for policy-makers \n39\nDong, X., Wu, J. and Zhou, L. 2017. Demystifying AlphaGo \nZero as AlphaGo GAN. Available at: http://arxiv.org/\nabs/1711.09091 (Accessed 15 February 2020). Douglas, L. 2017. AI is not just learning our biases; it is \namplifying them. Medium. Available at: https://medium. com/@laurahelendouglas/ai-is-not-just-learning-\nourbiases-it-is-amplifying-them-4d0dee75931d  \n(Accessed 28 August 2018). du Boulay, B. 2016. Artificial intelligence as an effective \nclassroom assistant. IEEE Intelligent Systems, Vol. 31, No. 6, \npp. 76–81. du Boulay, B., Poulovassilis, A., Holmes, W. and Mavrikis, M. 2018. What does the research say about how artificial \nintelligence and big data can close the achievement \ngap? R. Luckin (ed.), Enhancing Learning and Teaching \nwith Technology. London, Institute of Education Press, \npp. 316–327. ECNS. 2018. China to train 500 teachers in AI. Available at:  \nhttp://www.ecns.cn/2018/04-07/298280.shtml  \n(Accessed 29 December 2020). EPFL Technical University, n.d.. The CoWriter. Available at: \nhttps://www.epfl.ch/labs/chili/index-html/research/\ncowriter (Accessed 29 December 2020). European Union. 2016. General Data Protection Regulation. Available at: https://eur-lex.europa.eu/legal-content/\nEN/TXT/PDF/?uri=CELEX:32016R0679 (Accessed 22 \nFebruary 2021). European Union. 2018. The General Data Protection Regulation. Available at: https:// gdpr-info.eu (Accessed 29 \nDecember 2020). European Union. 2019. Ethics guidelines for trustworthy \nAI. Available at: https:// ec.europa.eu/digital-single-\nmarket/en/news/ethics-guidelines-trustworthy-ai \n(Accessed 29 December 2020). Feathers, T. 2019. Flawed Algorithms Are Grading Millions of \nStudents’ Essays. Vice. Available at: https://www.vice.com/\nen_us/article/pa7dj9/flawed-algorithms-are-grading-\nmillions-of-students-essays (Accessed 13 January 2020). Feng, J. 2019. China to curb facial recognition technology \nin schools. SupChina. Available at: https://supchina. com/2019/09/06/china-to-curb-facial-recognition-\ntechnology-in-schools (Accessed 29 December 2020). Ferguson, R., Brasher, A., Clow, D., Cooper, A., Hillaire, G., \nMittelmeier, J., Rienties, B., Ullmann, T. and Vuorikari, R. 2016. Research Evidence on the Use of Learning Analytics: \nImplications for Education Policy. Available at: http://oro. open.ac.uk/48173/ (Accessed 22 February 2021). Fiebrink, R. 2018. The Wekinator. Available at: http://www. wekinator.org (Accessed 29 December 2020). Finnish Government. 2019. 1 Percent. Available at: https://\nwww.politico.eu/article/finland-one-percent-ai-artificial-\nintelligence-courses-learning-training/ (Accessed 29 \nDecember 2020). Ford, M. 2018. Architects of Intelligence: The truth about AI from \nthe people building it. Birmingham, Packt Publishing. Frey, C.B. and Osborne, M. A. 2017. The future of employment: \nHow susceptible are jobs to computerisation? Technological Forecasting and Social Change 114: \n254–280. Frontier Economics. 2018. The Impact of Artificial Intelligence \non Work. An evidence review prepared for the Royal \nSociety and the British Academy. Available at: https://\nroyalsociety.org/-/media/policy/projects/ai-and-work/\nfrontier-review-the-impact-of-AI-on-work.pdf (Accessed 3 \nFebruary 2021). Giest, S. 2017. Big data for policymaking: Fad or fast-track? Policy Sciences, Vol. 50, No. 3, pp. 367–382. Goel, A.K."
  },
  {
    "id": "ca84acfb-d1df-4741-98d3-96db69110664",
    "filename": "documents\\376709eng.pdf",
    "page_number": 42,
    "chunk_id": "42_1",
    "chunk_text": "Policy Sciences, Vol. 50, No. 3, pp. 367–382. Goel, A.K. and Polepeddi, L. 2017. Jill Watson: A virtual teaching \nassistant for online education. Georgia Institute of \nTechnology. Available at: https://smartech.gatech.edu/\nhandle/1853/59104 (Accessed 22 February 2021). Goertzel, B. 2007. Human-level artificial general intelligence and \nthe possibility of a technological singularity: A reaction to \nRay Kurzweil’s The Singularity Is Near, and McDermott’s \ncritique of Kurzweil. Artificial Intelligence, Vol. 171, No. 18, \nSpecial Review Issue, pp. 1161–1173. Government of Malta. 2019. Towards an AI Strategy. High-level \npolicy document for public consultation. Available \nat: https://malta.ai/wp-content/uploads/2019/04/\nDraft_Policy_document_-_online_version.pdf (Accessed 2 \nJanuary 2020). Government of the People’s Republic of China. 2017. Next Generation of Artificial Intelligence Plan. Available at: \nhttps://flia.org/wp-content/uploads/2017/07/A-New-\nGeneration-of-Artificial-Intelligence-Development-Plan-1. pdf (Accessed 22 February 2021). Government of the Republic of Korea. 2016. Mid- to Long-Term \nMaster Plan in Preparation for the Intelligent Information \nSociety: Managing the Fourth Industrial Revolution. Available at: http://www.msip.go.kr/dynamic/file/\nafieldfile/msse56/1352869/2017/07/20/Master%20\nPlan%20for%20the%20intelligent%20information%20\nsociety.pdf (Accessed 15 March 2019). Graesser, A. C., VanLehn, K., Rosé, C. P., Jordan, P. W. and Harter, \nD. 2001. Intelligent tutoring systems with conversational \ndialogue. AI Magazine, Vol. 22, No. 4, p. 39. Graham, J. 2018. Meet the robots teaching Singapore’s kids \ntech. Available at: https://apolitical.co/solution_article/\nmeet-the-robots-teaching-singapores-kids-tech/ \n(Accessed 5 April 2019). Hao, K. 2019. In 2020, let’s stop AI ethics-washing and \nactually do something - MIT Technology Review [WWW \nDocument]. MIT Technology Review. Available at: https://\nwww.technologyreview.com/s/614992/ai-ethics-washing-\ntime-to-act/ (Accessed 13 January 2020)."
  },
  {
    "id": "07f15a27-5a66-4f80-98b0-4583a15245c1",
    "filename": "documents\\376709eng.pdf",
    "page_number": 43,
    "chunk_id": "43_0",
    "chunk_text": "AI and education: Guidance for policy-makers – References\n40\nHarvard University and Amgen Foundation. 2020. LabXchange. Available at: https://www.multivu.com/players/\nEnglish/8490258-amgen-foundation-harvard-labxchange  \n(Accessed 29 December 2020). Harwell, D. 2019. Colleges are turning students’ phones \ninto surveillance machines, tracking the locations \nof hundreds of thousands [WWW Document]. Washington Post. Available at: https://www. washingtonpost.com/technology/2019/12/24/\ncolleges-are-turning-students-phones-into-surveillance-\nmachines-tracking-locations-hundreds-thousands \n(Accessed 3 January 2020). Hawking, S., Russell, S., Tegmark, M. and Wilczek, F. 2014. Transcendence looks at the implications of artificial \nintelligence – but are we taking AI seriously enough? The \nIndependent, May. Available at: http://www.independent. co.uk/news/science/stephen-hawking-transcendence-\nlooks-at-the-implications-of-artificial-intelligence--but-\nare-we-taking-ai-seriously-enough-9313474.html  \n(Accessed 13 September 2015). Heikkila, A. 2018. Telepresence In Education And The Future \nOf eLearning. eLearning Industry. Available at: https://\nelearningindustry.com/telepresence-in-education-future-\nelearning (Accessed 29 December 2020). Herodotou, C., Gilmour, A., Boroowa, A., Rienties, B., Zdrahal, Z. and Hlosta, M. 2017. Predictive modelling for addressing \nstudents’ attrition in higher education: The case of OU \nAnalyse. The Open University, Milton Keynes, United \nKingdom. Available at: http://oro.open.ac.uk/49470/ \n(Accessed 5 November 2018). Herold, B. 2018. How (and Why) Ed-Tech Companies Are \nTracking Students’ Feelings [WWW Document]. Education \nWeek. Available at: https://www.edweek.org/technology/\nhow-and-why-ed-tech-companies-are-tracking-students-\nfeelings/2018/06 (Accessed 28 December 2020). HITSA. 2017. ProgeTiger Programme 2015-2017. Available \nat: https://www.hitsa.ee/it-education/educational-\nprogrammes/progetiger (Accessed 1 November 2019). Holmes, W., Anastopoulou, S., Schaumburg, H. and Mavrikis, \nM. 2018a. Technology-Enhanced Personalised Learning: \nUntangling the evidence. Stuttgart, Robert Bosch Stiftung. Available at: https://www.bosch-stiftung.de/sites/default/\nfiles/publications/pdf/2018-08/Study_Technology-\nenhanced%20Personalised%20Learning.pdf  \n(Accessed 22 February 2021). Holmes, W., Bektik, D., Whitelock, D. and Woolf, B. P. 2018b. Ethics in AIED: Who cares? C. Penstein Rosé, R. Martínez-\nMaldonado, H. U. Hoppe, R. Luckin, M. Mavrikis, K. Porayska-Pomsta, B. McLaren, and B. du Boulay (eds.), \nLecture Notes in Computer Science. London, Springer \nInternational Publishing, vol. 10948, pp. 551–553. Holmes, W., Bialik, M. and Fadel, C. 2019. Artificial Intelligence \nin Education: Promises and implications for teaching and \nlearning. Boston, MA, Center for Curriculum Redesign. Holstein, K., McLaren, B. M. and Aleven, V. 2018. Student \nlearning benefits of a mixed-reality teacher awareness \ntool in AI-enhanced classrooms. C. Penstein Rosé, R. Martínez-Maldonado, H. U. Hoppe, R. Luckin, R., M. Mavrikis, K. Porayska-Pomsta, B. McLaren, and B. du Boulay \n(eds.), Proceedings of the 19th International Conference, AI \nin Education 2018 London, United Kingdom, June 27–30, \n2018. Cham, Springer International Publishing, vol. 10947, \npp. 154–168. Hood, D., Lemaignan, S. and Dillenbourg, P. 2015. When \nChildren Teach a Robot to Write: An Autonomous \nTeachable Humanoid Which Uses Simulated Handwriting. ACM/IEEE International Conference on Human-Robot \nInteraction 2015, 83–90."
  },
  {
    "id": "f81675a6-4d60-4eed-8c4c-00a4f1206742",
    "filename": "documents\\376709eng.pdf",
    "page_number": 43,
    "chunk_id": "43_1",
    "chunk_text": "Hood, D., Lemaignan, S. and Dillenbourg, P. 2015. When \nChildren Teach a Robot to Write: An Autonomous \nTeachable Humanoid Which Uses Simulated Handwriting. ACM/IEEE International Conference on Human-Robot \nInteraction 2015, 83–90. Hopkins, P. and Maccabee, R. 2018. Chatbots and digital \nassistants: Getting started in FE and HE. Bristol, JISC. Hume, K.H., 2017. Artificial intelligence is the future—but it’s \nnot immune to human bias. Macleans. Available at: https://\nwww.macleans.ca/opinion/artificial-intelligence-is-the-\nfuture-but-its-not-immune-to-human-bias (Accessed 28 \nMarch 2021). IBM, n.d.. IBM Research–Africa. Available at: https://\nwww.research.ibm.com/labs/africa (Accessed 29 \nDecember 2020). Infocomm Media Development Authority. 2017. CODE@\nSG Movement: Developing Computational Thinking as a \nNational Capability. Available at: https://www.imda.gov.sg/\nfor-community/digital-readiness/Computational-Thinking-\nand-Making (Accessed 1 September 2019). iFLYTEK, n.d.. AlphaEgg. Available at: https:// \nifworlddesignguide.com/entry/203859-alphaegg \n(Accessed 29 December 2020). ILO (International Labour Organization). 2019. Work for a \nBrighter Future: Global Commission on the Future of Work. Available at: https://www.ilo.org/wcmsp5/groups/\npublic/---dgreports/---cabinet/documents/publication/\nwcms_662410.pdf (Accessed 26 January 2021). IRCAI (International Research Centre on Artificial Intelligence \nunder the auspices of UNESCO). 2020. Available at: https://\nircai.org/ (Accessed 29 December 2020). iResearch Global. 2019. 2018 China’s K12 Dual-teacher Classes \nReport. Available at: http://www.iresearchchina.com/\ncontent/details8_51472.html (Accessed 5 April 2019). ISTE (International Society for Technology in Education). 2018. Resources on AI in K-12 education. Available at: https://www. iste.org/learn/AI-in-education (Accessed 29 December 2020). James, E. A., Milenkiewicz, M. T. and Bucknam, A. 2008. Participatory Action Research for Educational Leadership: \nUsing data-driven decision making to improve schools. Sage. Jobin, A., Ienca, M., and Vayena, E. 2019. Artificial Intelligence: \nThe global landscape of ethics guidelines. Nature Machine \nIntelligence, 1(9), 389–399."
  },
  {
    "id": "afb71e42-caae-4c74-8e3e-89e90ba1c2b4",
    "filename": "documents\\376709eng.pdf",
    "page_number": 44,
    "chunk_id": "44_0",
    "chunk_text": "References – AI and education: Guidance for policy-makers \n41\nJoshi, D. 2017. Quoted in https://www.theguardian.com/\nbusiness/2017/aug/20/robots-are-not-destroying-jobs-\nbut-they-are-hollow-out-the-middle-class (Accessed 20 \nJanuary 2021). Kelly, S., Olney, A.M., Donnelly, P., Nystrand, M. and D’Mello, \nS.K. 2018. Automatically measuring question authenticity \nin real-world classrooms. Educational Researcher, 47(7), \npp.451-464. Kreitmayer, S., Rogers, Y., Yilmaz, E. and Shawe-Taylor, J. 2018. Design in the Wild: Interfacing the OER Learning Journey. Presented at the Proceedings of the 32nd International \nBCS Human Computer Interaction Conference. Lee, K. F. 2018. AI Superpowers: China, Silicon Valley and \nthe New World Order. Houghton Mifflin Harcourt \nPublishing Company. Leelawong, K. and Biswas, G. 2008. Designing learning by \nteaching agents: The Betty’s Brain system. International \nJournal of Artificial Intelligence in Education, Vol. 18, No. 3, \npp. 181–208. Leetaru, K. 2018. Does AI truly learn, and why we need to \nstop overhyping deep learning. Forbes. Available at: \nhttps://www.forbes.com/sites/kalevleetaru/2018/12/15/\ndoes-ai-truly-learn-and-why-we-need-to-stop-overhyping-\ndeep-learning/ (Accessed 10 February 2020). Leopold, T. A., Ratcheva, V., and Zahidi S. 2018. The Future of \nJobs Report 2018. World Economic Forum. Available \nat: http://www3.weforum.org/docs/WEF_Future_of_\nJobs_2018.pdf (Accessed 3 February 2021). Loizos, C. 2017. AltSchool wants to change how kids learn, but \nfears have surfaced that it’s failing students. TechCrunch. Available at: https://social.techcrunch.com/2017/11/22/\naltschool-wants-to-change-how-kids-learn-but-fears-\nthat-its-failing-students-are-surfacing (Accessed \n29 December 2020). Lucas, L. 2018. China’s artificial intelligence ambitions hit \nhurdles. Financial Times. Available at: https://www.ft.com/\ncontent/8620933a-e0c5-11e8-a6e5-792428919cee \n(Accessed 17 February 2019). Luckin, R. 2017. Towards artificial intelligence-based assessment \nsystems. Nat Hum Behav 1, 0028. Luckin, R. and Holmes, W. 2017. A.I. Is the New T.A. in the \nClassroom. Available at: https://howwegettonext.com/a-i-\nis-the-new-t-a-in-the-classroom-dedbe5b99e9e#---0-237. wcmt24rx7 (Accessed 4 January 2017). Luckin, R., Cukurova, M., Baines, E., Holmes, W. and Mann, M. 2017. Solved! Making the case for collaborative problem-\nsolving, London, Nesta. Available at: https://www.nesta. org.uk/report/solved-making-the-case-for-collaborative-\nproblem-solving/ (Accessed 22 February 2021). Luckin, R., Holmes, W., Griffiths, M. and Forcier, L. B. 2016. Intelligence Unleashed: An argument for AI in Education. London, Pearson. Available at: https://www.pearson. com/content/dam/one-dot-com/one-dot-com/global/\nFiles/about-pearson/innovation/open-ideas/Intelligence-\nUnleashed-v15-Web.pdf (Accessed 22 February 2021). Lupton, D. and Williamson, B. 2017. The datafied child: The \ndataveillance of children and implications for their rights’, \nNew Media & Society, Vol. 19, No. 5, pp. 780–794. Madgavkar, A. et al. 2019. The Future of Women at Work: \nTransitions in the age of automation. McKinsey Global \nInstitute. Available at: https://www.mckinsey.com/\nfeatured-insights/gender-equality/the-future-of-\nwomen-at-work-transitions-in-the-age-of-automation \n(Accessed 3 February 2021). Manyika, J., Lund, S., Chui, M., Bughin, J., Woetzel, J., Batra, P., Ko, \nR. and Sanghvi, S. 2017."
  },
  {
    "id": "b4052ab6-ab86-4294-9ff3-f6b11abd1099",
    "filename": "documents\\376709eng.pdf",
    "page_number": 44,
    "chunk_id": "44_1",
    "chunk_text": "McKinsey Global \nInstitute. Available at: https://www.mckinsey.com/\nfeatured-insights/gender-equality/the-future-of-\nwomen-at-work-transitions-in-the-age-of-automation \n(Accessed 3 February 2021). Manyika, J., Lund, S., Chui, M., Bughin, J., Woetzel, J., Batra, P., Ko, \nR. and Sanghvi, S. 2017. Jobs lost, jobs gained: Workforce \ntransitions in a time of automation. McKinsey Global \nInstitute. Available at: https://www.mckinsey.com/~/\nmedia/BAB489A30B724BECB5DEDC41E9BB9FAC.ashx  \n(Accessed 3 February 2021). Marcus, G. and Davis, E. 2019. Rebooting AI: Building artificial \nintelligence we can trust. New York, Ballantine Books Inc. Marsh, J.A., Pane, J.F. and Hamilton, L.S. 2006. Making sense of \ndata-driven decision making in education: Evidence from \nrecent RAND research. Available at: https://www.rand. org/pubs/occasional_papers/OP170.html (Accessed 22 \nFebruary 2021). Mavrikis, M. 2015a. FractionsLab. Available at: http://\nfractionslab.lkl.ac.uk/ (Accessed 29 December 2020). Mavrikis, M. 2015b. ITalk2Learn. Available at: https://www. italk2learn.com (Accessed 29 December 2020). McCarthy, J., Minsky, M. L., Rochester, N. and Shannon, C. E. 2006. A proposal for the Dartmouth Summer Research \nProject on Artificial Intelligence, August 31, 1955. AI Magazine, Vol. 27, No. 4, pp. 12–14. McKinney, S. M., Sieniek, M., Godbole, V., Godwin, J., Antropova, \nN., Ashrafian, H., Back, T., Chesus, M., Corrado, G. C., Darzi, \nA., Etemadi, M., Garcia-Vicente, F., Gilbert, F. J., Halling-\nBrown, M., Hassabis, D., Jansen, S., Karthikesalingam, A., \nKelly, C. J., King, D., Ledsam, J. R., Melnick, D., Mostofi, H., \nPeng, L., Reicher, J. J., Romera-Paredes, B., Sidebottom, R., \nSuleyman, M., Tse, D., Young, K. C., Fauw, J. D. and Shetty, \nS. 2020. International evaluation of an AI system for breast \ncancer screening. Nature, Vol. 577, No. 7788, pp. 89–94. Ministry of Education, Argentina. 2017. Aprender Conectados. Available at: https://www.educ.ar/recursos/150823/\npresentacion-plan-aprender-conectados (Accessed 29 \nDecember 2020). Ministry of Education, People's Republic of China. 2017. New \nICT Curriculum Standards for Senior High School. Available \nat: http://www.moe.gov.cn/srcsite/A26/s8001/201801/\nt20180115_324647.html (Accessed 29 December 2020). Ministry of Education, People's Republic of China. 2018. Innovative Action Plan for Artificial Intelligence in Higher \nEducation Institutions. Available at: http://www.moe.gov. cn/srcsite/A16/s7062/201804/t20180410_332722.html  \n(Accessed 29 December 2020)."
  },
  {
    "id": "21f4200c-1741-40ce-93ce-d8b7b06d924f",
    "filename": "documents\\376709eng.pdf",
    "page_number": 45,
    "chunk_id": "45_0",
    "chunk_text": "AI and education: Guidance for policy-makers – References\n42\nMinistry of Education & Malaysia Digital Economy Corporation. 2017. Digital Maker Playbook. Available at: https://mdec. my/wp-content/uploads/DMH-Playbook-2021-25Jan2021. pdf (Accessed 22 February 2021). MIT Technology Review and GE Healthcare. 2019. How artificial \nintelligence is making health care more human. Available \nat: https://www.technologyreview.com/hub/ai-effect/  \n(Accessed 9 January 2020). Mitchell, M. 2019. Artificial Intelligence: A guide for thinking \nhumans. London, Penguin. Moravec, H. 1988. Mind Children: The future of robot and human \nintelligence. Boston, MA, Harvard University Press. Mulgan, G. 2018. Artificial intelligence and collective intelligence: \nthe emergence of a new field. AI & Society, 33, 631–632. Narayanan, A. 2019. How to Recognize AI Snake Oil. Available at: \nhttps://www.cs.princeton.edu/~arvindn/talks/MIT-STS-AI-\nsnakeoil.pdf (Accessed 22 February 2021). National Science and Technology Council. 2016. The National \nArtificial Intelligence Research and Development \nStrategic Plan. Available at: https://www.nitrd.gov/news/\nnational_ai_rd_strategic_plan.aspx (Accessed 9 January \n2020). Nemorin, S. 2021. Fair-AI. Project Update #6. Preliminary \nFindings. Available at: https://www.fair-ai.com/project-\nupdate-6 (Accessed 4 February 2021). Next. 2000. Next AI. Available at: https://www.nextcanada.com/\nnext-ai (Accessed 29 December 2020). O’Neil, C. 2017. Weapons of Math Destruction: How big \ndata increases inequality and threatens democracy. London, Penguin. Pareto, L. 2009. Teachable Agents that Learn by Observing \nGame Playing Behavior, in: Craig, S.D., Dicheva, D. (Eds.), \nProceedings of AIED 2009. Presented at the AIED 2009: \n14th International Conference on Artificial Intelligence in \nEducation, Brighton, pp. 31–40. Pedro, F., Miguel, S. Rivas, A., and Valverde, P. 2019. Artificial \nIntelligence in Education: Challenges and opportunities \nfor sustainable development. Paris, UNESCO. Available at: \nhttps://unesdoc.unesco.org/ark:/48223/pf0000366994 \n(Accessed 29 December 2020). Pennington, M., 2018. Five tools for detecting Algorithmic \nBias in AI. Technomancers - LegalTech Blog. Available \nat: https://www.technomancers.co.uk/2018/10/13/five-\ntools-for-detecting-algorithmic-bias-in-ai/ (Accessed 29 \nDecember 2020). Pobiner, S. and Murphy, T. 2018. Participatory design in the \nage of artificial intelligence. Deloitte Insights. Available \nat: https://www2.deloitte.com/us/en/insights/focus/\ncognitive-technologies/participatory-design-artificial-\nintelligence.html (Accessed 29 December 2020). Robinson, A. and Hernandez, K. 2018. Quoted in https://www. edsurge.com/news/2018-11-15-dear-mr-zuckerberg-\nstudents-take-summit-learning-protests-directly-to-\nfacebook-chief (Accessed 29 March 2021). Rummel, N., Mavrikis, M., Wiedmann, M., Loibl, K., Mazziotti, \nC., Holmes, W. and Hansen, A. 2016. Combining exploratory \nlearning with structured practice to foster conceptual \nand procedural fractions knowledge. C. K. Looi, J. Polman, \nU. Cress, and P. Reimann (eds.), Transforming Learning, \nEmpowering Learners: The International Conference of the \nLearning Sciences (ICLS) 2016. Singapore, International \nSociety of the Learning Sciences, Vol. 1, pp. 58–65. Russell, S. and Norvig, P. 2016. Artificial Intelligence: A modern \napproach, 3rd edition. Boston, MA, Pearson. Säuberlich, F."
  },
  {
    "id": "0f756c67-47be-4f2d-b97f-9500bb895a3f",
    "filename": "documents\\376709eng.pdf",
    "page_number": 45,
    "chunk_id": "45_1",
    "chunk_text": "and Norvig, P. 2016. Artificial Intelligence: A modern \napproach, 3rd edition. Boston, MA, Pearson. Säuberlich, F. and Nikolić, D. 2018. AI without machine learning. Teradata Blog. Available at: https://www.teradata. com/Blogs/AI-without-machine-learning (Accessed \n22 December 2019). Schwab, K. 2017. The Fourth Industrial Revolution. New York, NY, \nCrown Publishing. Searle, J. R. 1980. Minds, brains, and programs. Behavioral and \nBrain Sciences, Vol. 3, No. 3, pp. 417–424. Seldon, A. and Abidoye, O. 2018. The Fourth Education \nRevolution: Will artificial intelligence liberate or infantilise \nhumanity? University of Buckingham Press. Self, J. A. 1974. Student models in computer-aided instruction. International Journal of Man-Machine Studies, Vol. 6, No. 2, \npp. 261–276. SmartMusic, n.d.. SmartMusic. Available at: https://www. smartmusic.com (Accessed 29 December 2020). Smith, A. and Anderson. J., 2014. AI, Robotics, and the Future \nof Jobs. Pew Research Center. Washington, DC. Available \nat: https://www.pewresearch.org/internet/wp-content/\nuploads/sites/9/2014/08/Future-of-AI-Robotics-and-Jobs. pdf (Accessed 1 February, 2021). Smith, M. L. and Neupane, S. 2018. Artificial Intelligence and \nHuman Development. Toward a Research Agenda., 0ttawa, \nInternational Development Research Centre. Available at: \nhttps://www.idrc.ca/en/stories/artificial-intelligence-and-\nhuman-development (Accessed 22 February 2021). Stone, P., Brooks, R., Brynjolfsson, E., Calo, R., Etzioni, O., Hager, \nG., Hirschberg, J., Kalyanakrishnan, S., Kamar, E., Kraus, S., \nLeyton-Brown, K., Parkes, D., Press, W., Saxenian, A., Shah, \nJ., Tambe, M. and Teller, A. 2016. Artificial Intelligence and \nLife in 2030, A 100 Year Study on Artificial Intelligence: Report \nof the 2015 Study Panel. Stanford, CA, Stanford University. Available at: http://ai100.stanford.edu/2016-report \n(Accessed 1 February 2019). Tencent Research Institute. 2017. Global Artificial Intelligence \nTalent White Paper. Available at: https://www.tisi.org/\nPublic/Uploads/file/20171201/20171201151555_24517. pdf (Accessed 22 February 2021). The Open University. 2018. OU Analyse. Available at: https://\nanalyse.kmi.open.ac.uk (Accessed 29 December 2020). Trafton, A. 2020. Artificial intelligence yields new \nantibiotic. MIT News | Massachusetts Institute of \nTechnology. Available at: https://news.mit.edu/2020/\nartificial-intelligence-identifies-new-antibiotic-0220 \n(Accessed 28 December 2020)."
  },
  {
    "id": "3973f237-2a3a-47c9-8dca-98634c229759",
    "filename": "documents\\376709eng.pdf",
    "page_number": 46,
    "chunk_id": "46_0",
    "chunk_text": "43\nNotes – AI and education: Guidance for policy-makers \nTuomi, I. 2018. The impact of artificial intelligence on learning, \nteaching, and education. M. Cabrera, R. Vuorikari, and \nY. Punie (eds.), Policies for the future. Luxembourg, \nPublications Office of the European Union, EUR 29442 \nEN. Available at: https://ec.europa.eu/jrc/en/publication/\nimpact-artificial-intelligence-learning-teaching-and-\neducation (Accessed 22 February 2021). Turing, A. M. 1950. Computing machinery and intelligence. Mind, Vol. 59, No. 236, pp. 433–460. UNESCO. 2016. The World Needs Almost 69 Million New Teachers \nto Reach the 2030 Education Goals. UIS Fact Sheet, UNESCO \nInstitute for Statistics. Available at: http://uis.unesco.org/\nen/file/784/download?token=150HBrZo (Accessed 22 \nFebruary 2021). UNESCO. 2018. ICT Competency Framework for Teachers. Available at: https://unesdoc.unesco.org/ark:/48223/\npf0000265721 (Accessed 29 December 2020). UNESCO. 2019a. Beijing Consensus on Artificial Intelligence \nand Education. Available at: https://unesdoc.unesco.org/\nark:/48223/pf0000368303 (Accessed 29 December 2020). UNESCO. 2019b. Steering AI and Advanced ICTs for Knowledge \nSocieties A Rights, Openness, Access, and Multi-\nstakeholder Perspective. Available at: https://unesdoc. unesco.org/ark:/48223/pf0000372132 (Accessed 29 \nDecember 2020). UNESCO. 2020. Outcome document: first draft of the \nRecommendation on the Ethics of Artificial Intelligence. Available at: https://unesdoc.unesco.org/ark:/48223/\npf0000373434 (Accessed 29 December 2020). UNESCO and EQUALS Skills Coalition. 2019. I'd blush if I could: \nclosing gender divides in digital skills through education. Available at: https://unesdoc.unesco.org/ark:/48223/\npf0000367416 (Accessed 29 December 2020). United Arab Emirates. 2017. UAE Strategy for Artificial \nIntelligence. Available at: https://u.ae/en/about-the-uae/\nstrategies-initiatives-and-awards/federal-governments-\nstrategies-and-plans/uae-strategy-for-artificial-intelligence \n(Accessed 22 February 2021). United Nations. 2015. The 2030 Agenda for Sustainable \nDevelopment: Sustainable Development Goals. Available \nat: https://sustainabledevelopment.un.org  \n(Accessed 1 February 2019). Verbert, K., Duval, E., Klerkx, J., Govaerts, S. and Santos, J. L. 2013. Learning analytics dashboard applications. American \nBehavioral Scientist, Vol. 57, No. 10, pp. 1500–1509. Villanueva, C. C. 2003. Education Management Information \nSystem (EMIS) and the Formulation of Education for All \n(EFA) Plan of Action, 2002-2015. UNESCO Almaty Cluster \nOffice and the Ministry of Education of Tajikistan. Available \nat: https://unesdoc.unesco.org/ark:/48223/pf0000156818 \n(Accessed 22 February 2021). World Economic Forum. 2018. Insight Report. The Global \nGender Gap Report. Available at: http://www3.weforum. org/docs/WEF_GGGR_2018.pdf (Accessed 21 July 2020). World Economic Forum and Boston Consulting Group. 2016. New Vision for Education: Fostering social and emotional \nlearning through technology. Geneva, Switzerland. Available at: https://www.weforum.org/reports/\nnew-vision-for-education-fostering-social-and-\nemotional-learning-through-technology (Accessed 22 \nFebruary 2021). Yixue Group. n.d.. Squirrel AI Learning. Available at: https://\nwww.technologyreview.com/2019/08/02/131198/\nchina-squirrel-has-started-a-grand-experiment-in-\nai-education-it-could-reshape-how-the/ (Accessed \n29 December 2020). Zawacki-Richter, O., Marín, V. I., Bond, M. and Gouverneur, \nF. 2019."
  },
  {
    "id": "bb659fbd-4a8d-42ca-8380-cd490f08a7ed",
    "filename": "documents\\376709eng.pdf",
    "page_number": 46,
    "chunk_id": "46_1",
    "chunk_text": "Available at: https://\nwww.technologyreview.com/2019/08/02/131198/\nchina-squirrel-has-started-a-grand-experiment-in-\nai-education-it-could-reshape-how-the/ (Accessed \n29 December 2020). Zawacki-Richter, O., Marín, V. I., Bond, M. and Gouverneur, \nF. 2019. Systematic review of research on artificial \nintelligence applications in higher education – where \nare the educators? International Journal of Educational \nTechnology in Higher Education, Vol. 16, No. 1, pp. 1–27. Zheng, N., Liu, Z., Ren, P., Ma, Y., Chen, S., Yu, S., Xue, J., Chen, \nB., & Wang, F. 2017. Hybrid-augmented intelligence: \nCollaboration and cognition. Frontiers of Information \nTechnology & Electronic Engineering, 18(2), 153–179. Zhixue. n.d.. Intelligent Learning. Available at: https://www. zhixue.com/login.html (Accessed 29 December 2020). Zhong, Y. X. 2006. A cognitive approach and AI research. 2006 5th IEEE International Conference on Cognitive \nInformatics, Vol. 1, pp. 90-100."
  },
  {
    "id": "f5309cd3-eb7c-4039-a138-517c36779f5c",
    "filename": "documents\\376709eng.pdf",
    "page_number": 47,
    "chunk_id": "47_0",
    "chunk_text": "44\nAI and education: Guidance for policy-makers – Notes\nNotes\n1 \nMore detailed non-technical guidance for policy-makers \nhas been produced by the ‘AI for Peace’ group: https://www. aiforpeace.org/library\n2 \nA quintillion equals 1,000,000,000,000,000,000\n3 \nThe computing power requires large amounts of energy with \nsignificant implications for the world’s climate. 4 \n https://www.gehealthcare.com/article/\nartificial-intelligence-helps-doctors-with-critical-measure-\nment-during-pregnancy\n5 \n https://ai.googleblog.com/2018/12/improving-effectiveness-of-\ndiabetic.html\n6 \n https://www.nytimes.com/2019/05/20/health/cancer-artifi-\ncial-intelligence-ct-scans.html\n7 \nFor example, researchers overlaid an image of a panda, that the \nAI tool correctly recognized, with some random noise. The image \nwas still easily recognizable to a human as a panda, but the AI \ntool identified it as showing a gibbon. Similarly, sticking some \nsmall pieces of paper randomly on a road sign, such as a stop \nsign, can lead autonomous vehicles to misidentify it. 8 \nA seminal book that introduces much of this complexity is \nRussell and Norvig (2016)\n9 \nhttps://www.mturk.com\n10 https://www.ft.com/content/\na4b6e13e-675e-11e5-97d0-1456a776a4f5\n11 https://thispersondoesnotexist.com\n12 https://otter.ai\n13 https://www.alibabacloud.com/products/machine-translation\n14 https://lens.google.com\n15 https://woebothealth.com\n16 https://www.affectiva.com\n17 https://www.frontiersin.org/articles/10.3389/fnhum.2019.00076/\nfull\n18 https://cs.nyu.edu/faculty/davise/papers/GPT3CompleteTests.html\n19 The introduction of chatbots to answer customers’ banking \nqueries suggests that even here things are beginning to change \n(https://www.scmp.com/business/companies/article/2128179/\nhsbcs-amy-and-other-soon-be-released-ai-chatbots-are-about-\nchange). However, Google’s infamous Duplex technology now \nseems to be less intelligent than it first appeared. 20 https://www.apple.com/uk/siri/\n21 https://www.digitaltrends.com/home/what-is-amazons-alexa-\nand-what-can-it-do/ \n22 https://dueros.baidu.com/en/index.html\n23 https://www.gearbest.com/blog/tech-news/huawei-releases-ai-\nsmart-speaker-mini-with-xiaoyi-voice-assistant-in-china-6420\n24 https://www.jisc.ac.uk/news/\nchatbot-talks-up-a-storm-for-bolton-college-26-mar-2019\n25 http://genie.deakin.edu.au\n26 https://analyse.kmi.open.ac.uk\n27 https://www.swiftelearningservices.com/learning-analytics-big- \ndata-in-elearning\n28 http://kidaptive.com\n29 https://www.unitime.org\n30 https://moodle.org\n31 https://open.edx.org\n32 https://www.khanacademy.org\n33 For example, Bayesian Knowledge Tracing or Performance \nFactors Analysis\n34 Alef: https://alefeducation.com\n35 ALEKS: https://www.aleks.com\n36 Byjus: https://byjus.com (NB Not available in Europe)\n37 Mathia: https://www.carnegielearning.com\n38 Qubena: https://qubena.com\n39 Riiid: https://riiidlabs.ai/\n40 Squirrel AI: http://squirrelai.com\n41 https://educationcommission.org\n42 Watson Tutor: https://www.ibm.com/blogs/watson/2018/06/\nusing-ai-to-close-learning-gap/\n43 See https://theconversation.com/artificial-intelligence-can-now- \nemulate-human-behaviors-soon-it-will-be-dangerously-\ngood-114136. And, for an early example of AI that can \n‘write’ a school assignment, see https://openai.com/blog/\nbetter-language-models/#sample6\n44 WriteToLearn: https://www.pearsonassessments.com/profession-\nal-assessments/products/programs/write-to-learn.html\n45 e-Rater: https://www.ets.org/erater/about\n46 Turnitin: https://www.turnitin.com\n47 Smartmusic: https://www.smartmusic.com\n48 AI Teacher: http://aiteacher.100tal.com\n49 ‘Amazing English’ uses AI to help students practise their \nEnglish aloud. It also provides real-time feedback and AI-driven \nassessments. See https://www.prnewswire.com/news-releases/\nxueersi-online-school-releases-dual-teacher-product-\noffering-more-english-speaking-time-than-one-on-one-\nteaching-300626008.html\n50 Babbel: https://www.babbel.com\n51 Duolingo: https://www.duolingo.coml\n52 https://elearningindustry.com/telepresence-in-education-future- \nelearning\n53 https://www.softbankrobotics.com/emea/en/nao\n54 https://www.softbankrobotics.com/emea/en/pepper\n55 https://www.youtube.com/watch?v=E_iozVysl5g\n56 https://www.blippar.com\n57 https://eonreality.com/eon-reality-education\n58 https://edu.google.com/products/vr-ar\n59 http://www.neobear.com\n60 http://www.vrmonkey.com.br\n61 https://thirdspacelearning.com\n62 http://slp.bnu.edu.cn\n63 https://www.mofaxiao.com/\n64 https://tesla-project.eu\n65 Open, distributed ledgers, hosted simultaneously by millions of \ncomputers across the Internet and linked using cryptography, that \ncan share data in a verifiable, incorruptible, and accessible way."
  },
  {
    "id": "03d15267-959c-4540-88fb-2ee654476dd8",
    "filename": "documents\\376709eng.pdf",
    "page_number": 48,
    "chunk_id": "48_0",
    "chunk_text": "References – AI and education: Guidance for policy-makers \n45\n66 e.g. Ada Lovelace Institute (https://www.adalovelaceinstitute. org), AI Ethics Initiative (https://aiethicsinitiative.org), \nAI Ethics Lab (http://www.aiethicslab.com), AI Now (https://\nainowinstitute.org), DeepMind Ethics and Society (https://\ndeepmind.com/applied/deepmind-ethics-society), and \nthe Oxford Internet Institute (https://www.oii.ox.ac.uk/\nblog/can-we-teach-morality-to-machines-three-perspec-\ntives-on-ethics-for-artificial-intelligence). Also see Winfield, \nAlan F. T., and Jirotka, M. 2018. Ethical governance is essential \nto building trust in robotics and artificial intelligence systems. Phil. Trans. R. Soc. A. 376. And see “Top 9 ethical issues in \nartificial intelligence.” Available at: https://www.weforum.org/\nagenda/2016/10/top-10-ethical-issues-in-artificial-intelligence, \n“Establishing an AI code of ethics will be harder than \npeople think.” Available at: https://www.technologyreview. com/s/612318/establishing-an-ai-code-of-ethics-will-be-\nharder-than-people-think, and Willson, M. 2018. Raising the \nideal child? Algorithms, quantification and prediction. Media, \nCulture & Society, 5. 67 https://www.brainco.tech and see https://www.independent. co.uk/news/world/asia/china-schools-scan-brains-concentra-\ntion-headbands-children-brainco-focus-a8728951.html\n68 For example, see the XPrize (https://learning.xprize.org). 69 https://digitallibrary.io\n70 https://www.changedyslexia.org\n71 e.g. http://www.voiceitt.com, https://www.nuance.com, https://\notter.ai and https://kidsense.ai\n72 https://blogs.microsoft.com/ai/ai-powered-captioning/\n73 https://consumer.huawei.com/uk/campaign/storysign/\n74 An example of a robot developed for children on the autism \nspectrum is Kaspar (Dautenhahn et al., 2009) \n75 See, for example, Bughin et al., 2017; Frey and Osborne, 2017; \nFrontier Economics, 2018; Leopold et al., 2018; Madgavkar et al., \n2019; and Manyika et al., 2017. 76 Manpower Group. 2016. Millennial Careers: 2020 Vision-\nFacts, figures and practical advice from workforce experts. Available at https://www.manpowergroup.com/wps/\nwcm/connect/660ebf65-144c-489e-975c-9f838294c237/\nMillennialsPaper1_2020Vision_lo.pdf?MOD=AJPERES\n77 See, for example: (Tencent Research Institute, 2017) 全球人工智\n能人才白皮书\n78 Courses designed to enable citizens to become familiar with \nhow AI works can be found at https://www.elementsofai.com, \nhttps://okai.brown.edu and http://ai-4-all.org. 79 Resources designed to help teachers introduce their students \nto AI can be found at http://teachingaifork12.org and https://\ngithub.com/touretzkyds/ai4k12/wiki\n80 http://www.gettingsmart.com/2018/07/coming-this-fall-to-\nmontour-school-district-americas-first-public-school-ai-program\n81 https://www.teensinai.com\n82 https://www.skillsfuture.gov.sg/\n83 https://microcompetencies.com\n84 https://github.com/touretzkyds/ai4k12/wiki\n85 http://teachingaifork12.org\n86 https://www.elementsofai.com\n87 https://okai.brown.edu\n88 http://ai-4-all.org\n89 https://www.oecd.ai/dashboards"
  },
  {
    "id": "3af5c95a-f95e-4839-a9e1-eb2e70cfd710",
    "filename": "documents\\376709eng.pdf",
    "page_number": 49,
    "chunk_id": "49_0",
    "chunk_text": "Stay in touch\nUNESCO\n7, place de Fontenoy \n75352 Paris France \n \nhttps://en.unesco.org\n  \n@UNESCO\n \n@UNESCO"
  },
  {
    "id": "cf1161d6-7bd3-454d-b48e-a6dc02718865",
    "filename": "documents\\376709eng.pdf",
    "page_number": 50,
    "chunk_id": "50_0",
    "chunk_text": "9 789231 004476\nAI and education\nGuidance for policy-makers\nArtificial intelligence (AI) is envisioned as a new tool to accelerate the progress towards the \nachievement of SDG 4. Policies and strategies for using AI in education are central to maximizing \nAI’s benefits and mitigating its potential risks. Fostering AI-ready policy-makers is the starting \npoint of the policy development process. This publication offers guidance to policy-makers in understanding AI and responding to \nthe challenges and opportunities in education presented by AI. Specifically, it introduces \nthe essentials of AI such as its definition, techniques, technologies, capacities and limitations. It also delineates the emerging practices and benefit-risk assessment on leveraging AI to \nenhance education and learning, and to ensure inclusion and equity, as well as the reciprocal \nrole of education in preparing humans to live and work with AI. The publication summarizes three approaches to the policy responses from existing practices: \nindependent approach, integrated approach and thematic approach. In a further step, it \nproposes more detailed recommendations and examples for planning AI and education policies, \naligned with the recommendations made in the 2019 Beijing Consensus on AI and Education. Sustainable \nDevelopment\nGoals"
  },
  {
    "id": "212847e7-db54-425b-8cb4-5304311dfe82",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 1,
    "chunk_id": "1_0",
    "chunk_text": "Disaster Response\nA Public Financial Management  \nReview Toolkit\nApproach Note \nInclusive Economic Management In The Caribbean Externally Funded Output\nFunded By The Government Of Canada\nExecuted By The World Bank\nNovember 2019\nPhoto Credit: NASA"
  },
  {
    "id": "dea1483b-286b-49be-9b49-e4ad3d8ff08d",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 2,
    "chunk_id": "2_0",
    "chunk_text": "Agile, disaster-responsive PFM systems \nfacilitate rapid rebuilding of infrastructure \nand more timely restoration of services. Photo Credit: World Bank\n2"
  },
  {
    "id": "f2eee150-f3d3-4217-9eef-e7b4ed07032c",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 3,
    "chunk_id": "3_0",
    "chunk_text": "TABLE OF CONTENTS\nAcknowledgements........................................................4\nIntroduction..........................................................................5\nEvaluation Framework.......................................,,,,,.................8\nModule 1: Legal and Institutional Foundations.,,,,,,....9\nModule 2: Budget Appropriation.........................,,,,,........,,,...9\nModule 3: Financial Management Controls....,,,,,.........10\nModule 4: Public Procurement..............,,,,,.............................11\nAssessment Strategy....................,,,,.....................................12\nReview Process.................................,,,,,...................................14\nStage 1 — Desk Review.................................,,,,,,,...........................14\nStage 2 — Country Visit....................................,,,,,,,.........................14\nStage 3 — Validation and Action Plan Development.,,.14\nReferences...................................................,,,,,,,,,,,,,,,,............15\nAnnex 1: Key Interview Questions...........,.............,..................16\nAnnex 2: PD-PFM Review Report Outline...........................20\n3"
  },
  {
    "id": "d58b9fc9-d05d-42c5-8258-e7f863970c98",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 4,
    "chunk_id": "4_0",
    "chunk_text": "ACKNOWLEDGEMENTS\nThe Post-Disaster Public Financial Management (PD-PFM) Review and \nEngagement framework was prepared by Leah April and Richard Sutherland \nof the World Bank Group’s Governance Global Practice. They led a team \nthat included Joanna Watkins, Samim Cilem, Diana Annandsingh, Angela \nNieves Marques Porto, and Ivana Smolenova. The authors express their sincere gratitude to all participating governments \n(Jamaica, Antigua and Barbuda, and Saint Lucia) and their respective \nMinistries of Finance, national disaster response agencies, and gender \ndirectorates for their collaboration in piloting the PD-PFM Review. We are also grateful to the following World Bank colleagues for their \ninsights, helpful comments, and contributions at various stages in preparing \nthis methodology: Ruxandra Burdescu, Gabriel Yorio, Davide Zucchini, Onur \nErdem, Urska Zrinski, Mitchell O’Brien, Patricia McKenzie, Arun Manuja, \nMarlon Rolston Rawlins, Shaun Moss, Yvolyn Maxwell, Sophia Whyte-Givans, \nAdrienne Hathaway, Josef Trommer, Mirtha Escobar, and Hanna Haile. The PD-PFM Review was prepared with the financial support of the \nGovernment of Canada under the “Supporting Economic Management in \nthe Caribbean Externally Funded Output” (SEMCAR EFO). 4"
  },
  {
    "id": "d7cc346d-0e19-4f1a-8d8a-10b7f3b99dcb",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 5,
    "chunk_id": "5_0",
    "chunk_text": "The PD-PFM Review is an analytical instrument that seeks to help countries \nbuild resilient, responsive public financial management (PFM) systems \nby pinpointing critical PFM policies, practices, and procedures that can \nbe strengthened to improve a government’s capability to respond more \nefficiently and effectively to natural disasters and other catastrophic events, \nwithout loss of the integrity and accountability. The PD-PFM Review focuses \non four key elements of the PFM system: legal and institutional foundations; \nbudget appropriation arrangements; financial management controls; and \nprocurement arrangements.1  \nFigure 1. Core modules of the PD-PFM Review\n1 - Development and application of the PD-PFM Review is supported with funding provided by Global \nAffairs Canada and is part of a larger World Bank executed Externally Financed Output (EFO) titled \nInclusive Economic Management in the Caribbean. This EFO is in place for three years (2017-2020) \nfor the benefit of selected Caribbean countries. A component of this EFO focuses on ensuring PFM \nprocesses and systems can respond effectively to increasingly frequent natural disasters that are \nassociated with worsening of climate change. INTRODUCTION\nThis document provides an overview of the conceptual framework and \ncore principles that underpin the design of the Post-Disaster Financial \nManagement \nReview \nand \nEngagement \nFramework \n– \nhereafter \nthe  \n“PD-PFM Review”. 5"
  },
  {
    "id": "d2d6f272-be26-4ed4-95a1-222196076f70",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 6,
    "chunk_id": "6_0",
    "chunk_text": "The objective of the PD-PFM Review is to help countries assess the \ncapability of their PFM systems to respond to natural disasters by \nmeasuring the extent to which disaster-response considerations are \nintegrated into key PFM functions and activities. This assessment can be \nused to design, implement and evaluate reforms that seek to strengthen \ntheir capacity to manage public funds more efficiently and effectively in \npost-disaster situations. The PD-PFM Review has been developed and \ntested as part of a program to support resilience in selected Caribbean \ncountries: Antigua and Barbuda, Belize, Dominica, Grenada, Guyana, \nJamaica, St. Lucia, St. Vincent and the Grenadines, and Suriname. The PD-PFM Review is designed to provide a quick and robust overview \nof the strengthens and weaknesses of a PFM system that may affect \ndisaster response and recovery efforts. The review is not an audit or a \ncomprehensive assessment of the PFM system. It does not substitute for \ndisaster risk or fiduciary assessments. Rather, the review is a standardized \ntool that countries can quickly apply, in a modular way if required, to pinpoint \nspecific elements of their PFM systems that could be refined to optimize \nthe allocation and execution of public resources to facilitate timely recovery \nfrom natural disasters. The modules of the PD-PFM Review can be applied \nseparately, allowing countries to assess their capability in specific areas. Successive PD-PFM Reviews over a number of years can be used to track \nthe progress of reforms and adjust their design to target weaknesses. The PD-PFM Review applies generally accepted principles of good \npublic financial management in the context of disaster response and \nrecovery. According to the Public Expenditure and Accountability (PEFA) \nprogram, the ‘purpose of a good PFM system is to ensure that the policies \nof governments are implemented as intended and achieve their objectives’. When a disaster occurs, the primary objective of government is typically to \nminimize loss and facilitate the recovery of affected areas and population as \nsoon as possible. Achievement of this objective requires a responsive and \norderly PFM system. The PD-PFM Review identifies eight core principles \nthat should guide the development of such a system. 6"
  },
  {
    "id": "6c086b75-4584-486c-9a9a-04a16354906d",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 7,
    "chunk_id": "7_0",
    "chunk_text": "Ȋ ►Accountability. Appropriate public or external scrutiny, internal control, \nand robust review of service quality take place that hold public officials \naccountable for adherence to established standards and procedures when \nmaking and recording decisions and the consequences of their actions. Ȋ ►Efficiency. Resources are used to deliver timely, high-quality outcomes that \nrepresent fair value for money. Ȋ ►Flexibility. Fiscal rules, institutional frameworks, and administrative guidelines \ninclude clauses that allow timely and appropriate response to disasters. Ȋ ►Gender Sensitivity. Attention is paid—in the assessment, planning, and \nprogramming stages of recovery—to the differentiated roles and special \nproblems that women and men face in particularly difficult disaster-related \ncircumstances. Ȋ ►Reliability. Emergency financial protocols are executed consistently \nirrespective of the physical state of the government. Ȋ ►Resilience. Financial resources are used to restore, redevelop, and revitalize \nnatural and socioeconomic (including governance) environments so that they \nare better able to withstand the impacts of future disasters. Ȋ ►Responsiveness. Relevant PFM actors and processes are identified and \nstrategically sequenced to deliver targeted results in a timely and organized \nmanner with minimum delays and loss of opportunities. Ȋ ►Transparency. Openness and clarity in the public finance decision-making \nand management processes enhance citizens’ trust in the decisions taken by \npublic officials. The PD-PFM Review is designed to determine the extent to which the \nabove eight principles are reflected in a country’s PFM system. In \nparticular, the PD-PFM Review seeks to understand, and adjust where \nappropriate, how a government prepares, activates, and manages public \nfunds in the context of catastrophic events. The PD-PFM Review assesses \nlegislation, institutions, policies, and procedures from the pre-disaster \nplanning stage, the declaration of a disaster, through budget appropriation, \nbudget execution, procurement and the applications of financial controls. The PD-PFM Review gives particular attention to the PFM processes and \npractices that need to react quickly following a disaster, identifying where \ndeviations from standard practices may be necessary. Following a disaster, PFM institutions, policies, processes and procedures, \nactors, and information systems should ensure:\n7"
  },
  {
    "id": "8acdc936-9e03-4b41-877a-84705a27e642",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 8,
    "chunk_id": "8_0",
    "chunk_text": "The PD-PFM review focuses on four key aspects \nof the PFM system: legal and institutional \nfoundations; budget appropriation arrangements; \nfinancial management controls; and procurement \narrangements\nPhoto Credit: World Bank\n8"
  },
  {
    "id": "fa442710-11dc-4ef1-9850-59d0702fae2a",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 9,
    "chunk_id": "9_0",
    "chunk_text": "EVALUATION FRAMEWORK \nThe PD-PFM Review comprises four modules. Module 1—Legal and \nInstitutional Foundations; Module 2—Budget Appropriation; Module 3—\nFinancial Management Controls; and Module 4—Public Procurement. Figure 2. PD-PFM Review Evaluation Framework\nModules\nI\nII\nIII\nIV\nTOTAL\nIndicators\n2\n2\n4\n3\n11\nDimensions\n8\n8\n25\n11\n52\nGuiding\nQuestions\n27\n31\n61\n29\n148\nModule 1: Legal and Institutional Foundations \nThe efficacy of post-disaster response depends on clear rules and \ninstitutional arrangements for planning, mobilizing, appropriating, and \nexecuting financial resources to support post-disaster relief and recovery. Public finance rules should be specified in a budget law—or set of laws—\nthat lays out the procedures and specifies the responsibilities of the key \npublic finance actors in the context of disasters. Two indicators are used to \nassess the extent to which there is clarity on the public finance operational \nframework that is instituted to expedite the government’s response during \nand after natural disasters and similar emergencies: \n9"
  },
  {
    "id": "a3532b37-a2c3-403d-a7e7-4feb8e5afda9",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 10,
    "chunk_id": "10_0",
    "chunk_text": "Ȋ M1.1: Post-disaster PFM rules. Indicator M1.1 examines the extent to which \nlegislation and procedures specify what specific budgetary processes are \nprescribed in the context of disaster response, when these budgetary steps \nshould be taken, and who is responsible. Legislation should define the \nconditions in which these post-disaster rules should apply and for how long. Ȋ M1.2: Institutional arrangements for managing post-disaster financing. This indicator examines the extent to which institutional mechanisms are in \nplace to execute the financing of post-disaster relief and recovery operations \nin accordance with the legal and regulatory framework. During a state of \nemergency, clear, streamlined institutional mechanisms are needed to: enable \nthe transmission of data, information, and decisions between the finance \nministry and emergency response agencies; expedite approval processes and \nthe flow of funds; and ensure the appropriate use of mobilized resources. Module 2: Budget Appropriation \nA significant part of the financing for disaster response and recovery \nwill be channeled through the State budget. Appropriate provisions for \ndisasters before they occur can significantly reduce fiscal risks and greatly \nenhance a government’s ability to provide victims with aid immediately after \na disaster when they may need it most. Ex-ante budgeting for disasters \ncan boost savings, reduce risk exposure and promote aggregate fiscal \nstability. Budget frameworks that allow greater flexibility after disasters \nincrease government’s response capacity by allowing quick redeployment \nof expenditures across budget lines. The post-disaster redeployment \nof resources has to be done transparently and following clearly defined \nprocedures to maintain citizen’s trust. The following indicators are used \nto assess the extent to which a country’s national budget is responsive \nand flexible enough to finance timely post-disaster relief and recovery \noperations:\n Ȋ M2.1: Budget planning for disaster relief and recovery. This indicator examines \nthe extent to which various sources for financing disaster relief and recovery \n(including reserve funds, contingent spending arrangements, contingent loan \nfacilities, risk transfer instruments) are predetermined, programmed, and \nmanaged to optimize the government’s financial response capacity without \ncompromising fiscal balances or development objectives. 10"
  },
  {
    "id": "27ff09a8-9808-467a-a7c6-a685170c8636",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 11,
    "chunk_id": "11_0",
    "chunk_text": "Ȋ M2.2: Budget flexibility for post-disaster relief and recovery. This indicator \nexamines the existence of clear rules for in-year adjustments to the national \nbudget by the government after parliamentary approval that allow for a \ntimely and flexible response to unforeseen external shocks such as natural \ndisasters. Indicator M2.2 takes stock of the various means to supplement \nand/or reallocate approved appropriations across and within the budgets of \ngovernment ministries, departments, and agencies (MDAs) in response to a \ndisaster. The indicator assesses the limits on the extent and nature of any such \nadjustments. Approval times by government and other PFM actors, such as \nparliament, and the clarity of the reallocation procedures are also considered. Module 3: Financial Management Controls \nThe management of public resources in response to disasters should \nensure that stakeholders are held accountable for the way they use public \nresources and exercise authority. This module focuses on evaluating the \ncontrols that are in place to ensure that post-disaster relief and recovery \nfinancial resources are used as intended in a transparent manner. It assesses \nwhether there is: appropriate supervision of officers and separation of \nfinancial duties to mitigate the risk of corruption; adequate record keeping \nallowing for proper monitoring and audit; and sufficient information system \nresiliency. The following four indicators are used to assess Module 3: \n Ȋ M3.1: Post-disaster expenditure controls. This indicator examines the extent \nto which the segregation of duties, or other controls, are applied in the \nauthorization of expenditures, transaction processing, custody, and recording \nfunctions during post-disaster situations. An individual or small group of \nindividuals should not be able to initiate, approve, undertake, and review the \nsame action. Separation of functions is one of the most important features of \nan internal control plan that reduces the risk of fraud or expropriation. Ȋ M3.2: Post-disaster spending traceability. This indicator examines the extent \nto which post-disaster relief and recovery financial transactions can be tracked \nand verified ex-post. It assesses the availability of reliable, relevant, and \ntimely information about funding allocations, procurement, implementation \nprogress, and contract management. Ȋ M3.3: External control and legislative scrutiny. Indicator M3.3 assesses the \nextent to which post-disaster relief and recovery expenditures are internally \nand independently reviewed, with sufficient frequency, to ensure compliance \nwith legislation and regulations."
  },
  {
    "id": "78abff4a-7374-4a7a-a616-023a260110ea",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 11,
    "chunk_id": "11_1",
    "chunk_text": "Ȋ M3.2: Post-disaster spending traceability. This indicator examines the extent \nto which post-disaster relief and recovery financial transactions can be tracked \nand verified ex-post. It assesses the availability of reliable, relevant, and \ntimely information about funding allocations, procurement, implementation \nprogress, and contract management. Ȋ M3.3: External control and legislative scrutiny. Indicator M3.3 assesses the \nextent to which post-disaster relief and recovery expenditures are internally \nand independently reviewed, with sufficient frequency, to ensure compliance \nwith legislation and regulations. It includes a review of the instruments that \nthe legislature and supreme audit institution can deploy to oversee the use \nof funds during the disaster or reconstruction phase, and the sanctions or \nremedies that can be applied. 11"
  },
  {
    "id": "a1fe066f-82d6-4884-9613-7e5f486214d9",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 12,
    "chunk_id": "12_0",
    "chunk_text": "Ȋ M3.4: Resiliency of information systems and vital records. This indicator \nexamines whether public financial management information systems and \ndigital records, including vital registries and financial transactions, can \nwithstand the impacts of a catastrophic event. Module 4: Public Procurement \nTimely disaster response may require the procurement of goods and \nservices through expedited procedures. Such expedient procedures \nshould ensure adequate accountability, transparency, and overall value for \nmoney, considering quality, cost and time of delivery. Ideally, public finance \nlegislation reviewed under Module 1 should prescribe the public procurement \nprocedures that can be followed after a disaster. More detailed instruments \nand instructions should supplement legislation, providing guidance on how \nto apply the legislation in specific post-disaster circumstances. Module 4 \nreviews the scope of operational tools at the implementing agency level to \nguide expedited purchases using three indicators: \n Ȋ M4.1: Procurement planning for emergencies. Indicator M4.1 examines whether \nmarket research, sourcing strategies, framework agreements, memorandums \nof understanding, and/or other strategic initiatives are considered at the \nplanning stage of the procurement cycle to optimize approaches for making \npurchases in response to the immediate and serious needs that may arise \nfrom unanticipated disaster threats. Ȋ M4.2: Emergency procurement procedures. Indicator M4.2 assesses the \nextent to which procuring entities with emergency responsibilities have \naccess to standard operating procedures (SOPs), handbooks, user guides, or \nother manuals that instruct how procurement is to be conducted in post-\ndisaster situations. Ȋ M4.3 Model documents for emergency procurement. Indicator M4.3 \nassesses the model documents and templates that inform the formulation \nof procurement documents to purchase goods, works, and services in post-\ndisaster situations. This indicator also assesses whether implementation \nconditions are specified in these documents and the extent to which these \nclarify the conditions under which contractors may perform agreed activities \nprior to submitting prices. 12"
  },
  {
    "id": "d4b2c992-4e10-4cc5-b67f-34643bef99b9",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 13,
    "chunk_id": "13_0",
    "chunk_text": "ASSESSMENT STRATEGY\nThe PD-PFM Review assesses the extent to which disaster response \nconsiderations are integrated into key PFM functions and activities. The \nPD-PFM Review covers the broad policy and institutional framework and \nmore granular level processes. The review allows an assessor to quickly \ncollect data that describes how a Ministry of Finance operates in disaster \nsituations, highlighting potential weaknesses and strengths. Annex 1 \npresents a list of key interview questions and the different aspects of the \nPFM system that pertain to each question. Each of the indicators described \nabove has several dimensions. The indicators are assessed on a three-point \nscale based on existence of the function/process with the following scores: \nYes = 1, Partial = 0.5, or No = 0. The summary score is calculated by adding \ntogether the scores for each indicator and expressing the final score as \na percentage of the potential score if all indicators were scored as 1. The \nsummary score can be used to provide an overall assessment of the degree \nof integration of disaster response considerations across the PFM system. The extent to which disaster-response considerations are integrated into \nPFM functions are assessed in five categories. Ȋ Low (or no) Integration, an aggregate score of less than 25 percent, denotes \nthat a few PFM functions support post-disaster response and those which do \nhelp to accelerate response are likely to be incidental rather than part of a \ncoherent strategy. This may indicate a low level of awareness of post-disaster \nresponse as a functional imperative of the overall PFM system. Significant \nimprovements are needed to facilitate efficient and effective response to \ndisasters. Ȋ Basic Integration, an aggregate score of between 25 and 50 percent, \nindicates that disaster-response considerations are integrated in some key \nPFM functions. Some PFM processes carried out with the intent to expedite \nresponse to disasters, but this approach is not yet systematic. This category \nsignals that disaster response awareness is still limited. The PFM system \nwould benefit from further strengthening to facilitate response to disasters. 13"
  },
  {
    "id": "ed420343-945e-49a0-95f9-76005a10219a",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 14,
    "chunk_id": "14_0",
    "chunk_text": "Ȋ Moderate Integration, an aggregate score of between 50 and 75 percent, \ndenotes that disaster-response considerations are integrated in the majority \nof key PFM functions. Many PFM processes are performed with the intent \nto expedite response to disasters, and, these functions are documented, \nreasonably well coordinated and streamlined. This category signals awareness \ndisaster response as a functional imperative. The PFM system is capable of \nfacilitating an effective response to disasters. Ȋ Advanced Integration, an aggregate score of between 75 and 90 percent, \ndenotes that disaster-response considerations are integrated in most PFM \nfunctions. Most PFM processes expedite response to unforeseen disaster \nevents. There a strategic intent to use PFM processes for disaster response, \nmost processes are documented, coordinated and streamlined. This category \nsignals that that the capability of the PFM system to respond to disasters is \naccepted as a core functional requirement and efforts have been in practice \nlong enough to demonstrate their impact on disaster response performance. Ȋ Full Integration, an aggregate score of over 90 percent, denotes that disaster-\nresponse considerations are integrated in all key PFM functions. Almost all \nPFM processes are undertaken strategically to expedite disaster response, \nare streamlined, coordinated and automated where possible. New disaster-\nresponse measures are easily integrated into existing PFM processes. Disaster-\nresponsiveness is a component of the PFM system and organizational culture. The PFM system facilitates efficient or effective response to disasters and \nefforts have been in practice long enough to demonstrate their impact on \ndisaster response performance. The PD-PFM Review can be \ncompleted on-site in as little as \nthree days\nPhoto Credit: World Bank\n14"
  },
  {
    "id": "0f083d9e-0a5d-4c83-a283-fd6eafc0e864",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 15,
    "chunk_id": "15_0",
    "chunk_text": "The PD-PFM review is administered in the following three stages:  \n \nStage 1 — Desk Review\nThis entails an in-depth evaluation of legislative, policy and operational \ndocuments, assessments, and reports (such as the constitution, budget \nlaws, financial regulations, parliamentary rules of procedure/conventions \nand various PFM or disaster risk assessments) to ascertain the enabling \nenvironment provided to manage disaster response from a PFM perspective. A team of assessors reviews the “As-Is” state of preparedness against the \nlist of key interview questions and criteria outlined in Annex 1. Once these \npractices are documented, they are confirmed in Stage 2. Stage 2 — Country Visit  \nThe review team visits the country to map the PFM processes and practices \nthat facilitate response to disasters. Through discussions with government \nauthorities using Annex 1 as a guide, areas of strength and vulnerability \nare identified. The output of Stage 2 is a report of the results with \nrecommendations on ways to strengthen identified vulnerable PFM areas  \nStage 3 — Validation and Action Plan Development \nIn the final stage of the review, a validation exercise is conducted with key \nstakeholders to ensure that the findings of the PD-PFM Review are valid \nand credible. The team develops recommendations and works together \nwith the government to formulate a prioritized reform strategy to address \nthe key challenges identified in the prior two stages. All reports undergo \na robust internal quality enhancement review by the World Bank prior to \ndissemination. REVIEW PROCESS\nTypical duration: 3 to 4 days \nScope: Conduct country visit \nand administer semi-structured \ninterviews to verify findings of \nthe desk review, fill information \ngaps, confirm priorities, and \nidentify recommendations\nOutput: Completed draft of the \nPD-PFM Review report, including \nrecommended key reform \nactions. Typical duration: 1 week\nScope: In-depth desk review of \nlegislative, policy and operational \ndocuments, assessments, and \nreports\nOutput: Working draft of the  \nPD-PFM Review report\nTypical duration: 3 to 4 days\nScope: Gather client feedback; \nfinalize and disseminate final \nPD-PFM Review report. Conduct \nstakeholder meetings to jointly \nformulate the Reform Action \nPlan. Output: Dissemination of the  \nPD-PFM Review report; working \ndraft of the Reform Action Plan. 15"
  },
  {
    "id": "a514275a-0fdb-413e-b9b7-3676379e0d27",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 16,
    "chunk_id": "16_0",
    "chunk_text": "REFERENCES\nCevik, S. and Huang, G. (2018). How to Manage the Fiscal Costs of Natural \nDisasters. International Monetary Fund, Washington, D.C. Fengler, W., Ihsan, A., and Kaiser, K. (2008). Managing Post-Disaster \nReconstruction Finance: International Experience in Public Financial \nManagement. World Bank Policy Research Working Paper. GFDRR (2017). Assessing Financial Protection against Disasters: A Guidance \nNote on Conducting a Disaster Risk Finance Diagnostic. World Bank \npublication, Washington, D.C. Ghesquiere, F. and Mahul O. (n.d.). Building financial resilience against \nnatural disasters and climate change. Global Facility for Disaster Reduction \nand Recovery. IMF (2016). Small States’ Resilience to Natural Disasters and Climate \nChange—Role for the IMF. IMF Policy Paper. International Monetary Fund, \nWashington, D.C. International Federation of Red Cross and Red Crescent Societies (2010). A \nPractical guide to Gender-sensitive Approaches for Disaster Management. Public Expenditure and Financial Accountability (2016). Framework for \nassessing public financial management. PEFA Secretariat, Washington, D.C. Saxena S. and Yläoutinen S. (2016). Managing Budgetary Virements. International Monetary Fund, Washington, D.C. Secretariat of the Pacific Community (2015). Pacific Disaster Risk Finance \nand Insurance in the Kingdom of Tonga – post disaster budget execution \nguidelines. Tax Administration Diagnostic Assessment Tool (2015). Field Guide. TADAT \nSecretariat, Washington, D.C. UNDP (2017). Measuring integration of Climate Change in PFM systems. World Bank (2015). Fiji Country Note: Disaster Risk Financing and Insurance. PCRAFI. World Bank (2018). Advancing Disaster Risk Finance in Jamaica. Social, Urban, \nRural and Resilience Global Practice Latin American and the Caribbean Unit. 16"
  },
  {
    "id": "fea605b2-d317-4ed9-a357-b6116aa8d9e7",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 17,
    "chunk_id": "17_0",
    "chunk_text": "Annex 1: Key Interview Questions\nIndicator \nM1.1\nIs disaster response incorporated into the legal and regulatory framework for \npublic financial management? What is reviewed: Legislation, regulations, policies, directives, and strategies that \ndefine:\na. disaster events, their notification and termination, and specific phases (such \nas response, recovery and reconstruction); \nb. disaster response triggers for PFM actors; \nc. operating rules for accelerated (re)allocation, execution, accounting, and \noversight of disaster-specific budgetary resources;\nd. powers and duties of public finance officers during disasters; and\ne. the approach for accessing and sequencing disaster risk financing. Indicator \nM1.2\nWhat are the institutional arrangements for responding to disasters from a PFM \nperspective? What is reviewed: Institutional mechanisms that facilitate post-disaster financing, \nsuch as:\na. a centralized entity to coordinate disaster response and recovery activities;\nb. mechanisms to coordinate and communicate budgetary arrangements for \ndisaster response;\nc. contingency measures and procedures to ensure operational continuity during \ndisasters; and \nd. staff who are knowledge of and trained on how to execute emergency finance \nprocedures. Indicator \nM2.1\nTo what extent is budget planning carried out to support disaster response and \nrecovery efforts? What is reviewed: Availability, accessibility, adequacy, and timeliness of \npredetermined funding options for disaster relief and recovery, such as:\na. contingent budget lines (e.g. earmarked budget lines, standby appropriations, \nor unallocated provisions);\nb. extrabudgetary funds (e.g. permanent funds such as contingency funds and \nnational disaster funds, or temporary funds such as trust funds or special \nfunds); and\nc. external standby facilities (e.g. risk transfer instruments such as parametric \ninsurance and asset insurance, contingent loan/grant facilities, disaster \nbonds). 17"
  },
  {
    "id": "39861067-7b4e-4065-bf74-2d60279da699",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 18,
    "chunk_id": "18_0",
    "chunk_text": "Indicator \nM2.2\nIs there adequate budget flexibility to facilitate disaster response and recovery \nefforts? What is reviewed: Authorities and procedures that can be used to adjust the national \nbudget after approval for post-disaster response purposes:\na. Supplementary provisioning;\nb. Advance provisioning;\nc. Within Ministerial, Departmental and Agency budget amendments, including \nvirements;\nd. Reallocations of budget provisions between Ministeries, Departments and \nAgencies; \ne. interim finance directives to guide PFM decision making in disaster situations. Indicator \nM3.1\nTo what extent are PFM duties and functions structured to enhance disaster-\nrelated expenditure controls? What is reviewed: Instructions for accelerating disbursements and the flow of \nfunds in disaster situations and the unit, department, and/or staff position that is \nresponsible for:\na. receipt of financial transfers of external assistance for disaster response and \nrecovery;\nb. approving financial transactions for disaster response ex-post and ex-ante;\nc. authorizing the execution of approved transactions for disaster response;\nd. making disbursements in the aftermath of a disaster;\ne. recording transactions in the aftermath of a disaster;\nf. acknowledging the receipt of goods or services involved in the transactions; \nand\ng. carrying out periodic reviews and reconciliation of existing assets to recorded \namounts. Indicator \nM3.2\nHow are disaster-related expenditures tracked and recorded? What is reviewed: Evidence of the government’s capability to:\na. track disaster-related expenditure by event, event type (such as flooding or \nhurricane) and nature (response, recovery or reconstruction) through the Chart \nof Accounts (COA);\nb. enforce the uniform reporting of disaster-related spending by all government \nministries, departments, and agencies (i.e. uniform use of the COA, reporting \nrequirements and standards);\nc. track disaster-related external assistance commitments, transfers and \ndisbursements;\nd. ensure fiscal transparency through timely publication of disaster response \nplans, budget allocations, contracting information, financial reports and \nstatements, implementation reports and results; and\ne. ensure availability of disaster-response related accounting records, requiring \nthe retention of supporting documents for reasonable periods of time. 18"
  },
  {
    "id": "612219c2-8ab6-4989-bbdb-f7b296b05191",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 19,
    "chunk_id": "19_0",
    "chunk_text": "Indicator \nM3.3\nHow are disaster-related expenditures scrutinized? What is reviewed: Mechanisms for verifying, controlling, and monitoring disaster-\nrelated spending, with particular focus on:\na. verification mechanisms (i.e. to confirm the eligibility and legality of disaster-\nrelated expenditures, availability of budget, provision of goods/services, and \nsubmission of supporting documents for expenses incurred);\nb. commitment control for post-disaster spending;\nc. disbursement monitoring arrangements (from authorizing payments to \ndisbursement of funds from different sources, including special funds and \nother off-budget accounts);\nd. external oversight including requirements for audit and oversight of disaster-\nrelated expenditure;\ne. timeliness of audit submissions to the legislature; and\nf. enforcement of and follow-up on audit recommendations. Indicator \nM3.4\nHow resilient are PFM information systems and vital records to threats from \nnatural disasters? What is reviewed: Measures that ensure the protection and continuation of financial \ntransactions in the aftermath of a disaster. a. Preparedness of finance agencies to handle disaster including definition of \nmission-critical functions and systems, established hierarchy of operational \nimportance, pre-identified list of critical applications, impact assessments of \nsystem failure; \nb. Disaster \nrecovery \nplanning \nincluding \navailability \nof \nan \nup-to-date, \ncomprehensive IT disaster recovery plan covering computer room environment, \nhardware, connectivity, software applications, and data protection and \nrestoration, including for hardcopy files;\nc. Recovery readiness including creation of a Recovery Point and Time Objectives \nfor all major PFM applications; \nd. Known vulnerabilities if critical PFM systems collapse;\ne. Data backup routines, technology, and locations; and\nf. Data center resiliency including fire and flood barriers and robust building \narchitecture; multiple connections; uninterruptible power supply with battery \nbackup and generators; redundant servers and storage; multiple high-speed \nnetwork links entering and exiting at different points; smoke, fire, humidity and \nflood detection; and physically secured servers. 19"
  },
  {
    "id": "9b354eef-ea5f-4c95-a872-de8a2eeba5ca",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 20,
    "chunk_id": "20_0",
    "chunk_text": "Indicator \n4.1\nHow is disaster response and recovery procurement planned? What is reviewed: Operational instruments that support the government’s planning \nneeds that may arise from disasters:\na. Preemptive planning including creation and maintenance of annual and \nmulti-annual procurement plans that include provisions for disaster events, \nplans and strategies to address with disruptions in the supply chain of critical \nsupplies such as medicine;\nb. Strategic use of market research and analytics including: use of data to \nextrapolate future requirements from previous disaster response purchases; \nconducting market research and cost analyses to assess supplier markets \nbefore disasters strike; visualizations of end-to-end supply chains through \ngeographic maps and network graphs;\nc. Pre-established contracting arrangements that minimize time to mobilize \nprimary and/or alternate supplies including pre-identification of suppliers \nand alternate suppliers, establishment of framework agreements and \nmemorandums of understanding for purchases; and\nd. Flexibility to respond forgoing routine procurement procedures to expedite \nresponse; use of preemptive levers used to increase contract flexibility during \nemergencies such as inserting clauses in contracts that enable adjustments \nin volumes. Indicator \n4.2\nHow is disaster-related contracting carried out in disaster situations? What is reviewed: Guidelines, techniques or procedures that support the \naccelerated acquisition of goods, services, and works for disaster response and \nrecovery, including:\na. Standard operating procedures, protocols and instruction manuals that lay \nout how entities should execute procurement and contracting for disaster \nresponse and recovery;\nb. Measures prescribed for disaster response and recovery circumstances that \nstreamline the procurement process for disaster-related procurement;\nc. Protocols to ensure adequate and timely access to information on each phase \nof the public procurement of disaster-related works, supplies and services;\nd. Mechanisms for the timely determination of vendor eligibility and their \nregistration; and\ne. Post-award contract oversight functions and procedures that ensure the \ntimely implementation and completion of post-disaster contracts including \na monitoring and evaluation framework for contract performance; clearly \ndefined contract management functions and responsibilities; methods for \ninspection, quality control, supervision of civil works, and final acceptance of \nproducts; and techniques for invoice examination. Indicator \n4.3\nWhat instruments are used to streamline and expedite disaster-related public \nprocurement? What is reviewed: \na. The existence of up-to-date model procurement documents and templates \nthat are of acceptable quality and widely accessible to all procuring entities, \nwhich may be used for the acquisition of goods, services, and works that are \nmost frequently needed for disaster response and recovery; and\nb."
  },
  {
    "id": "8ba8e70f-3110-4dce-9a60-8070ab7e4675",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 20,
    "chunk_id": "20_1",
    "chunk_text": "Mechanisms for the timely determination of vendor eligibility and their \nregistration; and\ne. Post-award contract oversight functions and procedures that ensure the \ntimely implementation and completion of post-disaster contracts including \na monitoring and evaluation framework for contract performance; clearly \ndefined contract management functions and responsibilities; methods for \ninspection, quality control, supervision of civil works, and final acceptance of \nproducts; and techniques for invoice examination. Indicator \n4.3\nWhat instruments are used to streamline and expedite disaster-related public \nprocurement? What is reviewed: \na. The existence of up-to-date model procurement documents and templates \nthat are of acceptable quality and widely accessible to all procuring entities, \nwhich may be used for the acquisition of goods, services, and works that are \nmost frequently needed for disaster response and recovery; and\nb. The specification of implementation conditions in contracts that are awarded \nfor disaster response and recovery operations. 20"
  },
  {
    "id": "52506f14-0514-4065-afcf-2a190d726f02",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 21,
    "chunk_id": "21_0",
    "chunk_text": "The PD-PFM Review is a rapid, modular, \nstandardized tool that assesses how well PFM \nsystems respond to climate change\nPhoto Credit: World Bank\n21"
  },
  {
    "id": "e81b29d0-afbd-4b10-b284-d63ae4b5d693",
    "filename": "documents\\disaster-response-a-public-financial-management-review-toolkit.pdf",
    "page_number": 22,
    "chunk_id": "22_0",
    "chunk_text": "Richard Sutherland\nPublic Sector Analyst\nrsutherland@worldbank.org\n1-202-458-4577\nLeah April\nSenior Public Sector Specialist\nlapril@worldbank.org\n1-202-725-0643\nFOR MORE INFORMATION CONTACT:\nPhoto Credit: World Bank"
  }
]